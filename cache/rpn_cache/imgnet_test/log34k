training_utils: require set.	
proposal_test: weird	
net_def: models/zf_prelu.lua	
pnet: layer 1 ready.	
pnet: layer 2 ready.	
pnet: layer 3 ready.	
pnet: layer 4 ready.	
pnet: layer 5 ready.	


=========
pnet ready
=========

	
cnet inputs = 9216	


=========
cnet ready (prelu)
=========

	
model (printed by load_model)	
pnet module #1	
nn.Identity
pnet module #2	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> output]
  (1): nn.SpatialConvolution(3 -> 96, 7x7, 2,2, 1,1)
  (2): nn.PReLU
  (3): nn.SpatialCrossMapLRN
  (4): nn.SpatialMaxPooling(3x3, 2,2)
}
pnet module #3	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> output]
  (1): nn.SpatialConvolution(96 -> 256, 5x5, 1,1, 2,2)
  (2): nn.PReLU
  (3): nn.SpatialCrossMapLRN
  (4): nn.SpatialMaxPooling(3x3, 2,2)
}
pnet module #4	
nn.Sequential {
  [input -> (1) -> (2) -> output]
  (1): nn.SpatialConvolution(256 -> 384, 3x3, 1,1, 1,1)
  (2): nn.PReLU
}
pnet module #5	
nn.Sequential {
  [input -> (1) -> (2) -> output]
  (1): nn.SpatialConvolution(384 -> 384, 3x3, 1,1, 1,1)
  (2): nn.PReLU
}
pnet module #6	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> output]
  (1): nn.SpatialConvolution(384 -> 256, 3x3)
  (2): nn.PReLU
  (3): nn.SpatialConvolution(256 -> 18, 1x1)
}
pnet module #7	
nn.Sequential {
  [input -> (1) -> (2) -> output]
  (1): nn.SpatialConvolution(384 -> 256, 3x3, 1,1, 1,1)
  (2): nn.PReLU
}
pnet module #8	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> output]
  (1): nn.SpatialConvolution(256 -> 256, 3x3)
  (2): nn.PReLU
  (3): nn.SpatialConvolution(256 -> 18, 1x1)
}
pnet module #9	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> output]
  (1): nn.SpatialConvolution(256 -> 256, 5x5)
  (2): nn.PReLU
  (3): nn.SpatialConvolution(256 -> 18, 1x1)
}
pnet module #10	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> output]
  (1): nn.SpatialConvolution(256 -> 256, 7x7)
  (2): nn.PReLU
  (3): nn.SpatialConvolution(256 -> 18, 1x1)
}

	
cnet module #1	
nn.Identity
cnet module #2	
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> output]
  (1): nn.Linear(9216 -> 4096)
  (2): nn.BatchNormalization (2D) (4096)
  (3): nn.PReLU
  (4): nn.Dropout(0.500000)
  (5): nn.Linear(4096 -> 4096)
  (6): nn.PReLU
  (7): nn.Dropout(0.500000)
}
cnet module #3	
nn.Linear(4096 -> 4)
cnet module #4	
nn.Sequential {
  [input -> (1) -> (2) -> output]
  (1): nn.Linear(4096 -> 31)
  (2): nn.LogSoftMax
}

	
load_model: restored	
combine_and_flatten_par: pw:	
{
  1 : CudaTensor - size: 96x3x7x7
  2 : CudaTensor - size: 96
  3 : CudaTensor - size: 1
  4 : CudaTensor - size: 256x96x5x5
  5 : CudaTensor - size: 256
  6 : CudaTensor - size: 1
  7 : CudaTensor - size: 384x256x3x3
  8 : CudaTensor - size: 384
  9 : CudaTensor - size: 1
  10 : CudaTensor - size: 384x384x3x3
  11 : CudaTensor - size: 384
  12 : CudaTensor - size: 1
  13 : CudaTensor - size: 256x384x3x3
  14 : CudaTensor - size: 256
  15 : CudaTensor - size: 1
  16 : CudaTensor - size: 18x256x1x1
  17 : CudaTensor - size: 18
  18 : CudaTensor - size: 256x384x3x3
  19 : CudaTensor - size: 256
  20 : CudaTensor - size: 1
  21 : CudaTensor - size: 256x256x3x3
  22 : CudaTensor - size: 256
  23 : CudaTensor - size: 1
  24 : CudaTensor - size: 18x256x1x1
  25 : CudaTensor - size: 18
  26 : CudaTensor - size: 256x256x5x5
  27 : CudaTensor - size: 256
  28 : CudaTensor - size: 1
  29 : CudaTensor - size: 18x256x1x1
  30 : CudaTensor - size: 18
  31 : CudaTensor - size: 256x256x7x7
  32 : CudaTensor - size: 256
  33 : CudaTensor - size: 1
  34 : CudaTensor - size: 18x256x1x1
  35 : CudaTensor - size: 18
}
combine_and_flatten_par: cw:	
{
  1 : CudaTensor - size: 4096x9216
  2 : CudaTensor - size: 4096
  3 : CudaTensor - size: 4096
  4 : CudaTensor - size: 4096
  5 : CudaTensor - size: 1
  6 : CudaTensor - size: 4096x4096
  7 : CudaTensor - size: 4096
  8 : CudaTensor - size: 1
  9 : CudaTensor - size: 4x4096
  10 : CudaTensor - size: 4
  11 : CudaTensor - size: 31x4096
  12 : CudaTensor - size: 31
}
Weight size:	
 64755958
[torch.LongStorage of size 1]

Stoed weight size:	
 64755958
[torch.LongStorage of size 1]

=== check point: model loaded (time = 20.543241) ===	
=== check point: anchors prepared (time = 0.003530) ===	
=== check point: imdb loaded (time = 0.022801) ===	
=== check point: about to detect on imgs ===	
img #1	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00008004/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1902.5562 -2140.4092 -2063.7986
 -2027.2583 -2257.4514 -2148.4939
 -1986.4716 -2173.2361 -2048.7451

(2,.,.) = 
  2848.8506  3010.2898  2897.8384
  3052.9136  3230.8362  3075.9785
  2947.0251  3092.7446  2923.2756

(3,.,.) = 
  3651.1965  3976.3584  3975.4810
  4480.1948  4890.3511  4882.4683
  4902.0645  5377.1504  5354.2046

(4,.,.) = 
  1042.6887  1161.1475  1138.7224
  1303.9918  1403.8010  1351.8114
  1418.7228  1471.4813  1379.0393

(5,.,.) = 
   741.9105   732.5082   653.8729
   728.0226   680.0451   573.9576
   744.5477   661.6237   552.9973

(6,.,.) = 
  1630.9196  1848.4124  1890.4427
  2004.1644  2310.7817  2354.0901
  2307.8018  2651.0916  2678.7666

(7,.,.) = 
 -2739.3613 -2908.4048 -2730.8918
 -2955.7661 -3104.4192 -2840.9690
 -2834.2720 -2908.5261 -2616.3176

(8,.,.) = 
  5726.3179  6132.5918  5888.2671
  6455.8345  6878.6392  6554.8467
  6720.2837  7089.6353  6717.7812

(9,.,.) = 
  2511.2878  3020.2029  3219.3826
  2893.8130  3416.9626  3544.4553
  3165.8958  3696.7039  3781.6013

(10,.,.) = 
 -3390.3611 -3347.0059 -3097.1223
 -3630.6030 -3594.3491 -3324.0439
 -3593.2441 -3548.1079 -3300.9180

(11,.,.) = 
   475.1225   634.0964   725.2756
   746.5173   935.7521  1023.2197
   837.3706  1072.7229  1162.9861

(12,.,.) = 
   447.2224   718.3270   952.0729
   514.6709   831.1228  1054.0804
   272.2402   586.9344   781.6859

(13,.,.) = 
 -2923.1609 -3088.8938 -2985.1663
 -2946.1221 -3098.1477 -2981.2446
 -2879.0918 -3022.1140 -2879.2668

(14,.,.) = 
  5030.4673  5327.9131  5130.1689
  5302.3052  5590.1968  5349.0410
  5245.7236  5556.2354  5284.7266

(15,.,.) = 
  3413.2146  3699.9075  3673.1162
  3978.7935  4362.0977  4311.8599
  4311.3970  4715.2295  4643.7974

(16,.,.) = 
 -2903.0908 -2981.0051 -2968.6731
 -3029.5024 -3141.8286 -3117.9778
 -3161.9531 -3302.2053 -3265.2927

(17,.,.) = 
 -7520.2100 -7911.5542 -7809.4590
 -8631.7998 -9133.0469 -9028.4717
 -9330.8037 -9894.8057 -9770.3936

(18,.,.) = 
  1632.1781  1580.0868  1483.6249
  1819.0011  1739.1632  1632.4215
  1813.8223  1720.3623  1617.0671
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3651.1965332031	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #1: time = 0.737537	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1555e+04   4.2263e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #2	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00035000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1898.5720 -2136.7888 -2061.7422
 -2023.2080 -2253.8452 -2146.7720
 -1982.6084 -2170.3406 -2047.8470

(2,.,.) = 
  2843.2490  3005.7109  2895.3774
  3046.7981  3225.7900  3073.0076
  2941.2253  3088.2981  2921.0610

(3,.,.) = 
  3648.2922  3974.9783  3976.6492
  4475.7339  4887.3896  4881.9980
  4897.3301  5373.2437  5352.4326

(4,.,.) = 
  1042.3118  1161.7507  1140.0812
  1304.2212  1404.6747  1353.4253
  1418.6772  1472.4014  1380.7494

(5,.,.) = 
   740.6274   731.9605   654.0649
   727.0993   679.8934   574.3180
   744.0352   661.6843   553.4991

(6,.,.) = 
  1629.2736  1846.7167  1889.6025
  2001.1797  2307.3152  2351.6111
  2304.6074  2647.4314  2676.1553

(7,.,.) = 
 -2733.0713 -2903.0398 -2727.0569
 -2948.4402 -3098.0454 -2836.3142
 -2827.2314 -2902.9355 -2612.7312

(8,.,.) = 
  5717.7788  6126.3120  5886.2407
  6446.1108  6870.7593  6550.8784
  6710.8286  7081.9692  6713.7759

(9,.,.) = 
  2509.7666  3019.2830  3219.4038
  2890.9241  3414.6853  3543.5107
  3161.2073  3692.6699  3779.1792

(10,.,.) = 
 -3386.3145 -3344.8074 -3097.4109
 -3625.5515 -3590.9077 -3323.2498
 -3587.8088 -3544.0681 -3299.2737

(11,.,.) = 
   475.3817   634.3397   725.8006
   746.2377   935.3212  1022.8821
   837.2507  1072.1995  1162.2568

(12,.,.) = 
   446.6794   717.0016   950.2701
   513.6926   829.4955  1052.3263
   271.9587   586.6099   781.6176

(13,.,.) = 
 -2916.6521 -3083.7522 -2981.6890
 -2938.0981 -3091.7422 -2976.9863
 -2871.0999 -3015.7097 -2874.9844

(14,.,.) = 
  5022.0811  5321.7729  5127.3506
  5292.5908  5582.7847  5345.2051
  5236.0781  5548.8521  5280.8979

(15,.,.) = 
  3409.7690  3698.0286  3673.7834
  3974.0452  4358.5742  4311.0142
  4306.4199  4711.3340  4642.4082

(16,.,.) = 
 -2901.3447 -2981.5835 -2971.6101
 -3027.7100 -3142.0732 -3120.3115
 -3159.2634 -3301.0425 -3265.8647

(17,.,.) = 
 -7513.4775 -7908.9971 -7812.4795
 -8624.6240 -9129.2334 -9030.3760
 -9323.1279 -9889.6748 -9770.0762

(18,.,.) = 
  1630.8079  1579.7407  1484.1997
  1817.0396  1738.3213  1632.4591
  1811.6555  1719.2126  1616.9265
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3648.2922363281	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #2: time = 0.536085	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1570e+04   4.2282e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #3	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00008003/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1912.0182 -2151.6790 -2075.2742
 -2038.4458 -2270.5117 -2161.9111
 -1997.4861 -2186.4976 -2062.0234

(2,.,.) = 
  2862.7275  3025.6338  2913.5903
  3068.8950  3248.7327  3093.7458
  2962.4697  3110.2266  2940.6846

(3,.,.) = 
  3683.7424  4012.0320  4010.7400
  4517.7236  4931.5571  4922.7632
  4941.3506  5419.6299  5394.9463

(4,.,.) = 
  1052.9209  1173.0623  1150.6619
  1317.1080  1417.8057  1365.4086
  1432.0546  1485.7976  1392.6104

(5,.,.) = 
   749.5444   740.6915   661.4012
   735.7288   688.5079   581.5478
   752.2171   669.5729   560.2242

(6,.,.) = 
  1647.3414  1866.3313  1908.2360
  2022.4047  2330.6516  2373.5798
  2327.2441  2671.9934  2698.8230

(7,.,.) = 
 -2755.8269 -2926.9253 -2749.2568
 -2974.1003 -3124.7632 -2860.4004
 -2852.1604 -2928.1057 -2635.0271

(8,.,.) = 
  5768.0732  6178.2056  5933.5454
  6502.7949  6929.3872  6603.8589
  6768.2383  7140.9312  6766.6758

(9,.,.) = 
  2534.2427  3046.6804  3247.0044
  2919.2788  3445.8755  3573.9673
  3190.9045  3725.0088  3810.1519

(10,.,.) = 
 -3411.9692 -3369.3843 -3118.9309
 -3654.1846 -3618.5654 -3347.4805
 -3616.9558 -3572.2866 -3324.2251

(11,.,.) = 
   478.9836   638.6552   730.1580
   752.1094   941.8511  1029.4564
   843.1171  1079.1962  1169.4879

(12,.,.) = 
   447.2511   719.1223   953.8196
   515.7139   833.3637  1057.2533
   272.9371   589.4355   785.4024

(13,.,.) = 
 -2936.9990 -3104.5879 -3001.0776
 -2959.5542 -3113.9934 -2997.6394
 -2892.9983 -3038.1938 -2895.3225

(14,.,.) = 
  5059.2378  5359.5532  5161.6665
  5333.0767  5623.7515  5382.4292
  5276.9048  5590.5132  5318.4233

(15,.,.) = 
  3443.0295  3732.9204  3706.0737
  4012.1719  4398.9375  4348.2515
  4346.0693  4753.1938  4680.6914

(16,.,.) = 
 -2926.1624 -3005.9453 -2993.7480
 -3055.0796 -3169.0171 -3144.7065
 -3187.6196 -3329.4146 -3291.4729

(17,.,.) = 
 -7582.4385 -7978.3579 -7875.4067
 -8702.0430 -9207.7461 -9102.0781
 -9403.9639 -9971.8857 -9844.8955

(18,.,.) = 
  1642.6033  1590.7473  1493.9559
  1831.1210  1751.1528  1643.8750
  1826.3655  1732.5426  1628.7900
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3683.7424316406	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #3: time = 0.57927	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2085e+04   4.2622e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #4	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00010014/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1920
 1920
[torch.LongStorage of size 3]

x_start = 1 / y_start = 421	
img_means:size() vs img:size():	
    3
 1080
 1920
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.55555555555556	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
 1080
 1920
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.55555555555556	
proposal_im_detect: scaled_img_size:	
    2
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1910.1224 -2149.6672 -2073.8188
 -2036.1665 -2268.1790 -2160.2017
 -1995.2377 -2184.3047 -2060.4951

(2,.,.) = 
  2859.7488  3022.8533  2911.4771
  3065.4023  3245.3928  3091.1980
  2959.0229  3106.9790  2938.2695

(3,.,.) = 
  3678.4976  4007.0334  4006.6333
  4511.2056  4925.3462  4917.5728
  4934.3252  5412.7690  5389.2573

(4,.,.) = 
  1051.0576  1171.1417  1148.9126
  1315.1302  1415.8212  1363.6112
  1429.9821  1483.8599  1391.0912

(5,.,.) = 
   748.0372   739.5884   660.9048
   734.2711   687.4427   581.0370
   750.8859   668.5909   559.6219

(6,.,.) = 
  1644.1725  1863.1289  1905.3245
  2018.5985  2326.7900  2370.1113
  2323.1753  2667.8452  2695.1819

(7,.,.) = 
 -2751.2229 -2922.5129 -2745.6709
 -2969.1118 -3119.9636 -2856.6245
 -2847.4392 -2923.7068 -2631.7063

(8,.,.) = 
  5759.2188  6169.8350  5927.0073
  6492.8867  6920.0566  6596.4990
  6758.2471  7131.5439  6759.3667

(9,.,.) = 
  2529.8096  3041.8088  3242.2087
  2914.0344  3440.2405  3568.7246
  3185.4778  3719.3342  3805.1790

(10,.,.) = 
 -3408.8369 -3366.8728 -3117.3647
 -3650.6738 -3615.6221 -3345.6401
 -3613.1931 -3569.0356 -3321.9187

(11,.,.) = 
   477.9805   637.4260   728.9629
   750.9377   940.4787  1028.0712
   841.7121  1077.5005  1167.7998

(12,.,.) = 
   446.9754   718.2707   952.5259
   515.2480   832.2849  1055.8291
   272.6135   588.6132   784.4495

(13,.,.) = 
 -2933.0676 -3100.8542 -2998.0066
 -2955.0000 -3109.5813 -2993.9622
 -2888.5024 -3033.9189 -2891.8840

(14,.,.) = 
  5052.6631  5353.3838  5156.8262
  5325.8408  5616.9624  5377.0552
  5269.6699  5583.6899  5313.0972

(15,.,.) = 
  3437.4819  3727.5444  3701.6555
  4005.7786  4392.6968  4343.1367
  4339.4536  4746.7456  4675.4536

(16,.,.) = 
 -2923.0615 -3003.3132 -2991.7561
 -3051.3953 -3165.7988 -3142.1914
 -3183.5105 -3325.6799 -3288.5034

(17,.,.) = 
 -7571.8340 -7968.8003 -7867.8223
 -8689.9932 -9196.6406 -9093.1230
 -9391.0859 -9959.8789 -9835.0898

(18,.,.) = 
  1641.0862  1589.6844  1493.3506
  1829.3162  1749.8464  1642.9851
  1824.3678  1730.9852  1627.6326
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3678.4975585938	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #4: time = 0.632024	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.9200e+03   1.9200e+03
        -inf         -inf   1.0803e+05   6.3884e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #5	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00138010/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  816
 1920
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1920
 1920
[torch.LongStorage of size 3]

x_start = 1 / y_start = 553	
img_means:size() vs img:size():	
    3
  816
 1920
[torch.LongStorage of size 3]

    3
  816
 1920
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.73529411764706	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1411
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x174
  2 : CudaTensor - size: 18x72x174
  3 : CudaTensor - size: 18x70x172
  4 : CudaTensor - size: 18x68x170
  5 : CudaTensor - size: 256x74x176
}
proposal_im_deteect: img_blob size:     3
  600
 1411
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  816
 1920
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.73529411764706	
proposal_im_detect: scaled_img_size:	
    2
  600
 1412
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1900.0870 -2137.3179 -2061.3374
 -2022.7842 -2252.5605 -2144.3840
 -1980.9364 -2167.5361 -2043.8712

(2,.,.) = 
  2845.2363  3006.5024  2894.2180
  3047.5115  3224.7817  3070.0432
  2940.1060  3085.1282  2915.9919

(3,.,.) = 
  3637.5259  3959.9143  3957.1431
  4461.9355  4868.9897  4858.9858
  4881.1479  5353.1934  5328.5845

(4,.,.) = 
  1035.9338  1153.0309  1129.5060
  1296.9969  1395.1229  1341.9480
  1411.6150  1463.1064  1370.3472

(5,.,.) = 
   737.4390   728.1608   650.0171
   723.1972   675.3572   569.5497
   740.0142   657.1163   547.8965

(6,.,.) = 
  1620.5911  1835.0845  1875.3459
  1991.3452  2294.4570  2335.7749
  2293.7610  2633.2502  2659.1538

(7,.,.) = 
 -2726.1692 -2894.7849 -2716.9524
 -2940.1926 -3088.1394 -2824.7451
 -2817.8064 -2891.9292 -2600.2109

(8,.,.) = 
  5702.2397  6106.0723  5861.5444
  6427.5479  6847.7705  6523.6396
  6690.4795  7057.6753  6686.2749

(9,.,.) = 
  2500.4043  3006.4736  3202.4604
  2878.1982  3397.9885  3522.8787
  3148.5750  3676.5603  3759.8196

(10,.,.) = 
 -3387.4507 -3344.1255 -3093.5173
 -3626.0667 -3589.3354 -3319.1396
 -3585.8013 -3540.0444 -3292.6082

(11,.,.) = 
   470.6500   628.7462   720.2604
   742.9810   931.3865  1018.5869
   833.4173  1067.6949  1157.3774

(12,.,.) = 
   446.8922   716.7122   950.0166
   513.7889   828.3859  1050.9391
   270.1425   583.0278   777.4368

(13,.,.) = 
 -2915.8457 -3082.4543 -2978.8062
 -2934.7285 -3087.4731 -2970.7375
 -2866.7554 -3010.5007 -2868.3535

(14,.,.) = 
  5017.5381  5314.8809  5117.3623
  5285.6904  5573.8315  5333.0269
  5226.8901  5537.4473  5266.8052

(15,.,.) = 
  3396.5840  3680.3096  3651.9883
  3958.8735  4338.7925  4287.2856
  4290.0264  4690.6343  4618.7251

(16,.,.) = 
 -2899.4041 -2976.6218 -2962.5879
 -3022.3420 -3133.9304 -3108.3728
 -3152.0627 -3290.8513 -3252.4617

(17,.,.) = 
 -7494.0444 -7881.7612 -7776.0815
 -8600.1963 -9096.6826 -8988.3457
 -9295.2441 -9854.5010 -9726.9268

(18,.,.) = 
  1630.3292  1578.6158  1481.9364
  1815.9977  1736.6825  1628.9460
  1809.0792  1715.7292  1611.4448
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 172
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 36120
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 172
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 172
[torch.LongStorage of size 2]

shift_y size:	
  70
 172
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
     3
 12040
     4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 36120
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 36120
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 36120
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  36120
[torch.LongStorage of size 1]
	
  first line: 3637.5258789062	
(fast bbox transform) src_w size:  36120
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 36120
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 36120
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 36120
     4
[torch.LongStorage of size 2]

scores size:	
 36120
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 36120
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 36120
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 36120
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 96320
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 24080
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 24080
[torch.LongStorage of size 1]

test img #5: time = 0.845124	
(proposal_test:boxes_filter) boxes & scores size:	
 24080
     4
[torch.LongStorage of size 2]

 24080
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 3
[torch.LongStorage of size 1]

 1379
    3
    4
[torch.LongTensor of size 3]

mask size:	
 24080
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 12
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.9200e+03   1.9200e+03
  1.0000e+00   1.0000e+00   8.1600e+02   8.1600e+02
        -inf         -inf   8.0782e+04   4.7352e+04
[torch.CudaTensor of size 3x4]

(proposal_test:boxes_filter) boxes size returned:	
 3
 4
[torch.LongStorage of size 2]

img #6	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00133002/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1906.2096 -2145.3721 -2069.4414
 -2032.2606 -2263.8589 -2155.9563
 -1991.2897 -2180.0005 -2056.2737

(2,.,.) = 
  2854.0540  3016.8401  2905.6812
  3059.5068  3239.3423  3085.3738
  2953.1240  3101.0049  2932.6531

(3,.,.) = 
  3675.1025  4002.9644  4001.9255
  4507.0063  4920.3496  4911.8281
  4929.1826  5406.7798  5382.4541

(4,.,.) = 
  1051.1733  1171.2081  1148.8625
  1314.7440  1415.3799  1363.0721
  1429.2000  1482.9974  1389.9702

(5,.,.) = 
   747.9347   739.2544   660.4739
   734.1453   687.2894   580.8850
   750.3597   668.1963   559.5386

(6,.,.) = 
  1644.5466  1863.5098  1905.3817
  2018.8262  2326.8423  2369.7415
  2322.7336  2667.1760  2694.1067

(7,.,.) = 
 -2748.8262 -2919.8499 -2743.3076
 -2966.5457 -3117.3000 -2854.3667
 -2844.6243 -2920.9204 -2629.4307

(8,.,.) = 
  5753.5742  6163.2065  5919.9385
  6486.2373  6912.4312  6588.5220
  6750.2354  7122.7305  6750.2808

(9,.,.) = 
  2528.4126  3039.8948  3240.0330
  2912.7119  3438.3130  3566.4524
  3183.1782  3716.2207  3801.5771

(10,.,.) = 
 -3401.2773 -3359.3828 -3110.3538
 -3642.7439 -3607.8857 -3338.2263
 -3605.6558 -3561.8018 -3315.1399

(11,.,.) = 
   478.2086   637.5234   728.5378
   750.5375   939.7970  1026.9758
   841.2007  1076.6866  1166.6787

(12,.,.) = 
   446.3182   717.5488   951.3271
   514.7366   831.6805  1054.7803
   272.9021   588.7477   784.1703

(13,.,.) = 
 -2928.1338 -3095.5452 -2993.0579
 -2950.6443 -3105.0144 -2989.8945
 -2884.1436 -3029.3274 -2887.7190

(14,.,.) = 
  5044.5312  5344.6064  5148.1606
  5317.4717  5607.8730  5368.2866
  5261.2622  5574.6025  5304.3330

(15,.,.) = 
  3435.3701  3725.0525  3698.5354
  4003.0879  4389.4048  4339.1309
  4335.7925  4742.4204  4670.3467

(16,.,.) = 
 -2917.9502 -2997.9780 -2986.3660
 -3046.8027 -3160.8142 -3137.0588
 -3178.8418 -3320.7625 -3283.4653

(17,.,.) = 
 -7564.1450 -7959.9043 -7857.8726
 -8680.7646 -9186.2852 -9081.7568
 -9380.1973 -9947.8281 -9822.0137

(18,.,.) = 
  1637.6776  1586.2289  1490.1818
  1825.7606  1746.2794  1639.8152
  1821.0956  1727.8533  1624.8900
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3675.1025390625	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #6: time = 0.536622	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1884e+04   4.2519e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #7	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00023001/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1902.7057 -2141.4771 -2065.9602
 -2028.4698 -2259.7163 -2152.1624
 -1987.8743 -2176.2749 -2052.9658

(2,.,.) = 
  2848.8835  3011.4924  2900.6306
  3053.9060  3233.3494  3079.8704
  2948.2180  3095.7048  2927.7405

(3,.,.) = 
  3663.9326  3991.5044  3991.4961
  4494.4150  4907.3491  4899.9849
  4917.0430  5394.1519  5371.0771

(4,.,.) = 
  1047.2246  1167.0448  1144.9847
  1310.3899  1411.0365  1359.1572
  1425.1331  1479.0786  1386.6327

(5,.,.) = 
   744.9872   736.4886   658.0839
   731.4589   684.6720   578.6088
   748.0305   665.9807   557.4866

(6,.,.) = 
  1638.2749  1856.5671  1898.8003
  2011.6910  2318.9050  2362.2522
  2315.5022  2659.2300  2686.6421

(7,.,.) = 
 -2741.8804 -2912.5112 -2736.2744
 -2959.0957 -3109.4189 -2846.9905
 -2838.0291 -2913.9753 -2622.9368

(8,.,.) = 
  5738.4683  6147.8296  5905.9834
  6470.3105  6896.1938  6573.9868
  6735.5112  7107.7617  6736.9907

(9,.,.) = 
  2520.4636  3030.9590  3231.0000
  2903.9958  3428.7092  3557.0144
  3175.0312  3707.3130  3793.0271

(10,.,.) = 
 -3395.2485 -3353.5159 -3105.1252
 -3636.5269 -3601.6980 -3332.8416
 -3599.7361 -3555.8022 -3309.7446

(11,.,.) = 
   476.8152   635.8055   726.9634
   748.6150   937.6727  1025.0010
   839.3027  1074.4746  1164.5275

(12,.,.) = 
   445.6579   716.2490   949.6195
   513.4633   829.6606  1052.4441
   271.7096   586.8083   781.9382

(13,.,.) = 
 -2922.5547 -3089.7478 -2987.4287
 -2945.0210 -3098.9863 -2983.9573
 -2878.8530 -3023.7190 -2882.3323

(14,.,.) = 
  5034.3550  5334.1528  5138.5371
  5307.1401  5597.3667  5358.5317
  5251.6035  5564.6211  5295.1758

(15,.,.) = 
  3424.8220  3714.1128  3688.5505
  3991.6909  4377.5259  4328.3726
  4324.6934  4730.9277  4660.0728

(16,.,.) = 
 -2911.0579 -2991.1865 -2980.0835
 -3039.5137 -3153.6946 -3130.6216
 -3171.8057 -3313.7285 -3277.1204

(17,.,.) = 
 -7542.6001 -7938.5381 -7838.6328
 -8658.0332 -9163.4688 -9061.0576
 -9358.1260 -9925.6074 -9801.9824

(18,.,.) = 
  1634.6694  1583.4319  1487.5046
  1822.3203  1743.1851  1636.8146
  1817.6973  1724.7213  1621.8608
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3663.9326171875	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #7: time = 0.605199	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1783e+04   4.2447e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #8	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00096003/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1902.5171 -2141.4424 -2065.9834
 -2028.5792 -2259.9839 -2152.5493
 -1988.0574 -2176.6365 -2053.4033

(2,.,.) = 
  2848.6082  3011.3586  2900.7275
  3053.9536  3233.6843  3080.3596
  2948.3611  3096.1577  2928.3796

(3,.,.) = 
  3667.5222  3995.3655  3995.1240
  4498.4189  4911.7095  4904.0801
  4920.8755  5398.3184  5374.8789

(4,.,.) = 
  1048.9150  1168.9896  1146.8851
  1312.2073  1412.9861  1361.0243
  1426.8391  1480.8920  1388.2440

(5,.,.) = 
   746.0214   737.4989   658.8536
   732.5890   685.8362   579.5678
   749.0623   667.0776   558.5587

(6,.,.) = 
  1640.9558  1859.5568  1901.6605
  2014.6195  2322.1521  2365.4114
  2318.3655  2662.3928  2689.6824

(7,.,.) = 
 -2743.5071 -2914.3691 -2738.2756
 -2961.0400 -3111.6448 -2849.3293
 -2839.9080 -2916.1650 -2625.2510

(8,.,.) = 
  5742.7803  6152.4028  5910.2998
  6475.0181  6901.1436  6578.6450
  6739.8750  7112.4150  6741.2949

(9,.,.) = 
  2523.4207  3034.2993  3234.4614
  2907.4282  3432.5178  3560.8630
  3178.0544  3710.6272  3796.2815

(10,.,.) = 
 -3395.3708 -3353.7146 -3105.5027
 -3636.8020 -3602.1504 -3333.3391
 -3600.2153 -3556.5212 -3310.5588

(11,.,.) = 
   477.7914   636.8669   727.8287
   749.4415   938.5462  1025.7738
   840.0278  1075.3201  1165.3302

(12,.,.) = 
   445.4875   716.2879   949.7018
   513.4950   829.9919  1052.8129
   272.1418   587.5577   782.7398

(13,.,.) = 
 -2922.8682 -3090.1040 -2987.9495
 -2945.5986 -3099.7620 -2984.9993
 -2879.5789 -3024.6045 -2883.3672

(14,.,.) = 
  5035.6787  5335.6143  5140.0039
  5308.7490  5599.0825  5360.3564
  5253.3867  5566.5522  5297.1548

(15,.,.) = 
  3428.6282  3718.2920  3692.4893
  3995.7793  4381.9858  4332.5830
  4328.6602  4735.1899  4664.0039

(16,.,.) = 
 -2912.4045 -2992.7002 -2981.5752
 -3041.4832 -3155.7708 -3132.5999
 -3173.8979 -3316.0032 -3279.2793

(17,.,.) = 
 -7549.0518 -7945.2095 -7844.8813
 -8665.0312 -9170.7861 -9067.9473
 -9364.9580 -9932.7344 -9808.5430

(18,.,.) = 
  1634.7362  1583.4667  1487.5859
  1822.6188  1743.4202  1637.1779
  1818.2980  1725.3336  1622.6176
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3667.5222167969	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #8: time = 0.541849	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1821e+04   4.2486e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #9	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00016002/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 360
 640
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 640
 640
[torch.LongStorage of size 3]

x_start = 1 / y_start = 141	
img_means:size() vs img:size():	
   3
 360
 640
[torch.LongStorage of size 3]

   3
 360
 640
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6666666666667	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 360
 640
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6666666666667	
proposal_im_detect: scaled_img_size:	
    5
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1914.7814 -2155.0542 -2079.2310
 -2041.2119 -2273.9189 -2165.8831
 -2000.2106 -2189.7952 -2065.8904

(2,.,.) = 
  2866.8250  3030.5352  2919.1914
  3073.0723  3253.7090  3099.4226
  2966.5237  3114.9863  2946.1272

(3,.,.) = 
  3687.8447  4017.8342  4018.1748
  4522.7671  4938.5737  4931.5669
  4946.9722  5427.1997  5404.3687

(4,.,.) = 
  1053.9393  1174.5349  1152.4783
  1318.5629  1419.7638  1367.6882
  1433.5878  1487.8275  1395.0020

(5,.,.) = 
   749.5811   741.1986   662.4669
   735.7966   688.9730   582.4298
   752.4679   670.0916   561.0182

(6,.,.) = 
  1648.4956  1868.2308  1910.8871
  2023.9167  2333.0759  2376.8472
  2329.3259  2675.0654  2702.7917

(7,.,.) = 
 -2758.3171 -2930.2222 -2753.1240
 -2976.7251 -3128.0840 -2864.2493
 -2854.7683 -2931.3589 -2638.7156

(8,.,.) = 
  5774.0425  6186.3022  5943.5747
  6509.5854  6938.3667  6614.6904
  6775.6533  7150.3867  6777.8516

(9,.,.) = 
  2536.4941  3050.2837  3251.7246
  2921.6555  3449.6514  3578.9966
  3193.7268  3729.3149  3815.8499

(10,.,.) = 
 -3417.2810 -3375.5767 -3125.9316
 -3659.7419 -3624.9653 -3354.7498
 -3622.2729 -3578.3235 -3330.9993

(11,.,.) = 
   479.5946   639.5636   731.3566
   753.1462   943.2889  1031.1748
   844.1958  1080.6666  1171.2509

(12,.,.) = 
   448.4501   720.5776   955.4440
   516.8175   834.7756  1058.9421
   273.6184   590.4753   786.8373

(13,.,.) = 
 -2940.4456 -3108.8596 -3006.1199
 -2962.5891 -3117.6721 -3002.0576
 -2895.8843 -3041.7522 -2899.6016

(14,.,.) = 
  5065.5288  5367.4775  5171.0259
  5339.4741  5631.7314  5391.7529
  5283.1870  5598.3555  5327.5757

(15,.,.) = 
  3446.4253  3737.6458  3712.2234
  4016.1228  4404.4209  4355.2749
  4350.6294  4759.2896  4688.3120

(16,.,.) = 
 -2930.1711 -3011.0977 -3000.1223
 -3058.8481 -3173.9800 -3150.9363
 -3191.2859 -3334.2588 -3297.5632

(17,.,.) = 
 -7591.2202 -7990.2319 -7890.3955
 -8712.1641 -9221.2031 -9118.9238
 -9415.0381 -9986.3428 -9862.6709

(18,.,.) = 
  1645.1891  1593.8723  1497.4626
  1833.8884  1754.4644  1647.4875
  1828.9928  1735.6240  1632.1718
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3687.8447265625	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #9: time = 0.423943	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   6.4000e+02   6.4000e+02
        -inf         -inf   3.6077e+04   2.1315e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #10	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00045000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1907.7515 -2147.3054 -2071.3831
 -2034.5514 -2266.5359 -2158.5830
 -1994.1536 -2183.2263 -2059.4460

(2,.,.) = 
  2856.5090  3019.5649  2908.4343
  3062.7583  3242.9509  3088.9570
  2957.1077  3105.3440  2936.9263

(3,.,.) = 
  3681.0703  4009.8958  4009.2004
  4515.0464  4929.5488  4921.3354
  4938.9658  5417.7788  5393.5791

(4,.,.) = 
  1053.4833  1174.0093  1151.7301
  1317.6143  1418.7750  1366.5258
  1432.5270  1486.7937  1393.6432

(5,.,.) = 
   749.1882   740.5727   661.5266
   735.7816   688.9510   582.2476
   752.2822   670.1668   561.3669

(6,.,.) = 
  1648.0880  1867.5720  1909.6218
  2023.2314  2331.8499  2374.9585
  2327.9263  2673.1228  2700.1453

(7,.,.) = 
 -2753.2283 -2924.5454 -2747.8145
 -2971.7322 -3122.7744 -2859.4727
 -2850.3706 -2926.8679 -2634.9082

(8,.,.) = 
  5763.3589  6174.0127  5930.6196
  6498.2998  6925.4658  6601.2231
  6763.9795  7137.3867  6764.3193

(9,.,.) = 
  2533.0681  3045.6787  3246.4836
  2918.8518  3445.6733  3574.3347
  3190.3030  3724.5073  3810.2192

(10,.,.) = 
 -3405.1121 -3363.2134 -3114.1882
 -3647.5286 -3612.6985 -3342.9097
 -3611.2837 -3567.4399 -3320.6108

(11,.,.) = 
   480.0951   639.6901   730.6599
   752.3306   941.9376  1029.1860
   843.1107  1079.0742  1169.1688

(12,.,.) = 
   446.5116   718.1627   952.0744
   514.8237   832.3493  1055.6575
   273.1568   589.6374   785.3148

(13,.,.) = 
 -2931.5830 -3099.1567 -2996.6602
 -2954.9773 -3109.5432 -2994.4802
 -2889.0088 -3034.3987 -2892.6770

(14,.,.) = 
  5051.3672  5351.9355  5155.3740
  5325.7402  5616.6343  5376.9004
  5270.6450  5584.4678  5313.9082

(15,.,.) = 
  3441.9465  3732.5571  3706.2568
  4011.2205  4398.6128  4348.4932
  4345.1489  4752.8530  4680.7285

(16,.,.) = 
 -2921.5859 -3002.0012 -2990.6458
 -3051.7632 -3166.2246 -3142.7280
 -3184.9465 -3327.4343 -3290.3286

(17,.,.) = 
 -7576.2393 -7973.3398 -7871.9102
 -8696.3174 -9203.3857 -9099.4062
 -9398.6260 -9967.8096 -9842.2471

(18,.,.) = 
  1639.5170  1587.9543  1491.7318
  1828.1575  1748.5479  1641.9723
  1824.1255  1730.7784  1627.7496
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3681.0703125	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #10: time = 0.543803	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2065e+04   4.2631e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #11	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00060006/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1909.8394 -2149.4355 -2073.5488
 -2036.0911 -2268.1208 -2160.1184
 -1995.2666 -2184.3354 -2060.4778

(2,.,.) = 
  2859.3938  3022.5420  2911.2363
  3065.2183  3245.3267  3091.1504
  2958.9824  3107.0295  2938.3396

(3,.,.) = 
  3680.3896  4009.0540  4008.4790
  4513.5386  4927.8828  4919.8711
  4936.7217  5415.4082  5391.5806

(4,.,.) = 
  1052.1656  1172.4016  1150.1166
  1316.2595  1417.1064  1364.8413
  1431.0430  1485.0680  1392.1262

(5,.,.) = 
   748.4995   739.9702   661.2021
   734.7485   687.8743   581.4163
   751.2365   668.9415   560.0685

(6,.,.) = 
  1645.8807  1865.0968  1907.2188
  2020.5938  2329.0044  2372.1990
  2325.1440  2670.0703  2697.2576

(7,.,.) = 
 -2752.3381 -2923.7358 -2746.9412
 -2970.4463 -3121.4087 -2857.9990
 -2848.7964 -2925.1238 -2632.9900

(8,.,.) = 
  5761.7793  6172.5181  5929.4434
  6495.8369  6923.0986  6599.2041
  6761.1255  7134.5356  6761.8936

(9,.,.) = 
  2531.5376  3043.8799  3244.4011
  2916.2773  3442.7852  3571.2681
  3187.6475  3721.7163  3807.4170

(10,.,.) = 
 -3408.4009 -3366.5142 -3117.1348
 -3650.4194 -3615.4624 -3345.4778
 -3613.2925 -3569.2024 -3322.0698

(11,.,.) = 
   478.7391   638.2759   729.6329
   751.5765   941.1644  1028.6415
   842.3461  1078.2311  1168.4666

(12,.,.) = 
   446.9389   718.4328   952.6256
   515.2839   832.5473  1056.0275
   272.8827   589.0916   784.8792

(13,.,.) = 
 -2933.1802 -3100.9626 -2998.2678
 -2955.5598 -3110.1621 -2994.7207
 -2889.2334 -3034.6125 -2892.6284

(14,.,.) = 
  5053.2686  5354.0537  5157.5215
  5326.8018  5617.9077  5378.0464
  5270.9229  5584.8950  5314.2251

(15,.,.) = 
  3439.8008  3730.1194  3704.0251
  4008.4146  4395.5537  4345.7139
  4342.0312  4749.5371  4677.8623

(16,.,.) = 
 -2923.3835 -3003.7192 -2992.2275
 -3052.1992 -3166.6479 -3143.0537
 -3184.5410 -3326.8286 -3289.6287

(17,.,.) = 
 -7575.3105 -7972.3877 -7871.1255
 -8693.9424 -9200.8594 -9097.0918
 -9395.1104 -9964.2090 -9839.0566

(18,.,.) = 
  1640.8983  1589.4980  1493.2374
  1829.2922  1749.8049  1643.0282
  1824.5846  1731.2166  1627.9230
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3680.3896484375	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #11: time = 0.555818	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2025e+04   4.2590e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #12	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00006000/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1914.8147  -2155.4258  -2079.8862
  -2042.1161  -2275.3909  -2167.7725
  -2002.0637  -2192.6296  -2068.9380

(2,.,.) = 
   2866.8982   3031.0815   2920.4922
   3074.1030   3255.5349   3101.6560
   2968.2112   3117.7200   2949.3550

(3,.,.) = 
   3701.5935   4032.2209   4031.5076
   4538.0039   4955.0366   4946.9478
   4962.4170   5443.8599   5419.7695

(4,.,.) = 
   1059.0153   1180.2571   1157.9065
   1325.0303   1426.4545   1374.0627
   1440.2532   1494.9633   1401.8915

(5,.,.) = 
    753.8390    745.6716    666.5447
    740.3551    694.0019    587.0622
    757.1033    675.0696    565.8613

(6,.,.) = 
   1657.0947   1877.9072   1919.9913
   2033.1814   2343.4873   2386.7407
   2338.4519   2685.2629   2712.4541

(7,.,.) = 
  -2763.1008  -2935.8984  -2759.7302
  -2982.6082  -3135.1738  -2871.9956
  -2861.1423  -2939.0742  -2647.5430

(8,.,.) = 
   5787.9888   6200.8755   5957.9180
   6525.5542   6955.4448   6631.1294
   6792.3521   7168.5645   6795.5908

(9,.,.) = 
   2545.7993   3059.9343   3261.1025
   2932.6621   3461.1206   3590.0540
   3204.4292   3740.6084   3826.9207

(10,.,.) = 
  -3421.5100  -3380.1870  -3131.0623
  -3665.1536  -3630.7856  -3360.8809
  -3628.5986  -3585.3345  -3338.2380

(11,.,.) = 
    481.3450    641.3019    732.6190
    755.1319    945.1354   1032.6235
    845.4040   1081.9993   1172.3887

(12,.,.) = 
    446.9890    719.2345    954.1993
    515.9251    834.2543   1058.6418
    273.8159    591.3591    788.3425

(13,.,.) = 
  -2941.0559  -3109.4712  -3006.7996
  -2963.4048  -3119.0757  -3003.7510
  -2898.0115  -3044.4563  -2902.2671

(14,.,.) = 
   5069.8506   5371.7500   5175.2080
   5345.1426   5637.4033   5397.5747
   5290.8296   5606.4312   5335.7256

(15,.,.) = 
   3459.2922   3751.7798   3725.7461
   4030.6721   4420.3652   4370.5806
   4365.9199   4776.1621   4704.4429

(16,.,.) = 
  -2938.1792  -3019.1958  -3007.4365
  -3069.1885  -3184.1470  -3159.8772
  -3202.4468  -3345.4106  -3307.3831

(17,.,.) = 
  -7614.4971  -8014.2192  -7912.5698
  -8739.2803  -9249.2158  -9145.1641
  -9443.6035 -10016.0342  -9890.1318

(18,.,.) = 
   1647.2429   1595.9286   1499.9745
   1836.7614   1757.0903   1650.6418
   1832.5555   1739.0217   1636.1312
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3701.5935058594	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #12: time = 0.526461	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2442e+04   4.2904e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #13	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00018002/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1915.7872 -2156.2549 -2080.2383
 -2042.4819 -2275.3455 -2167.2693
 -2001.1970 -2190.9617 -2067.1421

(2,.,.) = 
  2868.2119  3032.1213  2920.7407
  3074.5222  3255.7053  3101.3301
  2967.0696  3116.3218  2947.5979

(3,.,.) = 
  3692.6768  4022.4539  4022.1396
  4527.1582  4942.7222  4935.2227
  4949.8945  5429.7759  5406.6289

(4,.,.) = 
  1055.8574  1176.4247  1154.1212
  1321.0255  1421.9473  1369.5476
  1436.2621  1490.0825  1396.9404

(5,.,.) = 
   751.2541   742.7250   663.7543
   737.4672   690.5919   583.9961
   753.8669   671.5461   562.8564

(6,.,.) = 
  1650.9546  1871.0490  1913.4496
  2025.7179  2335.6326  2379.5630
  2329.9463  2676.6653  2704.8354

(7,.,.) = 
 -2759.8552 -2931.9453 -2754.7661
 -2977.5127 -3129.4905 -2865.7305
 -2853.7961 -2931.3252 -2639.3418

(8,.,.) = 
  5779.3325  6191.5757  5948.1084
  6513.6104  6942.6206  6618.4351
  6776.3535  7151.6367  6779.3921

(9,.,.) = 
  2539.2524  3053.1189  3254.3269
  2923.9277  3451.9812  3581.2759
  3194.0208  3729.6807  3816.4763

(10,.,.) = 
 -3419.0437 -3377.2241 -3127.1875
 -3660.6248 -3626.2942 -3355.9119
 -3621.0757 -3578.2869 -3331.6655

(11,.,.) = 
   480.0004   640.0840   731.6957
   753.3229   943.5781  1031.2540
   843.8541  1080.5770  1171.0448

(12,.,.) = 
   448.2121   720.5045   955.3994
   517.3256   835.4860  1059.5024
   275.0689   592.2272   788.3661

(13,.,.) = 
 -2942.0562 -3110.5776 -3007.5403
 -2963.5339 -3119.2407 -3003.8008
 -2895.0278 -3041.7991 -2900.2493

(14,.,.) = 
  5068.8857  5370.8604  5173.7173
  5341.6821  5634.4551  5394.2251
  5282.5640  5598.8267  5328.4180

(15,.,.) = 
  3450.8665  3742.1675  3716.1580
  4019.9238  4408.4722  4358.9399
  4352.6128  4761.6011  4690.5288

(16,.,.) = 
 -2933.6279 -3014.3882 -3002.7605
 -3062.5315 -3177.6414 -3153.9736
 -3193.8486 -3337.1829 -3300.1797

(17,.,.) = 
 -7601.1157 -7999.6079 -7898.2778
 -8721.9248 -9230.6885 -9127.1621
 -9422.3477 -9993.6396 -9869.1611

(18,.,.) = 
  1646.1799  1594.6416  1498.1591
  1834.6792  1755.0771  1648.2150
  1829.2562  1736.0685  1633.0145
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3692.6767578125	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #13: time = 0.558648	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2027e+04   4.2579e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #14	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00012002/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 480
 480
[torch.LongStorage of size 3]

x_start = 1 / y_start = 61	
img_means:size() vs img:size():	
   3
 360
 480
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6666666666667	
(orep_img_for_blob) img size after scaling:	
   3
 600
 800
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x97
  2 : CudaTensor - size: 18x72x97
  3 : CudaTensor - size: 18x70x95
  4 : CudaTensor - size: 18x68x93
  5 : CudaTensor - size: 256x74x99
}
proposal_im_deteect: img_blob size:    3
 600
 800
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 360
 480
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6666666666667	
proposal_im_detect: scaled_img_size:	
   5
 600
 800
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1927.8406  -2171.0947  -2095.2234
  -2058.3823  -2294.0144  -2186.1345
  -2019.4215  -2212.0618  -2087.9788

(2,.,.) = 
   2886.4695   3052.7241   2942.4553
   3097.0527   3281.5449   3127.4722
   2991.7043   3144.4065   2976.0210

(3,.,.) = 
   3748.5662   4083.7432   4082.8057
   4595.1582   5017.5869   5009.0713
   5023.6465   5510.7861   5485.3281

(4,.,.) = 
   1077.8690   1201.4865   1178.8384
   1346.4492   1449.9286   1396.7880
   1462.3182   1518.2897   1423.3124

(5,.,.) = 
    764.7764    756.3688    675.7806
    751.6437    705.2328    597.0167
    768.0767    686.0489    576.7799

(6,.,.) = 
   1683.9877   1908.5592   1950.7756
   2064.5444   2379.3093   2422.7429
   2372.3335   2724.2524   2751.3975

(7,.,.) = 
  -2793.0393  -2968.0283  -2791.0344
  -3015.2007  -3170.3477  -2905.4973
  -2892.4443  -2972.6021  -2679.1360

(8,.,.) = 
   5857.0015   6275.0205   6029.4800
   6602.5049   7037.5649   6709.6909
   6869.6509   7250.5962   6873.2305

(9,.,.) = 
   2579.7163   3100.6240   3304.9436
   2973.1931   3508.4182   3639.4539
   3245.8521   3788.1877   3875.5569

(10,.,.) = 
  -3446.4255  -3405.8479  -3156.3389
  -3692.4209  -3659.4736  -3388.3088
  -3656.9678  -3615.4587  -3368.0725

(11,.,.) = 
    491.9641    654.0715    744.7960
    765.9276    957.9674   1045.3391
    856.6111   1095.9453   1186.4320

(12,.,.) = 
    449.4622    725.2399    961.6521
    519.5136    841.9271   1067.8981
    278.3553    600.0922    798.3896

(13,.,.) = 
  -2964.4492  -3134.7654  -3032.8037
  -2989.7610  -3148.1040  -3034.2053
  -2924.3811  -3073.3276  -2931.8877

(14,.,.) = 
   5115.9023   5421.7808   5224.4292
   5395.1890   5691.2300   5450.9722
   5341.2236   5660.8823   5389.3027

(15,.,.) = 
   3507.5344   3804.7437   3777.7520
   4085.3137   4480.3237   4429.0684
   4422.4531   4837.7437   4763.7305

(16,.,.) = 
  -2966.2935  -3049.3135  -3038.2649
  -3102.4993  -3219.5098  -3195.4990
  -3238.1724  -3384.1631  -3346.2646

(17,.,.) = 
  -7708.8418  -8114.2725  -8011.6030
  -8846.8887  -9364.0410  -9259.1045
  -9557.2832 -10137.2158 -10009.4922

(18,.,.) = 
   1659.7676   1608.1661   1511.9252
   1851.6066   1771.4711   1665.0952
   1849.0728   1755.3866   1652.7406
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 95
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 19950
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 95
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 95
[torch.LongStorage of size 2]

shift_y size:	
 70
 95
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6650
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 19950
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  19950
[torch.LongStorage of size 1]
	
  first line: 3748.5661621094	
(fast bbox transform) src_w size:  19950
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 19950
     4
[torch.LongStorage of size 2]

scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 19950
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 53200
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13300
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13300
[torch.LongStorage of size 1]

test img #14: time = 0.34294	
(proposal_test:boxes_filter) boxes & scores size:	
 13300
     4
[torch.LongStorage of size 2]

 13300
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 953
   3
[torch.LongTensor of size 2]

mask size:	
 13300
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   4.8000e+02   4.8000e+02
        -inf         -inf   3.6579e+04   2.1552e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #15	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00033003/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 358
 640
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 640
 640
[torch.LongStorage of size 3]

x_start = 1 / y_start = 142	
img_means:size() vs img:size():	
   3
 358
 640
[torch.LongStorage of size 3]

   3
 358
 640
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6759776536313	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1072
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x131
  2 : CudaTensor - size: 18x72x131
  3 : CudaTensor - size: 18x70x129
  4 : CudaTensor - size: 18x68x127
  5 : CudaTensor - size: 256x74x133
}
proposal_im_deteect: img_blob size:     3
  600
 1072
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 358
 640
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6759776536313	
proposal_im_detect: scaled_img_size:	
    5
  600
 1073
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1908.2115 -2147.5286 -2071.5955
 -2034.2793 -2266.0232 -2157.9890
 -1993.4688 -2182.2317 -2058.3782

(2,.,.) = 
  2857.0493  3019.9241  2908.4480
  3062.6497  3242.3928  3088.1135
  2956.5342  3104.2388  2935.4751

(3,.,.) = 
  3674.8372  4002.9329  4002.2668
  4507.0337  4920.6206  4912.5596
  4929.9785  5407.8931  5384.1343

(4,.,.) = 
  1050.2316  1170.2379  1147.9546
  1313.8945  1414.5770  1362.3533
  1428.6416  1482.5134  1389.6686

(5,.,.) = 
   747.3372   738.8044   660.0359
   733.5950   686.6829   580.2485
   750.1573   667.8743   558.9822

(6,.,.) = 
  1642.9484  1861.5767  1903.6272
  2017.1876  2324.9473  2368.0889
  2321.5222  2665.8413  2693.0178

(7,.,.) = 
 -2749.4426 -2920.5659 -2743.6750
 -2967.2100 -3117.9038 -2854.5520
 -2845.6792 -2921.8215 -2629.8093

(8,.,.) = 
  5754.7451  6164.8960  5921.8057
  6487.9590  6914.5469  6590.8052
  6753.1187  7125.9023  6753.5376

(9,.,.) = 
  2527.9138  3039.6328  3239.8638
  2912.0103  3437.9092  3566.2419
  3183.2947  3716.7761  3802.4443

(10,.,.) = 
 -3405.1304 -3362.9990 -3113.5247
 -3646.8071 -3611.6128 -3341.6516
 -3609.5332 -3565.2532 -3318.2178

(11,.,.) = 
   477.9080   637.2498   728.6244
   750.4459   939.8836  1027.3409
   841.2750  1076.9536  1167.1327

(12,.,.) = 
   446.7238   717.9885   952.0213
   514.8892   831.8646  1055.2047
   272.5735   588.4594   784.0584

(13,.,.) = 
 -2930.9172 -3098.5022 -2995.6558
 -2953.2898 -3107.6621 -2992.0637
 -2886.8687 -3032.0720 -2890.0605

(14,.,.) = 
  5048.7080  5349.0581  5152.3726
  5321.9189  5612.6431  5372.6641
  5265.8438  5579.4321  5308.7715

(15,.,.) = 
  3434.6099  3724.3083  3698.1863
  4002.5039  4388.9229  4339.1460
  4335.8604  4742.6602  4671.1567

(16,.,.) = 
 -2919.7446 -2999.7739 -2988.0818
 -3048.1646 -3162.3311 -3138.6829
 -3180.3745 -3322.3867 -3285.2068

(17,.,.) = 
 -7564.8682 -7961.0835 -7859.6890
 -8682.1660 -9188.0713 -9084.1631
 -9382.7627 -9950.8027 -9825.7061

(18,.,.) = 
  1639.3538  1587.8850  1491.4515
  1827.4407  1747.9523  1641.0371
  1822.6390  1729.2970  1625.9496
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 129
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 27090
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 129
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 129
[torch.LongStorage of size 2]

shift_y size:	
  70
 129
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 9030
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 27090
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 27090
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 27090
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  27090
[torch.LongStorage of size 1]
	
  first line: 3674.8371582031	
(fast bbox transform) src_w size:  27090
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 27090
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 27090
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 27090
     4
[torch.LongStorage of size 2]

scores size:	
 27090
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 27090
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 27090
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 27090
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 72240
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 18060
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 18060
[torch.LongStorage of size 1]

test img #15: time = 0.432714	
(proposal_test:boxes_filter) boxes & scores size:	
 18060
     4
[torch.LongStorage of size 2]

 18060
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1809
    3
[torch.LongTensor of size 2]

mask size:	
 18060
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   6.4000e+02   6.4000e+02
        -inf         -inf   3.5722e+04   2.1044e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #16	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0001/ILSVRC2015_train_00217000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 480
 480
[torch.LongStorage of size 3]

x_start = 1 / y_start = 61	
img_means:size() vs img:size():	
   3
 360
 480
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6666666666667	
(orep_img_for_blob) img size after scaling:	
   3
 600
 800
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x97
  2 : CudaTensor - size: 18x72x97
  3 : CudaTensor - size: 18x70x95
  4 : CudaTensor - size: 18x68x93
  5 : CudaTensor - size: 256x74x99
}
proposal_im_deteect: img_blob size:    3
 600
 800
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 360
 480
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6666666666667	
proposal_im_detect: scaled_img_size:	
   5
 600
 800
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1925.2622  -2168.4490  -2092.9236
  -2055.8687  -2291.5813  -2184.0667
  -2017.0273  -2209.8086  -2085.8992

(2,.,.) = 
   2882.7825   3049.0898   2939.3440
   3093.3669   3277.9668   3124.2200
   2988.3059   3140.8970   2972.7979

(3,.,.) = 
   3749.8418   4085.1538   4083.9937
   4596.3843   5019.2998   5010.7339
   5024.2275   5512.0269   5486.5991

(4,.,.) = 
   1078.9529   1202.9064   1180.2616
   1347.6660   1451.4938   1398.4977
   1463.0334   1519.6061   1424.9197

(5,.,.) = 
    765.3937    757.0986    676.4022
    752.1034    706.0494    597.8076
    768.0579    686.4131    577.2087

(6,.,.) = 
   1685.6558   1910.4626   1952.5309
   2066.2314   2380.9878   2424.2358
   2373.4219   2725.2490   2752.1165

(7,.,.) = 
  -2791.9248  -2967.1655  -2790.8481
  -3014.3240  -3169.6978  -2905.3323
  -2891.7400  -2971.9023  -2678.7971

(8,.,.) = 
   5856.2070   6274.3696   6029.2744
   6602.0610   7037.5352   6710.0728
   6869.0112   7250.5791   6873.6382

(9,.,.) = 
   2580.9226   3101.5996   3305.7832
   2975.0513   3510.2397   3641.2026
   3247.3640   3789.5928   3876.8025

(10,.,.) = 
  -3444.0710  -3403.8311  -3154.9536
  -3690.6177  -3657.8489  -3387.1604
  -3655.8442  -3614.3196  -3367.0586

(11,.,.) = 
    492.3107    654.3161    744.8253
    766.1026    958.0598   1045.3337
    856.3661   1095.6379   1186.2517

(12,.,.) = 
    448.2395    723.7615    959.9405
    518.1589    840.1888   1066.0341
    277.1100    598.4716    796.8901

(13,.,.) = 
  -2961.0857  -3131.2649  -3029.6028
  -2986.7183  -3144.7944  -3031.0957
  -2921.8555  -3070.4551  -2928.8594

(14,.,.) = 
   5111.5654   5417.3018   5220.3652
   5391.5093   5687.1108   5447.2573
   5338.3262   5657.5981   5386.2959

(15,.,.) = 
   3508.8972   3806.6052   3779.6331
   4086.8604   4482.4590   4431.3276
   4423.6064   4839.5796   4765.7227

(16,.,.) = 
  -2965.8308  -3049.0115  -3037.8892
  -3102.8701  -3219.8918  -3195.7534
  -3238.4231  -3384.4734  -3346.4666

(17,.,.) = 
  -7709.2598  -8115.1133  -8012.2046
  -8847.7383  -9365.5732  -9260.7012
  -9557.0840 -10138.0127 -10010.4287

(18,.,.) = 
   1658.6616   1607.1913   1511.1991
   1850.6584   1770.6349   1664.4854
   1848.5366   1754.9121   1652.3860
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 95
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 19950
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 95
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 95
[torch.LongStorage of size 2]

shift_y size:	
 70
 95
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6650
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 19950
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  19950
[torch.LongStorage of size 1]
	
  first line: 3749.841796875	
(fast bbox transform) src_w size:  19950
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 19950
     4
[torch.LongStorage of size 2]

scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 19950
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 53200
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13300
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13300
[torch.LongStorage of size 1]

test img #16: time = 0.352244	
(proposal_test:boxes_filter) boxes & scores size:	
 13300
     4
[torch.LongStorage of size 2]

 13300
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 953
   3
[torch.LongTensor of size 2]

mask size:	
 13300
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   4.8000e+02   4.8000e+02
        -inf         -inf   3.6578e+04   2.1578e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #17	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00069013/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1910.4241 -2150.0706 -2074.0330
 -2037.0513 -2269.1294 -2160.9634
 -1996.4038 -2185.5198 -2061.4973

(2,.,.) = 
  2860.3577  3023.4060  2911.9502
  3066.5652  3246.6646  3092.2705
  2960.5142  3108.6094  2939.7222

(3,.,.) = 
  3683.4412  4012.4028  4011.6763
  4517.5015  4932.1484  4923.9019
  4941.2285  5420.2236  5396.0303

(4,.,.) = 
  1053.3986  1173.8407  1151.6169
  1317.7006  1418.7533  1366.5535
  1432.6721  1486.8024  1393.8187

(5,.,.) = 
   749.6678   741.1125   661.9193
   736.0740   689.2222   582.3561
   752.6135   670.3636   561.2070

(6,.,.) = 
  1647.9938  1867.4395  1909.5428
  2023.1058  2331.8276  2374.9934
  2327.8701  2673.1506  2700.2258

(7,.,.) = 
 -2754.9807 -2926.3054 -2749.2268
 -2973.4521 -3124.4082 -2860.6692
 -2851.8030 -2928.1577 -2635.7334

(8,.,.) = 
  5766.8887  6177.6626  5934.0190
  6501.8271  6929.1948  6604.6265
  6767.3979  7140.9326  6767.6011

(9,.,.) = 
  2534.1448  3046.6985  3247.4319
  2919.6267  3446.3313  3574.9160
  3191.1824  3725.3542  3810.9980

(10,.,.) = 
 -3409.7078 -3367.5444 -3118.0366
 -3652.0654 -3616.8977 -3346.7083
 -3615.1841 -3571.0095 -3323.7854

(11,.,.) = 
   479.4853   639.1516   730.4888
   752.2477   941.9760  1029.4772
   843.0361  1079.1444  1169.4093

(12,.,.) = 
   446.9157   718.5977   952.9983
   515.3114   832.8175  1056.5178
   273.0632   589.5187   785.4677

(13,.,.) = 
 -2934.7622 -3102.3271 -2999.4377
 -2957.5974 -3112.0806 -2996.4807
 -2891.3286 -3036.6509 -2894.4775

(14,.,.) = 
  5056.2861  5356.8174  5159.9194
  5330.3921  5621.2461  5381.0454
  5274.7231  5588.5586  5317.5679

(15,.,.) = 
  3443.2310  3733.7773  3707.5662
  4012.5347  4399.9541  4349.9502
  4346.5015  4754.2554  4682.3164

(16,.,.) = 
 -2924.9009 -3005.1121 -2993.5610
 -3054.4089 -3168.7341 -3145.0134
 -3187.1953 -3329.4375 -3292.0652

(17,.,.) = 
 -7581.1191 -7978.3208 -7876.8755
 -8701.1748 -9208.2686 -9104.2637
 -9403.2549 -9972.5127 -9846.9932

(18,.,.) = 
  1641.6456  1590.0544  1493.6228
  1830.2611  1750.5929  1643.7205
  1825.8086  1732.3223  1628.9866
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3683.4411621094	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #17: time = 0.531303	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2089e+04   4.2636e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #18	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00051008/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1908.2932 -2147.7473 -2071.7703
 -2034.6727 -2266.5227 -2158.4253
 -1993.9733 -2182.7998 -2058.9016

(2,.,.) = 
  2857.2068  3020.1548  2908.8376
  3063.0906  3243.0342  3088.8604
  2957.1316  3105.0117  2936.3315

(3,.,.) = 
  3677.5354  4006.1345  4005.6973
  4510.7129  4924.8745  4917.0073
  4934.2329  5412.7266  5389.0161

(4,.,.) = 
  1051.7206  1171.9979  1149.7715
  1315.5369  1416.4889  1364.3198
  1430.3931  1484.4303  1391.4473

(5,.,.) = 
   748.0040   739.4031   660.4962
   734.4313   687.4938   580.9019
   750.8969   668.6185   559.7446

(6,.,.) = 
  1645.2639  1864.3936  1906.5786
  2019.9689  2328.2583  2371.5493
  2324.5190  2669.3757  2696.6355

(7,.,.) = 
 -2751.5588 -2922.6267 -2745.6560
 -2969.6589 -3120.3450 -2856.8643
 -2848.1223 -2924.2178 -2632.0002

(8,.,.) = 
  5759.1631  6169.5825  5926.3154
  6493.2710  6920.1519  6596.1851
  6758.6875  7131.7412  6759.0078

(9,.,.) = 
  2530.2834  3042.5222  3243.1455
  2915.2412  3441.6460  3570.2205
  3186.6831  3720.5371  3806.2581

(10,.,.) = 
 -3405.2080 -3363.1252 -3113.8394
 -3647.2620 -3612.1985 -3342.2561
 -3610.5198 -3566.3750 -3319.3987

(11,.,.) = 
   479.0639   638.6158   729.8552
   751.4506   941.0713  1028.5265
   842.3517  1078.2622  1168.5123

(12,.,.) = 
   446.7550   718.2567   952.2926
   514.9079   832.1885  1055.5696
   272.7517   588.9222   784.5412

(13,.,.) = 
 -2931.7148 -3099.2134 -2996.5149
 -2954.6768 -3108.9761 -2993.5764
 -2888.3669 -3033.4890 -2891.5586

(14,.,.) = 
  5050.5327  5350.9849  5154.3799
  5324.3340  5615.1128  5375.2065
  5268.6279  5582.2739  5311.5957

(15,.,.) = 
  3438.0334  3728.2139  3702.1006
  4006.6440  4393.5903  4343.7363
  4340.2734  4747.5669  4675.8447

(16,.,.) = 
 -2920.3735 -3000.6814 -2989.3857
 -3049.5630 -3163.9685 -3140.6213
 -3182.2397 -3324.5642 -3287.6484

(17,.,.) = 
 -7570.0117 -7966.8262 -7865.8252
 -8688.6592 -9195.3281 -9091.7910
 -9390.2266 -9959.0430 -9834.1445

(18,.,.) = 
  1639.4115  1587.8899  1491.5646
  1827.7764  1748.2526  1641.5167
  1823.3600  1730.0245  1626.8196
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3677.5354003906	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #18: time = 0.525144	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1999e+04   4.2574e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #19	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00017000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1906.6240 -2145.7209 -2069.9282
 -2032.4031 -2263.9526 -2156.0659
 -1991.5315 -2180.1367 -2056.4456

(2,.,.) = 
  2854.5955  3017.3347  2906.0505
  3059.8384  3239.3799  3085.3542
  2953.6482  3101.1443  2932.5977

(3,.,.) = 
  3670.8735  3998.7329  3998.3101
  4502.0757  4915.3237  4907.5146
  4924.5254  5401.9463  5378.3975

(4,.,.) = 
  1048.8234  1168.6925  1146.5052
  1312.3223  1412.8762  1360.7701
  1427.0031  1480.7751  1388.1245

(5,.,.) = 
   746.3738   737.8969   659.3179
   732.6380   685.7842   579.5148
   749.2170   666.9672   558.1160

(6,.,.) = 
  1640.8363  1859.2999  1901.4152
  2014.6073  2322.1196  2365.3176
  2318.5916  2662.5527  2689.7800

(7,.,.) = 
 -2746.3372 -2917.1792 -2740.4812
 -2963.7793 -3114.2026 -2851.1387
 -2842.2761 -2918.1941 -2626.4822

(8,.,.) = 
  5748.2612  6157.9854  5915.3877
  6480.6255  6906.7925  6583.6011
  6745.5537  7117.8994  6746.0674

(9,.,.) = 
  2524.8728  3035.9277  3235.9434
  2908.4155  3433.6465  3561.8240
  3179.4724  3712.2915  3797.8494

(10,.,.) = 
 -3402.2739 -3360.2224 -3111.0239
 -3643.6675 -3608.4624 -3338.7795
 -3606.2854 -3561.9373 -3315.0581

(11,.,.) = 
   477.1036   636.2510   727.6199
   749.5677   938.8011  1026.2424
   840.2578  1075.6588  1165.8217

(12,.,.) = 
   446.2946   717.1551   950.9925
   514.3677   830.9265  1054.0973
   272.0373   587.5168   783.0223

(13,.,.) = 
 -2928.0671 -3095.4365 -2992.6526
 -2950.1140 -3104.2151 -2988.6497
 -2883.6760 -3028.6323 -2886.6953

(14,.,.) = 
  5043.5928  5343.6118  5147.2373
  5316.3452  5606.7217  5367.0020
  5260.2173  5573.3999  5303.0166

(15,.,.) = 
  3430.5522  3719.9905  3694.0864
  3997.8230  4383.8936  4334.3213
  4330.8735  4737.2671  4665.9692

(16,.,.) = 
 -2917.0737 -2997.0732 -2985.5198
 -3045.1292 -3159.1907 -3135.6270
 -3177.0781 -3318.8552 -3281.7131

(17,.,.) = 
 -7556.5112 -7952.5679 -7851.7178
 -8672.5312 -9178.0479 -9074.5791
 -9372.4473 -9939.9189 -9815.1338

(18,.,.) = 
  1637.9124  1586.5182  1490.2811
  1825.7622  1746.3438  1639.5946
  1820.8021  1727.4910  1624.2310
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3670.8735351562	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #19: time = 0.563364	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1859e+04   4.2482e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #20	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00008002/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1915.1350 -2155.4243 -2079.3857
 -2041.8458 -2274.5732 -2166.3491
 -2001.0525 -2190.7102 -2066.5774

(2,.,.) = 
  2867.2991  3030.9622  2919.3992
  3073.8342  3254.5127  3099.9541
  2967.3955  3115.9573  2946.8555

(3,.,.) = 
  3691.7981  4021.6074  4021.1118
  4527.3521  4943.0488  4935.1382
  4951.7627  5431.9189  5408.1123

(4,.,.) = 
  1055.4562  1176.1107  1153.7905
  1320.4033  1421.5657  1369.1658
  1435.5615  1489.7681  1396.5975

(5,.,.) = 
   750.8096   742.3758   663.3916
   737.0778   690.2244   583.4572
   753.6828   671.2766   562.0963

(6,.,.) = 
  1651.0387  1870.9227  1913.1571
  2026.7444  2336.1213  2379.4683
  2332.1628  2678.1106  2705.3696

(7,.,.) = 
 -2760.1125 -2932.0425 -2754.7664
 -2978.8093 -3130.2856 -2866.1753
 -2856.8340 -2933.4944 -2640.6338

(8,.,.) = 
  5778.8315  6190.8975  5947.2593
  6515.0347  6943.6821  6618.9614
  6781.1025  7155.6943  6782.1353

(9,.,.) = 
  2539.2144  3053.0315  3254.1309
  2925.0271  3453.0801  3581.9924
  3197.1296  3732.7544  3818.7888

(10,.,.) = 
 -3418.5957 -3376.6436 -3126.6040
 -3661.3562 -3626.3508 -3355.6704
 -3623.9719 -3579.8936 -3332.1782

(11,.,.) = 
   480.2643   640.2390   731.8456
   753.8044   943.9169  1031.6187
   844.7326  1081.2871  1171.7485

(12,.,.) = 
   447.9309   720.1208   954.9602
   516.4619   834.5497  1058.6605
   273.5656   590.6008   786.9197

(13,.,.) = 
 -2941.3574 -3109.6443 -3006.5996
 -2963.7144 -3118.8550 -3003.1086
 -2897.1934 -3043.1099 -2900.7891

(14,.,.) = 
  5067.7817  5369.4531  5172.3413
  5342.1089  5634.1123  5393.5977
  5286.0684  5601.0498  5329.7012

(15,.,.) = 
  3450.3826  3741.6431  3715.5283
  4020.6545  4409.0029  4359.0708
  4355.2930  4764.0054  4692.1514

(16,.,.) = 
 -2932.3831 -3013.0193 -3001.4148
 -3061.7080 -3176.5354 -3152.7925
 -3194.3792 -3337.1689 -3299.8186

(17,.,.) = 
 -7598.5083 -7997.0186 -7895.6196
 -8720.6211 -9229.1533 -9125.1992
 -9423.9014 -9994.7139 -9869.2432

(18,.,.) = 
  1645.7474  1594.2318  1497.6650
  1834.6611  1754.9708  1647.8882
  1829.9231  1736.3451  1632.8000
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3691.7980957031	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #20: time = 0.607888	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2243e+04   4.2718e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #21	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00074000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1911.2482 -2151.5835 -2076.3125
 -2038.4299 -2271.2471 -2163.8489
 -1998.5544 -2188.5298 -2065.2100

(2,.,.) = 
  2861.7866  3025.6829  2915.2749
  3068.6697  3249.6765  3096.3257
  2963.4104  3112.4146  2944.5286

(3,.,.) = 
  3689.1687  4019.7800  4020.2976
  4524.9185  4941.7646  4935.0933
  4950.4014  5431.6670  5409.1099

(4,.,.) = 
  1055.3038  1176.3391  1154.3669
  1320.5168  1422.1910  1370.2450
  1436.1354  1491.0237  1398.1708

(5,.,.) = 
   750.0677   741.8866   663.0246
   736.7943   690.3254   583.6680
   753.7323   671.8022   562.8531

(6,.,.) = 
  1651.0155  1871.1001  1913.5216
  2026.6495  2336.1367  2379.8528
  2332.0320  2678.2307  2705.9695

(7,.,.) = 
 -2756.7861 -2928.7742 -2752.3562
 -2975.9602 -3127.6719 -2864.4739
 -2855.1394 -2932.2034 -2640.2302

(8,.,.) = 
  5773.7100  6186.3540  5944.3232
  6511.1011  6940.6655  6617.7422
  6779.0972  7154.9521  6783.0771

(9,.,.) = 
  2537.8469  3051.4878  3252.8015
  2924.4243  3452.5203  3581.8164
  3197.0940  3732.8943  3819.4617

(10,.,.) = 
 -3413.8462 -3372.5469 -3123.9001
 -3657.5918 -3623.1794 -3353.6890
 -3621.9917 -3578.4285 -3331.6504

(11,.,.) = 
   480.9726   640.9460   732.3487
   754.1054   944.1899  1031.8645
   844.8891  1081.3632  1171.8875

(12,.,.) = 
   446.8243   718.6452   953.2226
   514.9741   832.7039  1056.7269
   272.7077   589.4742   785.9529

(13,.,.) = 
 -2935.9380 -3104.1677 -3002.0122
 -2959.2905 -3114.4856 -2999.5925
 -2894.1145 -3040.1230 -2898.4429

(14,.,.) = 
  5060.4312  5362.3989  5166.8159
  5336.2881  5628.5796  5389.5908
  5282.6025  5597.9282  5327.9238

(15,.,.) = 
  3448.8721  3740.8921  3715.6372
  4019.8584  4408.9658  4360.0698
  4355.3916  4765.0464  4694.1968

(16,.,.) = 
 -2929.1318 -3010.5457 -2999.9019
 -3059.9932 -3175.4648 -3152.5505
 -3193.9258 -3337.4194 -3300.7715

(17,.,.) = 
 -7592.2739 -7992.2573 -7893.0537
 -8715.9316 -9226.2764 -9124.7129
 -9421.6162 -9994.3750 -9871.1787

(18,.,.) = 
  1643.4713  1592.3632  1496.3591
  1832.7500  1753.5106  1646.9895
  1828.9117  1735.7239  1632.6395
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3689.1687011719	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #21: time = 0.585244	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2321e+04   4.2788e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #22	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00035001/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1906.4771 -2146.2476 -2071.2598
 -2032.7312 -2264.9492 -2157.7761
 -1992.7601 -2181.9602 -2058.7156

(2,.,.) = 
  2854.9875  3018.9102  2908.5303
  3060.8914  3241.6289  3088.4438
  2955.7810  3104.1931  2936.2219

(3,.,.) = 
  3674.2136  4002.8962  4002.1299
  4506.5249  4921.0342  4913.1445
  4930.1890  5409.0054  5385.5024

(4,.,.) = 
  1050.2906  1170.2417  1147.5282
  1313.9335  1414.6171  1361.8469
  1428.9338  1482.9995  1389.5817

(5,.,.) = 
   746.3528   738.5712   660.0898
   732.7646   686.3632   579.9421
   749.7424   667.8665   558.8362

(6,.,.) = 
  1643.3009  1861.5770  1903.0249
  2017.6097  2324.9163  2367.3958
  2322.3389  2666.3506  2692.9109

(7,.,.) = 
 -2747.5791 -2919.4622 -2743.4211
 -2965.8096 -3117.1882 -2854.4504
 -2845.1162 -2921.8232 -2630.0872

(8,.,.) = 
  5752.6670  6164.0054  5922.0693
  6486.8584  6914.5278  6591.7134
  6753.6279  7127.3145  6755.4058

(9,.,.) = 
  2527.6355  3039.6672  3239.5654
  2912.0393  3438.3481  3566.4392
  3184.0737  3718.2002  3803.8923

(10,.,.) = 
 -3404.0557 -3362.3740 -3113.5171
 -3646.2703 -3611.2639 -3342.0056
 -3609.5535 -3565.2156 -3318.6128

(11,.,.) = 
   479.1459   638.2715   729.2039
   751.4445   940.7830  1027.9374
   842.0640  1077.6974  1167.7356

(12,.,.) = 
   447.4887   719.0438   952.9492
   515.2310   832.4587  1055.8809
   272.7751   588.8785   784.5499

(13,.,.) = 
 -2928.8723 -3097.6179 -2996.0847
 -2951.8782 -3107.3235 -2993.2351
 -2886.3914 -3032.5239 -2891.7656

(14,.,.) = 
  5046.9736  5348.5928  5153.3691
  5321.1699  5612.9619  5374.4526
  5266.3564  5580.7397  5311.2451

(15,.,.) = 
  3433.9722  3724.0945  3698.0720
  4002.3364  4388.8599  4339.1836
  4336.5498  4743.3667  4671.7227

(16,.,.) = 
 -2919.3772 -2999.7708 -2987.9905
 -3048.1313 -3162.6301 -3138.8845
 -3180.8850 -3323.3601 -3286.1333

(17,.,.) = 
 -7563.5938 -7960.7603 -7859.9922
 -8681.5898 -9188.5547 -9085.2969
 -9383.7910 -9952.8096 -9828.1748

(18,.,.) = 
  1639.1942  1588.1083  1491.6395
  1827.2623  1748.2465  1641.1517
  1822.6073  1729.5356  1625.9043
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3674.2136230469	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #22: time = 0.563066	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2016e+04   4.2569e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #23	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00094002/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1903.1005 -2141.4746 -2065.4592
 -2028.1610 -2258.8721 -2150.7385
 -1986.9569 -2174.4983 -2050.7344

(2,.,.) = 
  2849.3096  3011.3699  2899.6907
  3053.7261  3232.3789  3078.2222
  2947.5571  3094.0649  2925.3562

(3,.,.) = 
  3656.2588  3982.8335  3982.6599
  4485.4653  4896.9868  4889.4170
  4907.4248  5383.3267  5360.1899

(4,.,.) = 
  1044.1403  1163.3667  1141.2535
  1306.3154  1406.4924  1354.5405
  1420.8860  1474.1505  1381.6255

(5,.,.) = 
   742.8035   734.0571   655.6854
   728.9577   681.7377   575.7311
   745.4295   662.9612   554.3184

(6,.,.) = 
  1633.3363  1850.7957  1892.9912
  2006.2968  2312.6123  2355.8408
  2310.0959  2652.8889  2680.2061

(7,.,.) = 
 -2739.1365 -2909.0579 -2732.0027
 -2955.7686 -3105.2029 -2842.0940
 -2834.3772 -2909.4353 -2617.5439

(8,.,.) = 
  5730.3730  6138.6133  5896.0347
  6460.6489  6885.0669  6562.3296
  6725.2432  7095.8906  6724.5635

(9,.,.) = 
  2515.1377  3025.0061  3224.6687
  2897.3833  3421.3081  3549.2612
  3168.4458  3699.9360  3785.2297

(10,.,.) = 
 -3392.9731 -3350.5718 -3101.3870
 -3633.4490 -3597.9670 -3328.4045
 -3596.1228 -3551.4219 -3304.7402

(11,.,.) = 
   475.4482   634.3181   725.7137
   747.2507   936.2053  1023.6605
   838.3226  1073.3579  1163.4443

(12,.,.) = 
   446.3763   716.8099   950.1892
   514.0175   829.9138  1052.5452
   271.5984   586.1550   780.9074

(13,.,.) = 
 -2922.5750 -3089.4692 -2986.6733
 -2944.7778 -3098.1360 -2982.5137
 -2877.8926 -3022.1614 -2880.3894

(14,.,.) = 
  5032.0747  5331.3071  5135.0200
  5303.8540  5593.4590  5353.8062
  5247.2393  5559.3481  5289.1523

(15,.,.) = 
  3417.2847  3705.2744  3679.3916
  3982.9062  4367.2935  4317.7915
  4315.4766  4720.1011  4649.0176

(16,.,.) = 
 -2906.7361 -2986.3311 -2975.0496
 -3033.5012 -3147.2463 -3124.2324
 -3165.3179 -3306.5662 -3270.0737

(17,.,.) = 
 -7529.3916 -7923.6680 -7823.3657
 -8641.7441 -9145.2803 -9042.2832
 -9340.4580 -9905.9268 -9782.0293

(18,.,.) = 
  1633.4336  1581.9908  1485.6394
  1820.6177  1741.3810  1634.5481
  1815.5356  1722.4241  1619.0814
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3656.2587890625	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #23: time = 0.547462	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1725e+04   4.2367e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #24	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00069002/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1909.0500 -2148.5837 -2072.7847
 -2035.1340 -2267.1187 -2159.2058
 -1994.2548 -2183.1868 -2059.4805

(2,.,.) = 
  2858.1514  3021.2888  2910.0615
  3063.7388  3243.7759  3089.7766
  2957.4592  3105.3997  2936.9102

(3,.,.) = 
  3676.7422  4005.4080  4005.4514
  4509.3789  4923.6221  4916.3159
  4932.4336  5410.9810  5387.9580

(4,.,.) = 
  1051.0548  1171.1510  1148.9492
  1314.8679  1415.6803  1363.5878
  1429.6582  1483.6394  1390.8827

(5,.,.) = 
   747.3323   738.7740   660.2589
   733.6364   686.6823   580.4579
   750.2210   667.8246   559.0981

(6,.,.) = 
  1643.9526  1863.0531  1905.3937
  2018.4163  2326.7209  2370.1594
  2322.7554  2667.6504  2695.1362

(7,.,.) = 
 -2750.7239 -2921.9006 -2745.1497
 -2968.4731 -3119.1860 -2855.9929
 -2846.7253 -2922.8447 -2630.9868

(8,.,.) = 
  5757.5015  6168.1455  5925.5933
  6491.0137  6918.1143  6594.9639
  6756.1943  7129.4517  6757.6006

(9,.,.) = 
  2529.4001  3041.5840  3242.1877
  2913.6985  3440.0767  3568.7827
  3184.9480  3718.9082  3804.8992

(10,.,.) = 
 -3406.3875 -3364.5164 -3115.3823
 -3648.0793 -3613.1880 -3343.5271
 -3610.8069 -3566.7439 -3319.9995

(11,.,.) = 
   478.4231   637.9255   729.3027
   751.1606   940.7470  1028.2145
   841.9712  1077.8040  1168.0040

(12,.,.) = 
   447.2161   718.7086   952.6559
   515.3188   832.5795  1055.8647
   272.7398   588.9154   784.5071

(13,.,.) = 
 -2932.1189 -3099.7590 -2997.1123
 -2954.4072 -3108.7612 -2993.3708
 -2887.8350 -3033.0273 -2891.2200

(14,.,.) = 
  5050.8569  5351.5142  5155.2529
  5324.0630  5615.0254  5375.4922
  5267.8765  5581.6699  5311.4463

(15,.,.) = 
  3436.6350  3726.8411  3701.1189
  4004.8364  4391.8130  4342.4204
  4338.2339  4745.5835  4674.4429

(16,.,.) = 
 -2920.9504 -3001.2808 -2990.1592
 -3049.4094 -3163.8691 -3140.7593
 -3181.6367 -3323.8540 -3287.1907

(17,.,.) = 
 -7568.7803 -7965.8438 -7865.5312
 -8686.5752 -9193.4336 -9090.7178
 -9387.4248 -9956.4424 -9832.4746

(18,.,.) = 
  1639.7800  1588.5103  1492.3988
  1827.9631  1748.6646  1642.0769
  1823.1635  1729.9836  1626.8842
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3676.7421875	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #24: time = 0.522702	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1979e+04   4.2556e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #25	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00049001/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 358
 640
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 640
 640
[torch.LongStorage of size 3]

x_start = 1 / y_start = 142	
img_means:size() vs img:size():	
   3
 358
 640
[torch.LongStorage of size 3]

   3
 358
 640
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6759776536313	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1072
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x131
  2 : CudaTensor - size: 18x72x131
  3 : CudaTensor - size: 18x70x129
  4 : CudaTensor - size: 18x68x127
  5 : CudaTensor - size: 256x74x133
}
proposal_im_deteect: img_blob size:     3
  600
 1072
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 358
 640
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6759776536313	
proposal_im_detect: scaled_img_size:	
    5
  600
 1073
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1914.4120 -2154.6018 -2078.5771
 -2041.1523 -2273.7817 -2165.5679
 -2000.5154 -2190.1213 -2065.9998

(2,.,.) = 
  2866.3015  3029.8010  2918.2327
  3072.8318  3253.3518  3098.7991
  2966.6079  3115.0667  2945.9692

(3,.,.) = 
  3690.8726  4020.4897  4019.9529
  4526.3706  4941.8872  4933.8882
  4950.9302  5430.8901  5407.0098

(4,.,.) = 
  1055.1921  1175.7931  1153.4642
  1320.1508  1421.2645  1368.8802
  1435.3788  1489.5706  1396.4231

(5,.,.) = 
   750.7167   742.2292   663.2119
   737.0601   690.1911   583.3700
   753.7434   671.3375   562.0952

(6,.,.) = 
  1650.6493  1870.4176  1912.5870
  2026.3374  2335.4998  2378.7810
  2331.7520  2677.5068  2704.7336

(7,.,.) = 
 -2759.4353 -2931.1975 -2753.9150
 -2978.1763 -3129.4731 -2865.3484
 -2856.4482 -2932.9875 -2640.1382

(8,.,.) = 
  5777.4009  6189.1665  5945.5000
  6513.6875  6942.0688  6617.3159
  6780.1567  7154.5415  6780.9438

(9,.,.) = 
  2538.7180  3052.2991  3253.2156
  2924.5867  3452.4045  3581.1372
  3196.8064  3732.2271  3818.1543

(10,.,.) = 
 -3417.7122 -3375.6687 -3125.6365
 -3660.6086 -3625.4822 -3354.7944
 -3623.5649 -3579.3625 -3331.5806

(11,.,.) = 
   480.1487   640.0906   731.6658
   753.6674   943.7286  1031.4268
   844.5644  1081.0569  1171.5220

(12,.,.) = 
   447.6635   719.7318   954.4329
   516.1116   834.0644  1058.0955
   273.2540   590.2300   786.5533

(13,.,.) = 
 -2940.3840 -3108.5188 -3005.4319
 -2962.8875 -3117.9023 -3002.0557
 -2896.6982 -3042.4946 -2900.0134

(14,.,.) = 
  5066.2451  5367.6812  5170.5151
  5340.7954  5632.5571  5391.9805
  5285.2524  5600.0015  5328.5571

(15,.,.) = 
  3449.5908  3740.7202  3714.5605
  4019.8997  4408.0820  4358.1450
  4354.6958  4763.2817  4691.4219

(16,.,.) = 
 -2931.5994 -3012.1511 -3000.5188
 -3061.1431 -3175.8726 -3152.0654
 -3194.0669 -3336.7178 -3299.2659

(17,.,.) = 
 -7596.4780 -7994.6587 -7893.1411
 -8718.7080 -9226.9014 -9122.8613
 -9422.3838 -9992.8652 -9867.2920

(18,.,.) = 
  1645.3087  1593.7397  1497.1920
  1834.2655  1754.5323  1647.4353
  1829.6462  1735.9965  1632.4374
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 129
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 27090
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 129
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 129
[torch.LongStorage of size 2]

shift_y size:	
  70
 129
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 9030
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 27090
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 27090
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 27090
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  27090
[torch.LongStorage of size 1]
	
  first line: 3690.8725585938	
(fast bbox transform) src_w size:  27090
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 27090
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 27090
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 27090
     4
[torch.LongStorage of size 2]

scores size:	
 27090
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 27090
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 27090
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 27090
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 72240
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 18060
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 18060
[torch.LongStorage of size 1]

test img #25: time = 0.61618	
(proposal_test:boxes_filter) boxes & scores size:	
 18060
     4
[torch.LongStorage of size 2]

 18060
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1809
    3
[torch.LongTensor of size 2]

mask size:	
 18060
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   6.4000e+02   6.4000e+02
        -inf         -inf   3.5873e+04   2.1137e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #26	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00050004/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1901.7982 -2140.0098 -2063.9885
 -2026.9058 -2257.5090 -2149.2090
 -1986.0416 -2173.6084 -2049.8743

(2,.,.) = 
  2848.2014  3009.9675  2898.1848
  3052.6101  3231.0176  3076.6941
  2946.5999  3092.9963  2924.3430

(3,.,.) = 
  3654.9771  3980.8694  3980.4260
  4485.8462  4896.9287  4889.2476
  4909.3135  5385.1802  5362.0015

(4,.,.) = 
  1044.2827  1163.5089  1141.2159
  1306.8074  1407.1807  1355.1324
  1422.1238  1475.4751  1382.6506

(5,.,.) = 
   742.5469   733.1376   654.4229
   729.2876   681.3610   574.9356
   746.1586   663.1797   554.2000

(6,.,.) = 
  1633.7522  1851.2395  1893.2206
  2007.5392  2313.9646  2357.1233
  2311.4565  2654.5823  2682.0608

(7,.,.) = 
 -2740.2075 -2909.6780 -2732.3362
 -2956.8135 -3105.9539 -2842.5198
 -2835.3857 -2910.3591 -2618.2510

(8,.,.) = 
  5730.4658  6137.5640  5894.0430
  6462.2573  6885.7969  6562.2656
  6728.2837  7098.5615  6726.5723

(9,.,.) = 
  2515.0100  3024.7720  3224.0029
  2898.3367  3422.4846  3550.0188
  3170.5398  3702.3948  3787.3494

(10,.,.) = 
 -3391.5872 -3349.1494 -3099.9153
 -3632.6777 -3596.9534 -3327.1406
 -3596.1272 -3551.2695 -3304.2073

(11,.,.) = 
   476.8930   635.8826   726.9746
   748.6149   937.9348  1025.2612
   839.6175  1075.0529  1164.9819

(12,.,.) = 
   447.2599   718.3388   951.8777
   514.4807   831.0881  1053.9044
   271.8433   587.1289   782.0532

(13,.,.) = 
 -2922.3157 -3088.8706 -2985.8149
 -2945.0740 -3098.1536 -2982.0518
 -2878.5688 -3022.6814 -2880.4604

(14,.,.) = 
  5031.4614  5330.1206  5133.3027
  5304.1216  5593.2861  5352.9038
  5248.4375  5560.3931  5289.4873

(15,.,.) = 
  3417.5352  3705.0579  3678.4995
  3984.6199  4368.7134  4318.5342
  4318.1680  4722.9126  4651.3916

(16,.,.) = 
 -2905.0627 -2984.0432 -2972.4333
 -3032.9456 -3146.1558 -3122.7424
 -3166.2927 -3307.1477 -3270.2458

(17,.,.) = 
 -7527.2588 -7920.3267 -7819.1289
 -8643.0088 -9145.7129 -9041.5713
 -9345.0947 -9910.1807 -9785.3369

(18,.,.) = 
  1632.9261  1581.1356  1484.9069
  1820.2262  1740.5958  1633.8928
  1815.4307  1722.0623  1618.7695
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3654.9770507812	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #26: time = 0.577449	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1658e+04   4.2353e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #27	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00077000/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1910.0824 -2150.2698 -2074.9626
 -2037.0167 -2269.8049 -2162.3660
 -1997.3663 -2187.3105 -2064.0127

(2,.,.) = 
  2859.9766  3023.7747  2913.3254
  3066.3577  3247.2017  3093.8945
  2961.0659  3110.0232  2942.2534

(3,.,.) = 
  3685.7642  4016.0881  4016.5757
  4519.4956  4935.9854  4929.5405
  4943.1973  5423.8447  5401.9062

(4,.,.) = 
  1053.8307  1174.7644  1152.6887
  1318.8000  1420.3350  1368.3569
  1434.2002  1488.9977  1396.3778

(5,.,.) = 
   749.6701   741.7155   662.8511
   736.3303   690.0988   583.4869
   753.4255   671.6667   562.6922

(6,.,.) = 
  1648.4736  1868.3790  1911.1301
  2022.8112  2332.1853  2376.4856
  2326.9731  2673.1208  2701.6626

(7,.,.) = 
 -2754.5054 -2926.5234 -2750.1707
 -2972.6111 -3124.3347 -2861.4282
 -2851.4395 -2928.6636 -2637.3164

(8,.,.) = 
  5768.6416  6181.1694  5939.3638
  6503.7998  6933.3384  6610.9204
  6770.1494  7145.9829  6775.0854

(9,.,.) = 
  2535.4326  3048.4822  3249.5496
  2920.3843  3447.9597  3577.4177
  3191.9314  3727.0884  3814.2737

(10,.,.) = 
 -3412.9570 -3371.4336 -3122.7236
 -3655.7378 -3621.0430 -3351.7056
 -3618.6392 -3575.0593 -3328.4702

(11,.,.) = 
   479.8212   639.6687   731.2449
   752.3190   942.4716  1030.2887
   842.4468  1078.8048  1169.5248

(12,.,.) = 
   446.3585   718.0203   952.4097
   514.3378   831.8605  1055.8726
   272.4659   588.8693   785.5485

(13,.,.) = 
 -2934.4343 -3102.4507 -2999.9822
 -2956.6404 -3111.7737 -2996.7739
 -2890.7705 -3036.9343 -2895.4412

(14,.,.) = 
  5057.4326  5358.9502  5163.0923
  5331.7388  5623.9551  5384.9155
  5276.6255  5592.1196  5322.4683

(15,.,.) = 
  3445.0088  3737.0129  3712.1235
  4014.3276  4403.4854  4355.2759
  4348.3550  4758.0791  4688.1841

(16,.,.) = 
 -2927.8987 -3008.9236 -2997.9006
 -3057.8938 -3173.1714 -3149.9802
 -3190.5896 -3333.9395 -3297.2615

(17,.,.) = 
 -7585.5747 -7985.3906 -7886.1060
 -8706.8340 -9216.8682 -9115.5732
 -9409.3613 -9981.7461 -9859.2305

(18,.,.) = 
  1643.0255  1591.7927  1495.6476
  1831.7850  1752.4537  1645.7297
  1827.4139  1734.1750  1631.0459
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3685.7641601562	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #27: time = 0.55111	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2138e+04   4.2677e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #28	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00069000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1902.8827 -2141.5525 -2065.6560
 -2028.8353 -2259.9609 -2152.0374
 -1988.2086 -2176.5195 -2052.8489

(2,.,.) = 
  2849.1912  3011.5127  2900.1953
  3054.4299  3233.6487  3079.6062
  2948.6890  3096.0225  2927.6106

(3,.,.) = 
  3666.4766  3993.5601  3992.6650
  4497.1060  4909.4077  4900.9902
  4919.3037  5395.8042  5371.5547

(4,.,.) = 
  1048.3120  1168.1307  1145.9108
  1311.4249  1411.9519  1359.8723
  1425.9431  1479.7142  1387.0242

(5,.,.) = 
   746.2551   737.5003   658.6854
   732.6946   685.7660   579.3719
   749.1984   667.0555   558.3995

(6,.,.) = 
  1640.0547  1858.2981  1900.2006
  2013.6240  2320.7153  2363.6602
  2317.2759  2660.8181  2687.7556

(7,.,.) = 
 -2743.7639 -2914.2393 -2737.5940
 -2961.1787 -3111.3921 -2848.5205
 -2839.9358 -2915.8521 -2624.4946

(8,.,.) = 
  5742.0635  6150.7964  5907.7642
  6473.8662  6899.0386  6575.5293
  6738.4399  7110.0581  6738.0195

(9,.,.) = 
  2522.6333  3033.0562  3232.8152
  2906.3704  3430.9473  3558.8660
  3177.0374  3709.0745  3794.3105

(10,.,.) = 
 -3395.6746 -3353.4792 -3104.5344
 -3636.8164 -3601.6318 -3332.1697
 -3599.9446 -3555.7537 -3309.1682

(11,.,.) = 
   477.2110   636.2437   727.2373
   748.9273   937.9158  1025.0922
   839.4996  1074.6174  1164.5226

(12,.,.) = 
   445.5208   716.2502   949.5920
   513.5857   829.9944  1052.7061
   272.0690   587.3734   782.4738

(13,.,.) = 
 -2923.4033 -3090.3555 -2987.6235
 -2946.0388 -3099.9092 -2984.5078
 -2879.8794 -3024.6460 -2882.8420

(14,.,.) = 
  5035.9453  5335.2529  5138.7344
  5308.7295  5598.4873  5358.8271
  5253.0615  5565.6885  5295.4346

(15,.,.) = 
  3427.4351  3716.4348  3690.1111
  3994.3057  4379.8301  4329.8193
  4326.9448  4732.7925  4661.0420

(16,.,.) = 
 -2912.0491 -2991.7500 -2980.0898
 -3040.7502 -3154.4688 -3130.8003
 -3173.0007 -3314.5312 -3277.3035

(17,.,.) = 
 -7547.1450 -7941.9321 -7840.2876
 -8662.4541 -9166.7129 -9062.4844
 -9361.7910 -9928.0615 -9802.5156

(18,.,.) = 
  1634.9844  1583.4067  1487.1924
  1822.7234  1743.1835  1636.5880
  1818.1749  1724.8954  1621.8737
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3666.4765625	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #28: time = 0.597976	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1770e+04   4.2444e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #29	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00017001/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1915.6506  -2156.1074  -2080.1770
  -2042.4965  -2275.4531  -2167.3726
  -2001.7836  -2191.7781  -2067.7471

(2,.,.) = 
   2868.1145   3031.9182   2920.5537
   3074.7817   3255.6892   3101.2476
   2968.3203   3117.1736   2948.2124

(3,.,.) = 
   3695.2886   4025.3286   4024.7363
   4531.2104   4947.2734   4939.2085
   4955.5259   5435.9946   5412.0098

(4,.,.) = 
   1056.5970   1177.3649   1154.9984
   1321.9529   1423.1296   1370.6835
   1437.0977   1491.3850   1398.2028

(5,.,.) = 
    751.8331    743.4749    664.4689
    738.0993    691.4163    584.6108
    754.7312    672.4286    563.1991

(6,.,.) = 
   1652.7820   1872.9052   1915.0830
   2028.6221   2338.2334   2381.5647
   2334.0310   2680.1880   2707.4141

(7,.,.) = 
  -2761.4797  -2933.5959  -2756.4985
  -2980.3518  -3132.0408  -2868.0454
  -2858.3481  -2935.2417  -2642.5410

(8,.,.) = 
   5782.5786   6194.8638   5951.2949
   6519.1631   6948.1685   6623.3833
   6785.1909   7160.1772   6786.5527

(9,.,.) = 
   2541.4082   3055.3010   3256.3435
   2927.5549   3455.7170   3584.6067
   3199.5813   3735.3696   3821.4490

(10,.,.) = 
  -3420.6165  -3378.7881  -3128.7986
  -3663.5867  -3628.6682  -3358.0068
  -3626.1812  -3582.1658  -3334.3777

(11,.,.) = 
    480.5116    640.5234    732.1014
    754.2158    944.3200   1031.9713
    844.9678   1081.5327   1171.9534

(12,.,.) = 
    447.7906    719.9727    954.8250
    516.4449    834.5763   1058.7416
    273.6877    590.8474    787.3766

(13,.,.) = 
  -2941.9792  -3110.3704  -3007.3984
  -2964.2085  -3119.5625  -3003.8809
  -2897.9006  -3044.0286  -2901.6887

(14,.,.) = 
   5069.6758   5371.4980   5174.4297
   5344.1655   5636.3428   5395.8618
   5288.3369   5603.5337   5332.1934

(15,.,.) = 
   3453.4490   3745.0183   3718.8562
   4024.0503   4412.7822   4362.8242
   4358.6987   4767.8276   4695.9253

(16,.,.) = 
  -2934.8721  -3015.6135  -3003.9163
  -3064.5681  -3179.4407  -3155.4873
  -3197.2195  -3340.0486  -3302.4316

(17,.,.) = 
  -7604.6816  -8003.5391  -7901.8945
  -8727.6299  -9236.5371  -9132.3721
  -9430.9160 -10002.1064  -9876.3223

(18,.,.) = 
   1646.7933   1595.3033   1498.8452
   1835.8795   1756.1334   1649.1012
   1831.1530   1737.4855   1633.9319
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3695.2885742188	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #29: time = 0.588919	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2279e+04   4.2749e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #30	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00108001/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 240
 320
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 320
 320
[torch.LongStorage of size 3]

x_start = 1 / y_start = 41	
img_means:size() vs img:size():	
   3
 240
 320
[torch.LongStorage of size 3]

   3
 240
 320
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 2.5	
(orep_img_for_blob) img size after scaling:	
   3
 600
 800
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x97
  2 : CudaTensor - size: 18x72x97
  3 : CudaTensor - size: 18x70x95
  4 : CudaTensor - size: 18x68x93
  5 : CudaTensor - size: 256x74x99
}
proposal_im_deteect: img_blob size:    3
 600
 800
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 240
 320
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 2.5	
proposal_im_detect: scaled_img_size:	
   8
 600
 800
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1914.2582  -2154.8198  -2077.6865
  -2043.1271  -2275.9695  -2166.8621
  -2002.9907  -2192.9368  -2067.8638

(2,.,.) = 
   2866.1875   3029.7544   2917.9827
   3074.7280   3255.9377   3100.5881
   2969.0457   3118.3574   2948.8037

(3,.,.) = 
   3713.0144   4043.0093   4040.3381
   4552.4199   4969.0112   4959.1626
   4976.9272   5458.7139   5432.9639

(4,.,.) = 
   1066.6875   1188.5536   1166.0031
   1332.2399   1434.6670   1382.3829
   1446.8781   1502.2328   1408.6995

(5,.,.) = 
    758.1697    748.6872    667.8029
    744.4556    697.3127    589.3192
    760.0475    677.8158    568.9299

(6,.,.) = 
   1667.3198   1888.8647   1930.2852
   2044.7529   2355.6318   2398.0049
   2349.5886   2697.3003   2723.5750

(7,.,.) = 
  -2772.8777  -2945.2517  -2767.9187
  -2992.8721  -3145.2520  -2880.7366
  -2869.7793  -2947.4160  -2654.4485

(8,.,.) = 
   5808.3291   6220.3516   5973.6841
   6547.2646   6976.2983   6648.8301
   6810.9697   7186.9648   6811.3335

(9,.,.) = 
   2556.7617   3072.6633   3274.8933
   2946.6626   3476.8677   3606.2129
   3216.7979   3754.1550   3840.2273

(10,.,.) = 
  -3418.3223  -3376.2825  -3126.7297
  -3662.3638  -3628.0073  -3357.0583
  -3627.2600  -3584.3906  -3337.3435

(11,.,.) = 
    486.1465    646.8831    737.6054
    758.3812    948.9144   1036.4465
    848.9647   1086.4939   1177.3389

(12,.,.) = 
    446.2826    720.0691    954.9343
    515.4906    835.4196   1059.6295
    274.6085    593.4456    790.1082

(13,.,.) = 
  -2944.3105  -3111.8667  -3008.7095
  -2969.6169  -3124.7869  -3009.2588
  -2903.6450  -3049.3494  -2906.5361

(14,.,.) = 
   5077.1436   5378.4155   5179.6772
   5353.7803   5645.4150   5404.0942
   5298.9053   5614.1455   5342.1958

(15,.,.) = 
   3474.9165   3767.7761   3739.7607
   4047.6055   4437.7930   4386.0132
   4381.0322   4791.9478   4718.4155

(16,.,.) = 
  -2939.1929  -3019.5701  -3007.3684
  -3073.3667  -3187.8340  -3163.4587
  -3207.8855  -3351.3267  -3313.7222

(17,.,.) = 
  -7637.8149  -8035.5474  -7930.0591
  -8764.9746  -9274.6533  -9167.8125
  -9468.3018 -10041.6543  -9914.2490

(18,.,.) = 
   1646.2878   1594.1086   1497.6879
   1836.4854   1756.1245   1649.8594
   1833.8605   1740.2145   1637.7828
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 95
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 19950
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 95
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 95
[torch.LongStorage of size 2]

shift_y size:	
 70
 95
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6650
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 19950
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  19950
[torch.LongStorage of size 1]
	
  first line: 3713.0144042969	
(fast bbox transform) src_w size:  19950
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 19950
     4
[torch.LongStorage of size 2]

scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 19950
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 53200
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13300
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13300
[torch.LongStorage of size 1]

test img #30: time = 0.366452	
(proposal_test:boxes_filter) boxes & scores size:	
 13300
     4
[torch.LongStorage of size 2]

 13300
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 953
   3
[torch.LongTensor of size 2]

mask size:	
 13300
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   3.2000e+02   3.2000e+02
        -inf         -inf   2.4150e+04   1.4239e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #31	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00021000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1902.8590 -2141.2659 -2065.3518
 -2028.0551 -2258.8496 -2150.8528
 -1986.8751 -2174.6626 -2051.0032

(2,.,.) = 
  2848.9324  3011.0525  2899.5471
  3053.4451  3232.2239  3078.1863
  2947.2148  3093.9375  2925.4065

(3,.,.) = 
  3657.8765  3984.5857  3984.3254
  4487.0957  4898.8267  4891.1636
  4908.8242  5384.7954  5361.5610

(4,.,.) = 
  1044.7000  1164.0341  1141.9105
  1307.1445  1407.3636  1355.3987
  1421.6582  1475.0657  1382.5847

(5,.,.) = 
   743.3671   734.6868   656.2855
   729.5779   682.4907   576.4627
   746.0590   663.7144   555.0691

(6,.,.) = 
  1634.2629  1851.8546  1894.0029
  2007.1625  2313.6121  2356.8081
  2310.6543  2653.5488  2680.8267

(7,.,.) = 
 -2739.3757 -2909.4202 -2732.5688
 -2956.0334 -3105.6331 -2842.7053
 -2834.5176 -2909.7498 -2618.1326

(8,.,.) = 
  5731.6084  6139.9731  5897.5400
  6461.9751  6886.6294  6563.9619
  6726.2085  7097.1543  6725.9731

(9,.,.) = 
  2516.1799  3025.9954  3225.5898
  2898.5173  3422.4302  3550.3479
  3169.2422  3700.7354  3786.0596

(10,.,.) = 
 -3393.4919 -3351.1792 -3102.0991
 -3634.0540 -3598.6438 -3329.2065
 -3596.5537 -3551.9832 -3305.3989

(11,.,.) = 
   475.4950   634.3635   725.7283
   747.3339   936.2686  1023.6813
   838.1849  1073.1658  1163.2273

(12,.,.) = 
   445.9603   716.3182   949.6874
   513.6592   829.5273  1052.1945
   271.3985   586.0378   780.9013

(13,.,.) = 
 -2922.2073 -3089.0862 -2986.3315
 -2944.2939 -3097.7395 -2982.1807
 -2877.4739 -3021.8452 -2880.1096

(14,.,.) = 
  5032.0005  5331.2041  5134.9917
  5303.8599  5593.4775  5353.9390
  5247.1919  5559.4565  5289.4004

(15,.,.) = 
  3418.6968  3706.9045  3681.0420
  3984.4136  4369.0420  4319.5610
  4316.6831  4721.5991  4650.5449

(16,.,.) = 
 -2907.7820 -2987.4004 -2976.0283
 -3034.8633 -3148.6074 -3125.4368
 -3166.5066 -3307.8293 -3271.1846

(17,.,.) = 
 -7531.9126 -7926.3828 -7825.9282
 -8644.6699 -9148.4053 -9045.2949
 -9343.0469 -9908.7441 -9784.6709

(18,.,.) = 
  1633.6725  1582.2577  1485.9836
  1820.9148  1741.6533  1634.8997
  1815.8287  1722.7007  1619.4459
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3657.8764648438	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #31: time = 0.617507	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1633e+04   4.2330e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #32	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00103000/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 360
 490
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 490
 490
[torch.LongStorage of size 3]

x_start = 1 / y_start = 66	
img_means:size() vs img:size():	
   3
 360
 490
[torch.LongStorage of size 3]

   3
 360
 490
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6666666666667	
(orep_img_for_blob) img size after scaling:	
   3
 600
 816
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x99
  2 : CudaTensor - size: 18x72x99
  3 : CudaTensor - size: 18x70x97
  4 : CudaTensor - size: 18x68x95
  5 : CudaTensor - size: 256x74x101
}
proposal_im_deteect: img_blob size:    3
 600
 816
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 360
 490
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6666666666667	
proposal_im_detect: scaled_img_size:	
   5
 600
 817
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1926.6941  -2169.7310  -2093.8608
  -2056.8574  -2292.2617  -2184.3169
  -2017.3048  -2209.6489  -2085.3909

(2,.,.) = 
   2884.8948   3050.9143   2940.4917
   3095.1804   3279.2197   3124.9775
   2989.4817   3141.4341   2972.7817

(3,.,.) = 
   3743.9741   4078.8052   4077.9741
   4589.9453   5012.2124   5003.9780
   5017.7495   5504.9106   5480.0244

(4,.,.) = 
   1075.9493   1199.3883   1176.7936
   1344.0908   1447.5930   1394.6962
   1459.5914   1515.6904   1421.1500

(5,.,.) = 
    763.4400    755.0524    674.5774
    750.0031    703.6310    595.5225
    765.9793    683.9880    574.6635

(6,.,.) = 
   1681.4484   1905.5964   1947.8677
   2061.7844   2375.9944   2419.4329
   2368.9700   2720.2407   2747.2891

(7,.,.) = 
  -2790.6697  -2965.4092  -2788.3821
  -3012.5544  -3167.2229  -2902.2502
  -2889.2600  -2968.5881  -2674.7183

(8,.,.) = 
   5850.8936   6268.5264   6023.1841
   6596.0811   7030.8550   6703.3740
   6862.5371   7243.2104   6866.2124

(9,.,.) = 
   2576.7661   3097.1272   3301.2109
   2969.9810   3504.7412   3635.6562
   3242.2949   3784.1118   3871.2532

(10,.,.) = 
  -3444.3984  -3403.6587  -3154.1169
  -3690.6611  -3657.3684  -3386.2146
  -3655.1792  -3613.0371  -3365.2764

(11,.,.) = 
    491.0060    652.9394    743.7981
    765.1084    957.0177   1044.5614
    855.7178   1094.9075   1185.6782

(12,.,.) = 
    449.2097    724.6403    960.8858
    518.7921    840.7164   1066.5123
    276.9698    598.0433    796.2613

(13,.,.) = 
  -2962.6475  -3132.7029  -3030.6377
  -2987.9756  -3145.7310  -3031.4626
  -2922.4968  -3070.7354  -2928.7454

(14,.,.) = 
   5112.0938   5417.5635   5220.2451
   5391.3979   5686.9268   5446.5537
   5337.2100   5656.1372   5384.3037

(15,.,.) = 
   3502.9763   3799.7959   3772.9631
   4080.4417   4475.1304   4424.2007
   4416.8638   4831.9087   4758.3213

(16,.,.) = 
  -2963.4167  -3046.2729  -3035.2107
  -3099.1975  -3216.0972  -3192.2771
  -3234.5310  -3380.2593  -3342.5989

(17,.,.) = 
  -7699.6484  -8104.6636  -8002.2437
  -8836.7344  -9353.7363  -9249.3604
  -9545.9014 -10125.8438  -9999.0225

(18,.,.) = 
   1658.6842   1607.1250   1510.8309
   1850.4227   1770.3982   1663.9100
   1847.7780   1754.0597   1651.1754
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 97
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 20370
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 97
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 97
[torch.LongStorage of size 2]

shift_y size:	
 70
 97
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6790
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 20370
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 20370
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 20370
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  20370
[torch.LongStorage of size 1]
	
  first line: 3743.9741210938	
(fast bbox transform) src_w size:  20370
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 20370
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 20370
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 20370
     4
[torch.LongStorage of size 2]

scores size:	
 20370
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 20370
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 20370
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 20370
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 54320
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13580
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13580
[torch.LongStorage of size 1]

test img #32: time = 0.402072	
(proposal_test:boxes_filter) boxes & scores size:	
 13580
     4
[torch.LongStorage of size 2]

 13580
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 973
   3
[torch.LongTensor of size 2]

mask size:	
 13580
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   4.9000e+02   4.9000e+02
        -inf         -inf   3.6503e+04   2.1627e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #33	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00086000/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1908.4601 -2147.6292 -2071.7786
 -2033.8634 -2265.4202 -2157.4053
 -1992.5857 -2181.0483 -2057.2869

(2,.,.) = 
  2857.2656  3020.0383  2908.5090
  3062.2446  3241.6687  3087.4431
  2955.6353  3102.9001  2934.1099

(3,.,.) = 
  3668.6992  3996.6238  3996.7339
  4499.7744  4913.0005  4905.8013
  4922.2754  5399.8237  5377.0635

(4,.,.) = 
  1047.4143  1167.0977  1145.0284
  1310.7064  1411.1757  1359.1693
  1425.4449  1479.0541  1386.5707

(5,.,.) = 
   745.2629   736.7590   658.3454
   731.3681   684.3378   578.1738
   747.9507   665.4854   556.5604

(6,.,.) = 
  1638.4359  1856.6349  1899.0266
  2012.0958  2319.4194  2362.9136
  2316.2998  2660.1145  2687.6633

(7,.,.) = 
 -2746.0117 -2916.7285 -2739.6448
 -2963.1333 -3113.2993 -2849.8687
 -2841.2939 -2916.8730 -2624.6848

(8,.,.) = 
  5746.8281  6156.7236  5914.3799
  6478.8896  6905.1655  6582.3110
  6743.7832  7116.1479  6744.6924

(9,.,.) = 
  2522.8989  3034.0955  3234.2336
  2905.8137  3431.1440  3559.5300
  3177.1370  3710.1528  3795.9370

(10,.,.) = 
 -3404.3494 -3362.2312 -3112.7061
 -3645.4973 -3610.2053 -3340.3276
 -3607.5466 -3563.0220 -3315.9834

(11,.,.) = 
   476.4618   635.7132   727.4614
   749.2264   938.6340  1026.3783
   840.1695  1075.7195  1166.0908

(12,.,.) = 
   447.1351   718.0623   952.1091
   515.0152   831.5381  1054.8414
   271.9772   587.2821   782.7437

(13,.,.) = 
 -2930.0605 -3097.6404 -2994.7070
 -2951.6729 -3105.7515 -2989.9402
 -2884.6978 -3029.6296 -2887.5850

(14,.,.) = 
  5045.9331  5346.3203  5149.9668
  5318.2202  5608.9600  5369.1387
  5261.2671  5574.7344  5304.3213

(15,.,.) = 
  3427.9644  3717.1653  3691.6353
  3994.9624  4380.8438  4331.7114
  4328.0518  4734.2856  4663.5591

(16,.,.) = 
 -2917.1709 -2997.2761 -2985.9902
 -3044.1921 -3158.4978 -3135.3389
 -3175.7844 -3317.6755 -3281.0032

(17,.,.) = 
 -7553.7827 -7950.0923 -7850.1304
 -8669.1680 -9174.9121 -9072.3662
 -9369.0088 -9936.8184 -9813.2607

(18,.,.) = 
  1638.8087  1587.4734  1491.0724
  1826.4819  1747.2074  1640.2034
  1821.1071  1727.8685  1624.3657
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3668.69921875	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #33: time = 0.604272	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1839e+04   4.2447e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #34	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00123000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 480
 480
[torch.LongStorage of size 3]

x_start = 1 / y_start = 61	
img_means:size() vs img:size():	
   3
 360
 480
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6666666666667	
(orep_img_for_blob) img size after scaling:	
   3
 600
 800
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x97
  2 : CudaTensor - size: 18x72x97
  3 : CudaTensor - size: 18x70x95
  4 : CudaTensor - size: 18x68x93
  5 : CudaTensor - size: 256x74x99
}
proposal_im_deteect: img_blob size:    3
 600
 800
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 360
 480
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6666666666667	
proposal_im_detect: scaled_img_size:	
   5
 600
 800
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1915.6267  -2157.7778  -2082.8630
  -2045.9921  -2280.6414  -2173.8257
  -2007.9777  -2200.0061  -2077.0583

(2,.,.) = 
   2869.3906   3034.6812   2925.6143
   3079.5005   3262.9583   3110.2717
   2975.7136   3127.5786   2960.4480

(3,.,.) = 
   3727.1733   4061.1353   4061.4429
   4571.7051   4993.2192   4986.4473
   5001.1152   5487.7715   5464.3643

(4,.,.) = 
   1071.5687   1194.9390   1172.8468
   1339.7089   1443.4432   1391.3003
   1456.4517   1513.2139   1419.3848

(5,.,.) = 
    760.5756    751.7300    670.8260
    748.0065    701.4946    593.1432
    764.3907    682.8231    573.7273

(6,.,.) = 
   1675.6526   1899.1844   1941.8663
   2055.0791   2368.5654   2412.7241
   2361.9160   2712.8645   2740.6875

(7,.,.) = 
  -2779.5730  -2953.1633  -2776.9500
  -3001.3137  -3155.4399  -2891.7690
  -2879.9922  -2959.5266  -2667.1958

(8,.,.) = 
   5826.8315   6242.5386   5998.6577
   6572.0518   7005.7256   6680.4937
   6841.2407   7221.9624   6847.6348

(9,.,.) = 
   2566.6624   3084.5981   3288.0999
   2960.1270   3493.1106   3623.8252
   3233.5347   3773.9971   3861.2380

(10,.,.) = 
  -3428.3308  -3387.6909  -3139.6047
  -3674.9402  -3641.9285  -3372.3704
  -3641.2332  -3599.8701  -3353.9324

(11,.,.) = 
    490.5141    652.1422    742.6335
    763.2339    955.0694   1042.4022
    853.6872   1092.6995   1183.3909

(12,.,.) = 
    447.1907    721.7758    957.4202
    516.2885    837.1216   1062.4460
    276.3503    596.3509    794.0176

(13,.,.) = 
  -2948.4519  -3117.1899  -3015.5017
  -2975.0281  -3131.8901  -3017.9824
  -2910.9966  -3058.7327  -2917.2046

(14,.,.) = 
   5088.8940   5392.5615   5196.2583
   5369.4453   5663.6733   5424.5161
   5318.0547   5636.2734   5366.0327

(15,.,.) = 
   3489.3911   3785.4771   3759.4265
   4066.8816   4460.9648   4411.2505
   4404.6069   4819.6699   4747.5684

(16,.,.) = 
  -2949.6375  -3032.2598  -3021.6672
  -3087.3281  -3204.0024  -3180.5974
  -3224.4854  -3370.1760  -3333.1255

(17,.,.) = 
  -7666.0195  -8069.7324  -7969.0063
  -8803.8516  -9319.8301  -9217.4023
  -9516.3477 -10096.1357  -9971.5996

(18,.,.) = 
   1650.8402   1599.2010   1503.6163
   1842.3607   1762.4062   1656.8314
   1840.7898   1747.4661   1645.6095
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 95
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 19950
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 95
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 95
[torch.LongStorage of size 2]

shift_y size:	
 70
 95
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6650
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 19950
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  19950
[torch.LongStorage of size 1]
	
  first line: 3727.1733398438	
(fast bbox transform) src_w size:  19950
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 19950
     4
[torch.LongStorage of size 2]

scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 19950
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 53200
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13300
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13300
[torch.LongStorage of size 1]

test img #34: time = 0.420551	
(proposal_test:boxes_filter) boxes & scores size:	
 13300
     4
[torch.LongStorage of size 2]

 13300
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 953
   3
[torch.LongTensor of size 2]

mask size:	
 13300
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   4.8000e+02   4.8000e+02
        -inf         -inf   3.6486e+04   2.1534e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #35	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00100001/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 480
 480
[torch.LongStorage of size 3]

x_start = 1 / y_start = 61	
img_means:size() vs img:size():	
   3
 360
 480
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6666666666667	
(orep_img_for_blob) img size after scaling:	
   3
 600
 800
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x97
  2 : CudaTensor - size: 18x72x97
  3 : CudaTensor - size: 18x70x95
  4 : CudaTensor - size: 18x68x93
  5 : CudaTensor - size: 256x74x99
}
proposal_im_deteect: img_blob size:    3
 600
 800
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 360
 480
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6666666666667	
proposal_im_detect: scaled_img_size:	
   5
 600
 800
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1913.7581  -2155.0618  -2079.5688
  -2042.6796  -2276.3137  -2168.8066
  -2003.2877  -2193.9880  -2070.4292

(2,.,.) = 
   2865.7815   3030.5151   2920.5796
   3074.3010   3256.7285   3103.3167
   2969.5403   3119.8179   2951.9937

(3,.,.) = 
   3713.3657   4046.1101   4046.0938
   4554.0732   4973.8003   4966.6123
   4980.3887   5465.0527   5441.4922

(4,.,.) = 
   1066.6747   1189.3284   1167.1018
   1332.7418   1435.9148   1383.7096
   1447.7747   1504.0256   1410.4313

(5,.,.) = 
    756.5343    748.0355    668.1901
    743.1891    696.7382    589.2809
    759.0612    677.2855    568.4573

(6,.,.) = 
   1667.2549   1889.7063   1932.1588
   2045.4359   2357.3069   2400.7993
   2351.3735   2700.1350   2727.3142

(7,.,.) = 
  -2771.4597  -2944.7205  -2768.5916
  -2992.1804  -3145.2102  -2881.6526
  -2870.4167  -2948.4048  -2655.7642

(8,.,.) = 
   5807.5620   6222.6021   5979.3071
   6548.6870   6980.6934   6656.0898
   6815.5376   7193.9565   6820.0249

(9,.,.) = 
   2556.5732   3073.6360   3276.7910
   2947.5439   3479.0793   3609.4517
   3219.5986   3758.3521   3845.2490

(10,.,.) = 
  -3419.6897  -3379.0825  -3131.2319
  -3664.6626  -3631.3352  -3362.0413
  -3630.8047  -3588.3979  -3342.2280

(11,.,.) = 
    487.4532    648.4379    739.0568
    760.0198    951.0182   1038.4379
    850.8820   1088.8657   1179.4850

(12,.,.) = 
    447.1236    720.7225    955.4460
    515.7823    835.5454   1059.8188
    274.7474    593.5806    790.2651

(13,.,.) = 
  -2943.1350  -3111.8257  -3010.3958
  -2968.8022  -3124.8442  -3011.0916
  -2904.2725  -3050.7461  -2909.4944

(14,.,.) = 
   5076.8721   5380.2471   5184.5576
   5354.9785   5648.3140   5409.6743
   5302.4414   5618.8618   5348.9844

(15,.,.) = 
   3474.9153   3769.7415   3743.7549
   4049.0144   4441.2085   4391.3896
   4384.4873   4797.2285   4725.0693

(16,.,.) = 
  -2939.8337  -3022.1743  -3011.8877
  -3074.3010  -3190.6350  -3167.8931
  -3209.5662  -3354.5100  -3318.2090

(17,.,.) = 
  -7638.2373  -8040.9385  -7940.6865
  -8767.9834  -9282.4873  -9180.5303
  -9474.8545 -10052.4971  -9928.8643

(18,.,.) = 
   1646.7913   1595.5608   1499.8628
   1837.2883   1757.8739   1652.0323
   1834.9154   1741.8350   1639.4648
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 95
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 19950
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 95
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 95
[torch.LongStorage of size 2]

shift_y size:	
 70
 95
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6650
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 19950
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  19950
[torch.LongStorage of size 1]
	
  first line: 3713.3657226562	
(fast bbox transform) src_w size:  19950
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 19950
     4
[torch.LongStorage of size 2]

scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 19950
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 53200
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13300
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13300
[torch.LongStorage of size 1]

test img #35: time = 0.385451	
(proposal_test:boxes_filter) boxes & scores size:	
 13300
     4
[torch.LongStorage of size 2]

 13300
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 953
   3
[torch.LongTensor of size 2]

mask size:	
 13300
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   4.8000e+02   4.8000e+02
        -inf         -inf   3.6311e+04   2.1413e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #36	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00067001/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1902.5082 -2141.5120 -2066.0820
 -2029.2778 -2260.8291 -2153.4531
 -1989.6670 -2178.6062 -2055.8684

(2,.,.) = 
  2849.2468  3011.8870  2901.1165
  3055.3655  3234.9824  3081.8921
  2951.1833  3099.0859  2931.7385

(3,.,.) = 
  3665.1875  3994.7346  3997.0747
  4499.6553  4915.3638  4910.7705
  4926.8877  5407.4380  5387.2017

(4,.,.) = 
  1048.1514  1168.8484  1147.6783
  1312.1075  1414.1829  1363.5293
  1428.5657  1484.0126  1392.4500

(5,.,.) = 
   744.7821   736.2245   657.8361
   732.0555   685.4052   579.3425
   749.2810   667.5709   559.4011

(6,.,.) = 
  1640.1940  1859.1998  1902.3311
  2015.2972  2323.2532  2367.4419
  2320.7419  2665.5515  2693.7959

(7,.,.) = 
 -2745.1709 -2915.8738 -2739.6030
 -2963.7676 -3114.1484 -2851.6284
 -2843.9431 -2919.9858 -2628.5769

(8,.,.) = 
  5744.6348  6156.0264  5915.8921
  6481.1787  6909.6685  6589.6479
  6751.1064  7126.5493  6757.8594

(9,.,.) = 
  2522.5566  3034.6040  3236.4653
  2908.9402  3435.6094  3565.7036
  3182.5930  3717.1204  3804.4622

(10,.,.) = 
 -3395.9360 -3355.0322 -3107.6672
 -3639.7522 -3606.0146 -3337.9380
 -3606.2822 -3563.4832 -3318.2915

(11,.,.) = 
   478.9962   638.7479   730.2565
   750.8030   940.6080  1028.4734
   842.4078  1078.3801  1168.9215

(12,.,.) = 
   445.6458   716.2868   949.4418
   512.8301   828.9402  1051.4474
   271.1445   586.1492   780.9839

(13,.,.) = 
 -2923.4438 -3090.6614 -2988.7969
 -2948.1836 -3102.1685 -2987.5969
 -2883.4585 -3028.6021 -2887.6060

(14,.,.) = 
  5037.5615  5338.5190  5144.1289
  5313.8599  5605.5068  5368.0063
  5261.7183  5576.5640  5308.4849

(15,.,.) = 
  3428.6875  3719.7271  3695.9246
  3998.9636  4387.1392  4339.9961
  4335.3535  4744.3848  4675.4839

(16,.,.) = 
 -2910.2122 -2991.6526 -2982.4468
 -3041.5325 -3157.4565 -3136.6724
 -3177.3088 -3321.3875 -3287.1580

(17,.,.) = 
 -7546.7900 -7945.9604 -7850.1792
 -8669.0811 -9179.3613 -9081.7773
 -9377.4082 -9950.7939 -9832.3467

(18,.,.) = 
  1635.2206  1584.3066  1488.7228
  1824.2263  1745.5983  1639.6407
  1821.3203  1728.8899  1626.4293
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3665.1875	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #36: time = 0.53909299999999	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2170e+04   4.2696e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #37	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00050004/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1901.5978 -2140.1011 -2064.7512
 -2026.3506 -2257.3496 -2149.9143
 -1985.5958 -2173.5601 -2050.5210

(2,.,.) = 
  2847.8591  3010.4402  2899.3022
  3052.1653  3231.3120  3077.8071
  2946.4639  3093.5129  2925.5493

(3,.,.) = 
  3656.4951  3983.3354  3983.6885
  4487.0718  4899.4185  4892.6289
  4910.4033  5387.4673  5365.2129

(4,.,.) = 
  1044.9165  1164.4640  1142.1942
  1307.3026  1407.9655  1356.0387
  1422.0450  1476.0131  1383.6147

(5,.,.) = 
   742.4355   733.5380   655.5579
   728.5927   681.2007   575.3998
   745.2252   662.7661   554.3339

(6,.,.) = 
  1634.1047  1852.2109  1894.6150
  2007.8569  2314.6584  2358.2166
  2312.4746  2655.6699  2683.2439

(7,.,.) = 
 -2739.5032 -2910.1443 -2733.7996
 -2955.6909 -3105.9021 -2843.6357
 -2834.4548 -2910.3296 -2619.2258

(8,.,.) = 
  5730.7085  6140.0293  5898.4385
  6461.8188  6887.4165  6565.9121
  6727.8096  7099.6572  6729.3413

(9,.,.) = 
  2515.8071  3026.6580  3226.6636
  2898.5510  3423.8821  3552.4895
  3170.5027  3703.4592  3789.3643

(10,.,.) = 
 -3392.0400 -3350.4814 -3101.8630
 -3632.5496 -3597.7405 -3328.7954
 -3595.8093 -3551.7891 -3305.4937

(11,.,.) = 
   477.0916   636.1868   727.1390
   749.0027   938.2949  1025.3815
   840.0457  1075.4309  1165.2906

(12,.,.) = 
   447.7406   718.7568   951.7688
   515.1357   831.7917  1054.3949
   272.7412   588.1337   783.1240

(13,.,.) = 
 -2921.7920 -3089.4233 -2987.1946
 -2943.9807 -3098.2681 -2983.4397
 -2877.8699 -3022.9099 -2881.7058

(14,.,.) = 
  5031.6675  5332.0527  5136.4648
  5303.6831  5594.4502  5355.7896
  5248.0249  5561.3320  5291.9946

(15,.,.) = 
  3418.2119  3706.9983  3681.5269
  3984.7271  4370.1089  4321.3325
  4318.4922  4724.0991  4653.5630

(16,.,.) = 
 -2906.0872 -2985.9324 -2974.8442
 -3033.6226 -3147.6833 -3124.8621
 -3166.3926 -3308.2483 -3271.9883

(17,.,.) = 
 -7530.8618 -7926.2354 -7826.5513
 -8645.1035 -9150.4609 -9048.5986
 -9346.2910 -9913.8906 -9791.0371

(18,.,.) = 
  1633.2793  1582.1116  1485.9926
  1820.7520  1741.5858  1634.8704
  1815.8242  1722.9839  1619.8391
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3656.4951171875	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #37: time = 0.539448	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1671e+04   4.2372e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #38	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00035000/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1897.9080 -2136.0544 -2061.0376
 -2022.7090 -2253.3042 -2146.2427
 -1982.1104 -2169.7607 -2047.2607

(2,.,.) = 
  2842.3167  3004.5955  2894.3005
  3046.1089  3224.9380  3072.1743
  2940.6851  3087.6018  2920.3889

(3,.,.) = 
  3648.1975  3975.0776  3976.9834
  4475.2051  4887.0659  4881.9644
  4895.9443  5371.8726  5351.3276

(4,.,.) = 
  1042.6023  1162.2330  1140.6207
  1304.2920  1404.9351  1353.7917
  1418.5674  1472.4142  1380.8811

(5,.,.) = 
   740.4234   731.9056   654.0295
   726.8030   679.7619   574.2315
   743.5621   661.2731   553.1001

(6,.,.) = 
  1629.3071  1846.7742  1889.7766
  2000.8009  2306.8657  2351.2183
  2303.8323  2646.5552  2675.2263

(7,.,.) = 
 -2733.0698 -2902.9578 -2726.8069
 -2948.2871 -3097.6968 -2835.6848
 -2826.7285 -2902.1536 -2611.7646

(8,.,.) = 
  5717.8135  6126.5601  5886.5645
  6445.6187  6870.2964  6550.4487
  6709.4263  7080.4116  6712.2256

(9,.,.) = 
  2510.7925  3020.3469  3220.4714
  2891.6460  3415.4863  3544.2805
  3161.1296  3692.5310  3778.9878

(10,.,.) = 
 -3386.1147 -3344.5198 -3097.0398
 -3625.0032 -3590.1743 -3322.3635
 -3587.1384 -3543.2241 -3298.2041

(11,.,.) = 
   475.3491   634.2720   725.7306
   746.0824   935.1104  1022.6703
   836.9650  1071.8813  1161.9163

(12,.,.) = 
   446.2799   716.3475   949.4253
   513.4416   828.9831  1051.6812
   271.9323   586.3493   781.3130

(13,.,.) = 
 -2916.4824 -3083.3201 -2981.0022
 -2937.9045 -3091.3638 -2976.4009
 -2870.9019 -3015.3596 -2874.4958

(14,.,.) = 
  5021.7812  5321.3828  5126.6772
  5292.1729  5582.2002  5344.3633
  5235.2871  5547.9097  5279.8271

(15,.,.) = 
  3410.0625  3698.5471  3674.4065
  3973.7769  4358.3550  4310.9219
  4305.4312  4710.2417  4641.3794

(16,.,.) = 
 -2900.9680 -2981.3787 -2971.5234
 -3027.4897 -3141.9062 -3120.2378
 -3158.7007 -3300.4561 -3265.2625

(17,.,.) = 
 -7513.2007 -7909.1455 -7812.7891
 -8623.4805 -9128.3594 -9029.8350
 -9320.9531 -9887.4814 -9768.0664

(18,.,.) = 
  1630.5160  1579.4949  1483.8489
  1816.8617  1738.1182  1632.1426
  1811.4081  1718.9006  1616.5845
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3648.1975097656	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #38: time = 0.562046	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1577e+04   4.2279e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #39	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00051010/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1905.9125 -2144.4966 -2068.0229
 -2031.7738 -2262.8118 -2154.1550
 -1990.9513 -2178.9517 -2054.4954

(2,.,.) = 
  2853.6052  3015.6826  2903.3564
  3058.8730  3237.7871  3082.7637
  2952.7871  3099.6987  2930.2417

(3,.,.) = 
  3668.4834  3995.0034  3992.8606
  4499.3154  4911.0034  4901.2241
  4921.4580  5397.4028  5371.8936

(4,.,.) = 
  1048.3717  1167.7649  1144.9111
  1311.4048  1411.4271  1358.5400
  1425.9692  1479.1273  1385.5192

(5,.,.) = 
   746.3429   737.7784   658.9004
   732.5020   685.5690   579.0920
   748.9012   666.6995   557.7767

(6,.,.) = 
  1640.1100  1858.0334  1899.0995
  2013.6274  2320.4907  2362.5439
  2317.3674  2660.7407  2686.7698

(7,.,.) = 
 -2747.0981 -2917.2883 -2739.6130
 -2964.5898 -3114.3914 -2850.3640
 -2843.1577 -2918.4758 -2625.8545

(8,.,.) = 
  5747.1768  6155.3770  5910.3198
  6479.1245  6903.6001  6577.8408
  6743.7153  7114.3584  6739.9463

(9,.,.) = 
  2524.6348  3035.0173  3233.8359
  2908.3098  3432.7922  3559.6055
  3179.3052  3711.3650  3795.4565

(10,.,.) = 
 -3400.0603 -3356.9646 -3106.5054
 -3641.2275 -3605.0935 -3334.1790
 -3603.9258 -3558.6570 -3310.6785

(11,.,.) = 
   476.8250   635.7480   726.7927
   748.9857   937.9424  1025.0599
   839.9384  1075.0671  1164.8668

(12,.,.) = 
   446.2551   716.9536   950.5326
   514.4194   830.7856  1053.6787
   272.2950   587.6588   782.7484

(13,.,.) = 
 -2928.3345 -3095.0608 -2991.5312
 -2951.0266 -3104.5557 -2988.3560
 -2884.6384 -3029.0552 -2886.5452

(14,.,.) = 
  5042.8516  5341.5571  5143.4629
  5315.8203  5604.8970  5363.5933
  5259.6562  5571.5190  5299.5386

(15,.,.) = 
  3429.1724  3717.3765  3689.7449
  3996.0530  4380.7393  4329.2676
  4328.6880  4733.6489  4660.3198

(16,.,.) = 
 -2914.7908 -2993.7214 -2980.9153
 -3042.7954 -3155.8625 -3131.1941
 -3174.8005 -3315.6873 -3277.4834

(17,.,.) = 
 -7552.0737 -7945.3999 -7841.0703
 -8667.1670 -9169.8711 -9062.6543
 -9366.1865 -9930.7461 -9802.1895

(18,.,.) = 
  1636.9905  1585.0354  1488.0997
  1824.5990  1744.7067  1637.2665
  1819.6683  1725.9836  1622.1024
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3668.4833984375	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #39: time = 0.587862	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1776e+04   4.2410e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #40	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00013000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1920
 1920
[torch.LongStorage of size 3]

x_start = 1 / y_start = 421	
img_means:size() vs img:size():	
    3
 1080
 1920
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.55555555555556	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
 1080
 1920
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.55555555555556	
proposal_im_detect: scaled_img_size:	
    2
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1915.9552 -2156.3699 -2080.3015
 -2042.5062 -2275.3496 -2167.1248
 -2001.3904 -2191.1377 -2066.9502

(2,.,.) = 
  2868.5979  3032.2917  2920.6895
  3074.9062  3255.6511  3101.0410
  2967.9607  3116.5688  2947.4663

(3,.,.) = 
  3694.0325  4023.9663  4023.4294
  4529.1157  4944.9053  4936.9585
  4952.1611  5432.2349  5408.4360

(4,.,.) = 
  1056.1416  1176.8602  1154.5498
  1320.8856  1422.0317  1369.6506
  1435.6523  1489.6918  1396.5038

(5,.,.) = 
   751.2313   742.7902   663.7260
   737.2668   690.4017   583.5759
   753.6414   671.2002   562.0134

(6,.,.) = 
  1651.9156  1871.8474  1914.0695
  2027.0679  2336.4045  2379.7131
  2331.5107  2677.5037  2704.7444

(7,.,.) = 
 -2761.2534 -2933.1995 -2755.8352
 -2979.0530 -3130.4216 -2866.0630
 -2855.5745 -2931.9512 -2638.7700

(8,.,.) = 
  5781.7920  6194.0015  5950.2329
  6516.6851  6945.4106  6620.4614
  6780.1704  7154.5664  6780.7471

(9,.,.) = 
  2540.6213  3054.6133  3255.7993
  2925.8792  3453.8625  3582.7593
  3196.7388  3732.0195  3817.8091

(10,.,.) = 
 -3420.4551 -3378.4578 -3128.2876
 -3662.7461 -3627.6265 -3356.7651
 -3623.8914 -3579.5879 -3331.6377

(11,.,.) = 
   480.4301   640.5007   732.1785
   753.7642   943.9496  1031.7363
   844.1868  1080.7731  1171.2678

(12,.,.) = 
   447.9427   720.2068   955.1677
   516.3909   834.5770  1058.8137
   273.5131   590.5032   786.9385

(13,.,.) = 
 -2942.6548 -3110.9578 -3007.8472
 -2964.6597 -3119.7422 -3003.8628
 -2897.3364 -3043.1985 -2900.6504

(14,.,.) = 
  5070.2139  5371.9775  5174.7354
  5343.7461  5635.7559  5395.0942
  5285.9727  5600.9067  5329.3794

(15,.,.) = 
  3452.3525  3743.7390  3717.5881
  4021.7500  4410.1113  4360.1694
  4354.8169  4763.3335  4691.4253

(16,.,.) = 
 -2934.0845 -3014.7466 -3003.1343
 -3063.1995 -3177.9812 -3154.1826
 -3195.2246 -3337.9536 -3300.4421

(17,.,.) = 
 -7603.0093 -8001.6777 -7900.1777
 -8724.0205 -9232.7139 -9128.8193
 -9424.9043 -9995.5830 -9870.1719

(18,.,.) = 
  1646.6108  1595.0598  1498.4681
  1835.4120  1755.6702  1648.5396
  1830.2477  1736.5583  1632.9896
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3694.0324707031	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #40: time = 0.865442	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.9200e+03   1.9200e+03
        -inf         -inf   1.0814e+05   6.3960e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #41	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00042000/000006.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1903.0605 -2141.7068 -2066.2278
 -2028.5812 -2259.6782 -2152.1428
 -1987.8514 -2176.1096 -2052.8101

(2,.,.) = 
  2849.3672  3011.8000  2900.8518
  3054.1909  3233.4080  3079.8667
  2948.2659  3095.5369  2927.5208

(3,.,.) = 
  3663.1292  3990.2292  3989.6692
  4492.9316  4905.3418  4897.4731
  4914.8711  5391.4512  5368.0137

(4,.,.) = 
  1046.6455  1166.2407  1143.9368
  1309.8016  1410.1111  1357.9041
  1424.3876  1478.0371  1385.3427

(5,.,.) = 
   744.6590   736.2362   657.8370
   731.0262   684.2881   578.2184
   747.6241   665.6146   556.9851

(6,.,.) = 
  1637.1589  1855.1042  1896.9766
  2010.2382  2317.0693  2360.0107
  2313.8318  2657.1370  2684.1814

(7,.,.) = 
 -2740.6240 -2911.1465 -2734.7554
 -2957.6628 -3107.8103 -2845.2603
 -2836.4087 -2912.1870 -2621.0972

(8,.,.) = 
  5736.6704  6145.6489  5903.5166
  6467.8765  6893.3052  6570.7905
  6732.5801  7104.3394  6733.2871

(9,.,.) = 
  2519.4331  3029.5142  3228.9038
  2902.3049  3426.5916  3554.3696
  3173.0586  3705.0081  3790.3669

(10,.,.) = 
 -3396.0054 -3354.0200 -3105.1489
 -3636.9165 -3601.7637 -3332.5083
 -3599.5181 -3555.2021 -3308.7263

(11,.,.) = 
   476.2958   635.2416   726.4655
   748.2629   937.2752  1024.5835
   838.7834  1073.8842  1163.9417

(12,.,.) = 
   445.6388   716.0218   949.4412
   513.5267   829.5066  1052.3821
   271.5758   586.4821   781.7817

(13,.,.) = 
 -2922.5244 -3089.7161 -2987.2922
 -2944.4104 -3098.3584 -2983.2566
 -2878.0708 -3022.8918 -2881.5369

(14,.,.) = 
  5034.2070  5333.8486  5138.0229
  5306.4668  5596.5176  5357.4556
  5250.4307  5563.2441  5293.6309

(15,.,.) = 
  3423.4021  3712.1719  3686.2373
  3989.7878  4375.0205  4325.4707
  4322.4536  4728.0293  4656.8252

(16,.,.) = 
 -2911.5447 -2991.4260 -2979.7935
 -3039.3115 -3153.2864 -3129.7100
 -3171.0803 -3312.7507 -3275.6880

(17,.,.) = 
 -7541.4849 -7936.6465 -7835.7495
 -8655.7139 -9160.2266 -9056.8145
 -9354.7344 -9921.2627 -9796.7490

(18,.,.) = 
  1634.8943  1583.6411  1487.5200
  1822.3922  1743.2206  1636.6217
  1817.4343  1724.4022  1621.3063
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3663.1291503906	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #41: time = 0.601692	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1726e+04   4.2402e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #42	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00044001/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1913.8964 -2153.7432 -2077.2490
 -2040.0797 -2272.1321 -2163.1973
 -1999.1910 -2188.0513 -2063.0667

(2,.,.) = 
  2866.0637  3028.9246  2916.5405
  3072.0662  3251.7129  3095.9846
  2965.4387  3112.7668  2942.2883

(3,.,.) = 
  3689.6992  4018.5479  4017.0872
  4524.3159  4938.5098  4929.1558
  4947.6118  5426.0010  5400.3564

(4,.,.) = 
  1054.3423  1174.6083  1152.0908
  1318.5669  1419.0449  1366.2582
  1433.3708  1486.8907  1393.3588

(5,.,.) = 
   751.3497   742.4861   662.7318
   737.0931   689.7480   582.0326
   753.2317   670.2331   560.0397

(6,.,.) = 
  1649.6003  1868.9454  1910.9333
  2024.9773  2333.4805  2376.4194
  2330.0444  2674.7568  2701.2661

(7,.,.) = 
 -2759.5735 -2930.8337 -2752.8772
 -2977.7964 -3128.4822 -2863.7678
 -2855.4243 -2931.3279 -2637.7717

(8,.,.) = 
  5776.0635  6186.4883  5940.8784
  6510.8960  6937.5117  6610.6113
  6776.1646  7148.6318  6772.8745

(9,.,.) = 
  2538.0520  3050.9131  3251.0015
  2923.3555  3450.3398  3578.0659
  3195.3220  3729.8914  3814.6785

(10,.,.) = 
 -3417.1472 -3373.9780 -3122.5759
 -3659.2271 -3623.0708 -3351.2180
 -3621.4702 -3576.3398 -3327.6174

(11,.,.) = 
   479.9957   640.0353   731.6839
   753.4901   943.6585  1031.3760
   844.2966  1080.8732  1171.3656

(12,.,.) = 
   448.5600   720.9339   956.3239
   516.8945   835.1940  1059.8469
   273.4021   590.5286   787.0293

(13,.,.) = 
 -2940.4189 -3108.0117 -3003.9504
 -2962.7422 -3117.3679 -3000.4736
 -2896.5837 -3042.0022 -2898.4824

(14,.,.) = 
  5065.6045  5365.8657  5166.9438
  5339.4102  5630.0894  5387.8208
  5283.4351  5597.1567  5324.0962

(15,.,.) = 
  3447.7107  3737.8733  3710.7161
  4017.0750  4404.0854  4353.0220
  4351.1914  4758.3662  4685.3457

(16,.,.) = 
 -2930.7781 -3010.3889 -2997.3196
 -3059.0854 -3172.8201 -3147.5171
 -3191.4653 -3333.1494 -3294.4521

(17,.,.) = 
 -7593.1729 -7989.3970 -7885.7080
 -8713.5732 -9219.3701 -9112.7100
 -9415.6279 -9983.3730 -9854.9580

(18,.,.) = 
  1645.4211  1593.2782  1495.8607
  1833.7064  1753.2888  1645.3625
  1828.4564  1734.1514  1629.6785
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3689.69921875	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #42: time = 0.688328	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2133e+04   4.2642e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #43	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0001/ILSVRC2015_train_00151000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1908.1387 -2147.8132 -2072.4568
 -2033.8282 -2265.8840 -2158.3945
 -1992.4478 -2181.4585 -2058.1958

(2,.,.) = 
  2857.6553  3021.0510  2910.2571
  3062.7439  3243.0508  3089.3240
  2955.7761  3103.9163  2935.6050

(3,.,.) = 
  3673.6326  4002.3965  4002.7612
  4505.7866  4920.0664  4913.1479
  4928.4854  5406.9580  5384.3242

(4,.,.) = 
  1050.3148  1170.5378  1148.2939
  1314.1193  1415.1600  1362.9763
  1428.9841  1483.1375  1390.3058

(5,.,.) = 
   745.7284   737.1979   658.9330
   731.9062   684.7849   578.8243
   748.5912   666.0615   557.5217

(6,.,.) = 
  1642.7133  1861.9608  1904.4438
  2017.1598  2325.6809  2369.4609
  2321.1938  2666.2559  2693.9045

(7,.,.) = 
 -2750.3691 -2921.8406 -2745.1675
 -2967.3853 -3118.2971 -2855.0376
 -2844.7322 -2920.9768 -2628.9041

(8,.,.) = 
  5753.6855  6164.6592  5922.2676
  6486.4277  6913.5449  6590.4595
  6750.8706  7123.9678  6752.1572

(9,.,.) = 
  2528.1702  3040.8447  3241.6584
  2911.9773  3438.9031  3567.7861
  3182.9297  3717.4905  3803.4207

(10,.,.) = 
 -3404.6133 -3363.0210 -3113.8552
 -3645.8677 -3611.0376 -3341.2739
 -3607.8162 -3563.7700 -3317.0791

(11,.,.) = 
   478.4829   637.9429   729.0035
   751.4104   941.1559  1028.4271
   842.3745  1078.4480  1168.4774

(12,.,.) = 
   449.4685   721.2167   955.0296
   517.5988   835.0992  1058.3031
   274.6082   591.0163   786.5390

(13,.,.) = 
 -2931.8230 -3099.9385 -2997.6804
 -2953.6316 -3108.4631 -2993.4380
 -2886.2686 -3031.8608 -2890.3877

(14,.,.) = 
  5049.3462  5350.4888  5154.5205
  5321.8247  5613.1851  5373.8213
  5264.4702  5578.6733  5308.6558

(15,.,.) = 
  3433.7239  3724.0352  3698.4558
  4001.7051  4388.6113  4339.3916
  4334.6919  4741.8789  4670.8374

(16,.,.) = 
 -2918.6523 -2999.1533 -2988.2329
 -3046.5854 -3161.2378 -3138.3887
 -3178.6497 -3320.9873 -3284.6509

(17,.,.) = 
 -7563.0322 -7960.5562 -7860.8403
 -8680.2178 -9187.5889 -9085.4072
 -9380.6348 -9950.1055 -9826.7217

(18,.,.) = 
  1639.5040  1588.3282  1492.1178
  1827.2581  1747.9017  1641.1376
  1821.9221  1728.6958  1625.4207
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3673.6325683594	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #43: time = 0.599659	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1919e+04   4.2507e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #44	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00005001/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  576
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 353	
img_means:size() vs img:size():	
    3
  576
 1280
[torch.LongStorage of size 3]

    3
  576
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.0416666666667	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1333
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x164
  2 : CudaTensor - size: 18x72x164
  3 : CudaTensor - size: 18x70x162
  4 : CudaTensor - size: 18x68x160
  5 : CudaTensor - size: 256x74x166
}
proposal_im_deteect: img_blob size:     3
  600
 1333
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  576
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.0416666666667	
proposal_im_detect: scaled_img_size:	
    3
  600
 1333
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1896.1945 -2133.1584 -2057.2134
 -2020.5570 -2250.0398 -2141.8286
 -1980.1943 -2166.7134 -2042.8685

(2,.,.) = 
  2838.8179  2999.5791  2887.7605
  3042.4097  3219.3796  3065.1641
  2937.4863  3082.3704  2913.4507

(3,.,.) = 
  3636.7217  3960.8994  3959.8601
  4462.3467  4870.8027  4861.9897
  4884.0820  5356.4263  5331.8423

(4,.,.) = 
  1036.5659  1154.7758  1132.2926
  1298.1881  1397.3344  1345.0217
  1413.2921  1465.7767  1373.2906

(5,.,.) = 
   738.5267   729.6615   651.6363
   725.3476   677.9944   572.1520
   743.1756   660.5302   551.3136

(6,.,.) = 
  1622.9240  1838.5188  1879.9995
  1994.5397  2298.5376  2340.7830
  2297.5967  2637.8765  2664.1882

(7,.,.) = 
 -2726.9707 -2895.2205 -2718.1165
 -2943.2896 -3090.8621 -2827.8411
 -2824.0994 -2897.7390 -2606.0234

(8,.,.) = 
  5701.6704  6106.2451  5863.4834
  6430.3682  6850.7861  6527.5708
  6697.8721  7064.5757  6692.4834

(9,.,.) = 
  2501.9570  3008.3826  3205.8081
  2882.2224  3402.5613  3528.4741
  3153.8977  3682.0879  3765.6594

(10,.,.) = 
 -3381.5908 -3338.0400 -3088.5791
 -3622.2310 -3585.0193 -3315.2212
 -3585.9736 -3539.3428 -3291.5928

(11,.,.) = 
   471.4843   629.2779   720.4373
   743.1719   931.0764  1017.9763
   833.8042  1067.5637  1156.9634

(12,.,.) = 
   444.3832   713.5233   945.9565
   511.2999   825.7919  1047.6582
   268.9851   582.2210   776.6425

(13,.,.) = 
 -2911.6204 -3076.7756 -2973.3882
 -2933.3616 -3084.7639 -2968.0596
 -2867.9932 -3010.5105 -2867.6294

(14,.,.) = 
  5011.0259  5307.1069  5110.3774
  5282.9019  5569.2144  5328.5903
  5228.9146  5537.5781  5266.1108

(15,.,.) = 
  3398.0181  3683.4648  3656.9561
  3962.1399  4343.3594  4293.0327
  4295.6519  4697.0991  4624.9932

(16,.,.) = 
 -2894.6646 -2972.6006 -2960.3896
 -3020.9221 -3132.7090 -3108.4131
 -3153.6460 -3292.1506 -3253.9868

(17,.,.) = 
 -7488.7886 -7878.9756 -7777.2402
 -8598.2305 -9096.2881 -8990.8691
 -9298.0977 -9857.2363 -9730.1123

(18,.,.) = 
  1627.2561  1575.5663  1479.3463
  1813.9401  1734.3019  1627.2394
  1809.1958  1715.3303  1611.4404
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 162
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 34020
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 162
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 162
[torch.LongStorage of size 2]

shift_y size:	
  70
 162
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
     3
 11340
     4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 34020
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 34020
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 34020
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  34020
[torch.LongStorage of size 1]
	
  first line: 3636.7216796875	
(fast bbox transform) src_w size:  34020
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 34020
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 34020
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 34020
     4
[torch.LongStorage of size 2]

scores size:	
 34020
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 34020
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 34020
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 34020
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 90720
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 22680
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 22680
[torch.LongStorage of size 1]

test img #44: time = 0.623899	
(proposal_test:boxes_filter) boxes & scores size:	
 22680
     4
[torch.LongStorage of size 2]

 22680
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 3
[torch.LongStorage of size 1]

 1947
    3
    4
[torch.LongTensor of size 3]

mask size:	
 22680
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 12
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
  1.0000e+00   1.0000e+00   5.7600e+02   5.7600e+02
        -inf         -inf   5.7223e+04   3.3664e+04
[torch.CudaTensor of size 3x4]

(proposal_test:boxes_filter) boxes size returned:	
 3
 4
[torch.LongStorage of size 2]

img #45	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00108002/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 240
 320
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 320
 320
[torch.LongStorage of size 3]

x_start = 1 / y_start = 41	
img_means:size() vs img:size():	
   3
 240
 320
[torch.LongStorage of size 3]

   3
 240
 320
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 2.5	
(orep_img_for_blob) img size after scaling:	
   3
 600
 800
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x97
  2 : CudaTensor - size: 18x72x97
  3 : CudaTensor - size: 18x70x95
  4 : CudaTensor - size: 18x68x93
  5 : CudaTensor - size: 256x74x99
}
proposal_im_deteect: img_blob size:    3
 600
 800
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 240
 320
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 2.5	
proposal_im_detect: scaled_img_size:	
   8
 600
 800
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1919.5315  -2160.4138  -2082.1389
  -2049.5471  -2282.6414  -2172.0461
  -2010.0720  -2200.3130  -2073.4241

(2,.,.) = 
   2874.8323   3037.7253   2923.8438
   3084.8635   3265.5066   3107.6462
   2979.8328   3128.7905   2956.5039

(3,.,.) = 
   3726.8276   4055.3662   4049.3274
   4569.9160   4984.5552   4970.2939
   4996.9277   5476.4595   5445.3081

(4,.,.) = 
   1070.5808   1192.2399   1168.6929
   1336.9603   1438.8909   1385.2505
   1452.2397   1506.6731   1411.4647

(5,.,.) = 
    762.6296    752.3989    669.8682
    749.2623    701.2672    591.3984
    765.3281    682.0275    571.2071

(6,.,.) = 
   1674.2058   1895.0511   1934.8633
   2053.3313   2363.3792   2403.7283
   2359.5474   2706.2173   2729.9211

(7,.,.) = 
  -2784.7141  -2956.4553  -2776.6399
  -3006.2939  -3158.0791  -2890.6409
  -2883.9314  -2960.9124  -2665.0020

(8,.,.) = 
   5831.1963   6241.0581   5988.7202
   6573.8965   7000.3540   6665.9761
   6840.2529   7213.1084   6829.6606

(9,.,.) = 
   2567.2852   3083.4751   3284.4504
   2959.4226   3489.8303   3617.2979
   3231.6382   3768.9998   3852.5784

(10,.,.) = 
  -3430.0305  -3385.8003  -3132.9675
  -3675.6609  -3638.8127  -3364.2507
  -3641.0359  -3595.7971  -3344.9524

(11,.,.) = 
    488.4058    649.0347    739.2412
    761.3488    951.7464   1038.6874
    852.1614   1089.7424   1179.8794

(12,.,.) = 
    447.1246    721.9579    957.4701
    516.6960    838.1117   1063.0980
    275.4472    595.9712    793.3958

(13,.,.) = 
  -2955.3352  -3122.4810  -3017.1069
  -2981.8938  -3137.0166  -3019.0151
  -2916.9983  -3062.7119  -2917.0972

(14,.,.) = 
   5095.6636   5395.3735   5192.1992
   5374.7710   5664.8726   5418.6157
   5321.3530   5635.2256   5357.7471

(15,.,.) = 
   3488.3406   3779.9995   3748.7192
   4063.7578   4452.7148   4396.9277
   4399.2124   4808.5269   4730.2729

(16,.,.) = 
  -2949.6455  -3028.0681  -3013.0635
  -3085.5022  -3197.8896  -3170.2251
  -3221.7178  -3362.9163  -3321.4919

(17,.,.) = 
  -7664.9971  -8058.9087  -7946.2397
  -8797.8887  -9302.7529  -9187.0889
  -9505.3154 -10072.9297  -9935.0205

(18,.,.) = 
   1652.1006   1598.2694   1499.8602
   1843.1049   1760.6793   1652.2729
   1840.7512   1744.9435   1640.4432
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 95
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 19950
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 95
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 95
[torch.LongStorage of size 2]

shift_y size:	
 70
 95
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6650
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 19950
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  19950
[torch.LongStorage of size 1]
	
  first line: 3726.8276367188	
(fast bbox transform) src_w size:  19950
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 19950
     4
[torch.LongStorage of size 2]

scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 19950
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 53200
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13300
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13300
[torch.LongStorage of size 1]

test img #45: time = 0.332864	
(proposal_test:boxes_filter) boxes & scores size:	
 13300
     4
[torch.LongStorage of size 2]

 13300
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 953
   3
[torch.LongTensor of size 2]

mask size:	
 13300
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   3.2000e+02   3.2000e+02
        -inf         -inf   2.4208e+04   1.4264e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #46	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00012003/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 480
 480
[torch.LongStorage of size 3]

x_start = 1 / y_start = 61	
img_means:size() vs img:size():	
   3
 360
 480
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6666666666667	
(orep_img_for_blob) img size after scaling:	
   3
 600
 800
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x97
  2 : CudaTensor - size: 18x72x97
  3 : CudaTensor - size: 18x70x95
  4 : CudaTensor - size: 18x68x93
  5 : CudaTensor - size: 256x74x99
}
proposal_im_deteect: img_blob size:    3
 600
 800
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 360
 480
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6666666666667	
proposal_im_detect: scaled_img_size:	
   5
 600
 800
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1927.7418  -2171.0049  -2095.1370
  -2058.2979  -2293.9187  -2186.0508
  -2018.8284  -2211.4290  -2087.2896

(2,.,.) = 
   2886.3118   3052.6099   2942.3621
   3096.8896   3281.3804   3127.2715
   2991.1011   3143.6416   2975.1699

(3,.,.) = 
   3748.2542   4083.3672   4082.3972
   4594.8096   5017.2329   5008.7329
   5022.8799   5510.1084   5484.7070

(4,.,.) = 
   1077.8473   1201.4512   1178.7689
   1346.4192   1449.9326   1396.8206
   1462.0050   1518.0406   1423.1770

(5,.,.) = 
    764.7347    756.3162    675.7338
    751.4916    705.1262    596.9433
    767.5276    685.6047    576.3672

(6,.,.) = 
   1683.8733   1908.4447   1950.6783
   2064.3994   2379.1199   2422.6057
   2371.9065   2723.7241   2750.8354

(7,.,.) = 
  -2792.8416  -2967.8323  -2790.8418
  -3015.0547  -3170.1619  -2905.2659
  -2891.9338  -2971.8479  -2678.2319

(8,.,.) = 
   5856.4297   6274.4106   6028.8403
   6601.9771   7036.9971   6709.1260
   6868.4170   7249.3418   6871.9429

(9,.,.) = 
   2579.5562   3100.4072   3304.6826
   2973.1426   3508.3418   3639.3840
   3245.4614   3787.6782   3874.9441

(10,.,.) = 
  -3446.0137  -3405.4456  -3155.9751
  -3692.1079  -3659.1602  -3388.0620
  -3656.4399  -3614.7578  -3367.3350

(11,.,.) = 
    491.7854    653.8797    744.6036
    765.8220    957.8176   1045.1947
    856.4593   1095.7380   1186.3026

(12,.,.) = 
    449.4713    725.2426    961.6201
    519.4944    841.8340   1067.7463
    278.1096    599.6925    797.9929

(13,.,.) = 
  -2964.2837  -3134.6201  -3032.6951
  -2989.5552  -3147.8379  -3033.9441
  -2923.7231  -3072.4678  -2930.8909

(14,.,.) = 
   5115.4683   5421.3472   5224.0151
   5394.6992   5690.6895   5450.4072
   5340.1011   5659.5396   5387.8643

(15,.,.) = 
   3507.1877   3804.3682   3777.3506
   4084.9553   4479.9893   4428.7603
   4421.4883   4836.8325   4762.8618

(16,.,.) = 
  -2966.0623  -3049.1062  -3038.0535
  -3102.1584  -3219.2173  -3195.2881
  -3237.3269  -3383.2996  -3345.4856

(17,.,.) = 
  -7708.2104  -8113.6084  -8010.8936
  -8846.0605  -9363.3330  -9258.4932
  -9555.2539 -10135.3604 -10007.8457

(18,.,.) = 
   1659.6156   1608.0312   1511.7959
   1851.4233   1771.3441   1664.9586
   1848.8900   1755.2207   1652.5167
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 95
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 19950
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 95
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 95
[torch.LongStorage of size 2]

shift_y size:	
 70
 95
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6650
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 19950
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  19950
[torch.LongStorage of size 1]
	
  first line: 3748.2541503906	
(fast bbox transform) src_w size:  19950
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 19950
     4
[torch.LongStorage of size 2]

scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 19950
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 53200
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13300
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13300
[torch.LongStorage of size 1]

test img #46: time = 0.338363	
(proposal_test:boxes_filter) boxes & scores size:	
 13300
     4
[torch.LongStorage of size 2]

 13300
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 953
   3
[torch.LongTensor of size 2]

mask size:	
 13300
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   4.8000e+02   4.8000e+02
        -inf         -inf   3.6553e+04   2.1540e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #47	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00030003/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1914.9242 -2155.1814 -2079.1313
 -2041.6460 -2274.3267 -2166.0957
 -2000.8368 -2190.4758 -2066.3445

(2,.,.) = 
  2866.9993  3030.5747  2919.0200
  3073.5220  3254.1279  3099.5664
  2967.1045  3115.6245  2946.5142

(3,.,.) = 
  3691.6479  4021.3567  4020.8237
  4527.1714  4942.7661  4934.7993
  4951.5674  5431.6250  5407.7642

(4,.,.) = 
  1055.4462  1176.0798  1153.7642
  1320.3966  1421.5300  1369.1443
  1435.5267  1489.7189  1396.5513

(5,.,.) = 
   750.8373   742.3638   663.3547
   737.0969   690.2305   583.4371
   753.6959   671.2788   562.0587

(6,.,.) = 
  1650.9601  1870.7841  1912.9993
  2026.6646  2335.9343  2379.2358
  2332.0630  2677.9067  2705.1233

(7,.,.) = 
 -2759.8865 -2931.7371 -2754.4592
 -2978.6079 -3130.0120 -2865.8882
 -2856.6687 -2933.2798 -2640.4155

(8,.,.) = 
  5778.4980  6190.4209  5946.7583
  6514.7026  6943.2144  6618.4653
  6780.8091  7155.3169  6781.7183

(9,.,.) = 
  2539.1375  3052.8567  3253.8984
  2924.9736  3452.9290  3581.7930
  3197.0483  3732.5789  3818.5791

(10,.,.) = 
 -3418.2996 -3376.3044 -3126.2830
 -3661.0913 -3626.0410 -3355.3596
 -3623.8445 -3579.7031 -3331.9658

(11,.,.) = 
   480.2291   640.1837   731.7927
   753.7714   943.8542  1031.5597
   844.7084  1081.2343  1171.7051

(12,.,.) = 
   447.8186   719.9532   954.7521
   516.3374   834.3693  1058.4535
   273.4308   590.4379   786.7825

(13,.,.) = 
 -2941.0122 -3109.2300 -3006.1899
 -2963.4202 -3118.5005 -3002.7290
 -2896.9946 -3042.8494 -2900.4734

(14,.,.) = 
  5067.2866  5368.8662  5171.7568
  5341.6572  5633.5649  5393.0449
  5285.7476  5600.6343  5329.2603

(15,.,.) = 
  3450.2441  3741.4302  3715.2866
  4020.5024  4408.7725  4358.8149
  4355.1182  4763.7661  4691.8921

(16,.,.) = 
 -2932.1912 -3012.8022 -3001.2014
 -3061.5769 -3176.3591 -3152.6179
 -3194.2981 -3337.0227 -3299.6411

(17,.,.) = 
 -7598.1221 -7996.4668 -7894.9951
 -8720.1836 -9228.5518 -9124.5371
 -9423.4600 -9994.1230 -9868.6016

(18,.,.) = 
  1645.6011  1594.0597  1497.5159
  1834.5250  1754.8080  1647.7352
  1829.8317  1736.2175  1632.6831
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3691.6479492188	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #47: time = 0.530483	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2247e+04   4.2721e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #48	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00001000/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1916.0818  -2156.4922  -2080.4106
  -2042.9172  -2275.7524  -2167.4768
  -2002.1210  -2191.8965  -2067.6802

(2,.,.) = 
   2868.7227   3032.4167   2920.8059
   3075.4060   3256.1504   3101.4978
   2968.9551   3117.5825   2948.3860

(3,.,.) = 
   3694.4517   4024.3911   4023.8186
   4530.5132   4946.4102   4938.3955
   4955.1470   5435.5146   5411.5806

(4,.,.) = 
   1056.2998   1177.0284   1154.6877
   1321.4479   1422.6465   1370.2139
   1436.6359   1490.8699   1397.6400

(5,.,.) = 
    751.4419    742.9766    663.9074
    737.6996    690.8299    583.9697
    754.2995    671.8526    562.5754

(6,.,.) = 
   1652.2770   1872.2715   1914.4810
   2028.2238   2337.7126   2381.0144
   2333.7939   2679.8672   2707.0649

(7,.,.) = 
  -2761.6885  -2933.6816  -2756.3191
  -2980.5740  -3132.0876  -2867.8328
  -2858.5815  -2935.2759  -2642.2466

(8,.,.) = 
   5782.5249   6194.7256   5950.9092
   6519.2104   6948.0117   6623.0439
   6785.4731   7160.2329   6786.3726

(9,.,.) = 
   2541.0369   3055.0847   3256.2358
   2927.1497   3455.4331   3584.3679
   3199.3474   3735.2234   3821.2559

(10,.,.) = 
  -3420.5610  -3378.5605  -3128.3994
  -3663.5305  -3628.4658  -3357.6348
  -3626.2734  -3582.1265  -3334.2441

(11,.,.) = 
    480.5851    640.6462    732.2852
    754.2998    944.4838   1032.2321
    845.2549   1081.9178   1172.4313

(12,.,.) = 
    448.0163    720.3058    955.2393
    516.6005    834.8175   1059.0403
    273.5951    590.8038    787.2612

(13,.,.) = 
  -2942.7957  -3111.1194  -3008.0198
  -2965.2114  -3120.4043  -3004.5735
  -2898.7920  -3044.7551  -2902.2808

(14,.,.) = 
   5070.5093   5372.2720   5175.0312
   5345.0796   5637.1455   5396.4907
   5289.1763   5604.2627   5332.7280

(15,.,.) = 
   3452.8516   3744.2546   3718.0645
   4023.4766   4412.0146   4361.9907
   4358.2974   4767.2192   4695.2500

(16,.,.) = 
  -2934.3013  -3014.9656  -3003.3323
  -3063.8330  -3178.6846  -3154.8826
  -3196.6321  -3339.4514  -3302.0012

(17,.,.) = 
  -7603.6968  -8002.3228  -7900.7236
  -8726.5273  -9235.2344  -9131.0986
  -9430.2061 -10001.2305  -9875.5391

(18,.,.) = 
   1646.6748   1595.1067   1498.5182
   1835.7373   1755.9722   1648.8451
   1831.0654   1737.3922   1633.8085
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3694.4516601562	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #48: time = 0.5379	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2292e+04   4.2748e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #49	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00010013/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1920
 1920
[torch.LongStorage of size 3]

x_start = 1 / y_start = 421	
img_means:size() vs img:size():	
    3
 1080
 1920
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.55555555555556	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
 1080
 1920
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.55555555555556	
proposal_im_detect: scaled_img_size:	
    2
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1908.1366 -2147.2554 -2071.5127
 -2033.4130 -2264.9639 -2157.0659
 -1992.1190 -2180.6438 -2056.9927

(2,.,.) = 
  2856.6980  3019.5012  2908.1084
  3061.5725  3240.9980  3086.9187
  2954.9648  3102.2454  2933.6096

(3,.,.) = 
  3667.9932  3995.8154  3995.9675
  4498.7969  4911.9604  4904.8159
  4921.2158  5398.6548  5375.9780

(4,.,.) = 
  1047.0737  1166.7250  1144.6769
  1310.3634  1410.7765  1358.8253
  1425.0681  1478.6724  1386.2903

(5,.,.) = 
   745.1364   736.6544   658.3224
   731.2309   684.2529   578.1629
   747.8906   665.4587   556.5272

(6,.,.) = 
  1637.9471  1856.0929  1898.4692
  2011.5320  2318.7952  2362.2893
  2315.7651  2659.4626  2687.0386

(7,.,.) = 
 -2744.9089 -2915.6775 -2738.7932
 -2962.0234 -3112.2146 -2848.9788
 -2840.3420 -2915.9534 -2623.9626

(8,.,.) = 
  5744.9800  6154.8330  5912.7881
  6476.8643  6903.0923  6580.5518
  6741.9062  7114.2148  6743.0786

(9,.,.) = 
  2522.0371  3033.0178  3233.0632
  2904.7458  3429.8618  3558.2041
  3176.0437  3708.8513  3794.6538

(10,.,.) = 
 -3403.7761 -3361.7815 -3112.4492
 -3644.8816 -3609.6509 -3339.9712
 -3606.9895 -3562.4983 -3315.5676

(11,.,.) = 
   476.1275   635.3138   727.0934
   748.9604   938.2876  1026.0247
   839.8597  1075.2789  1165.6416

(12,.,.) = 
   446.9561   717.7829   951.8074
   514.8440   831.2476  1054.5319
   271.7957   587.0131   782.4936

(13,.,.) = 
 -2929.1196 -3096.7227 -2993.8757
 -2950.5046 -3104.6106 -2988.8574
 -2883.6238 -3028.5720 -2886.5671

(14,.,.) = 
  5044.4175  5344.7856  5148.6670
  5316.5645  5607.2681  5367.6426
  5259.7500  5573.1729  5302.9160

(15,.,.) = 
  3426.9702  3716.1208  3690.7007
  3993.8401  4379.6577  4330.6489
  4327.0176  4733.1826  4662.5898

(16,.,.) = 
 -2916.8870 -2996.9812 -2985.6738
 -3043.7915 -3158.0486 -3134.8372
 -3175.3110 -3317.1382 -3280.3669

(17,.,.) = 
 -7552.0864 -7948.3794 -7848.5811
 -8667.1914 -9172.8457 -9070.4629
 -9366.9834 -9934.6895 -9811.2646

(18,.,.) = 
  1638.5122  1587.2578  1490.9832
  1826.1764  1746.9459  1640.0344
  1820.7838  1727.5646  1624.1166
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3667.9931640625	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #49: time = 0.722092	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.9200e+03   1.9200e+03
        -inf         -inf   1.0778e+05   6.3702e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #50	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00058003/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 264
 480
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 480
 480
[torch.LongStorage of size 3]

x_start = 1 / y_start = 109	
img_means:size() vs img:size():	
   3
 264
 480
[torch.LongStorage of size 3]

   3
 264
 480
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 2.2727272727273	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1090
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x133
  2 : CudaTensor - size: 18x72x133
  3 : CudaTensor - size: 18x70x131
  4 : CudaTensor - size: 18x68x129
  5 : CudaTensor - size: 256x74x135
}
proposal_im_deteect: img_blob size:     3
  600
 1090
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 264
 480
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 2.2727272727273	
proposal_im_detect: scaled_img_size:	
    7
  600
 1091
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1904.1639 -2143.2141 -2067.7334
 -2030.5261 -2262.0376 -2154.5068
 -1990.3856 -2179.1367 -2055.9785

(2,.,.) = 
  2851.2427  3013.9980  2903.1599
  3056.9531  3236.6470  3083.2151
  2951.7498  3099.6370  2931.8076

(3,.,.) = 
  3669.0796  3997.8169  3998.4832
  4500.9902  4915.3789  4908.7856
  4924.5181  5403.2583  5380.9912

(4,.,.) = 
  1049.1127  1169.4193  1147.6434
  1312.7456  1414.0051  1362.4224
  1427.8224  1482.4218  1390.1915

(5,.,.) = 
   745.6156   737.1780   658.7507
   732.2313   685.4728   579.3710
   749.1188   667.1656   558.7518

(6,.,.) = 
  1640.7915  1859.5936  1902.0154
  2014.9114  2322.6785  2366.1633
  2319.1150  2663.5889  2691.0950

(7,.,.) = 
 -2745.0339 -2915.9343 -2739.5542
 -2962.6389 -3113.1345 -2850.4001
 -2841.5740 -2917.7383 -2626.3062

(8,.,.) = 
  5746.4785  6157.1924  5915.8159
  6479.7236  6907.0513  6585.2852
  6745.6821  7119.4292  6749.0039

(9,.,.) = 
  2524.3425  3035.8560  3236.4871
  2908.7566  3434.6177  3563.4607
  3180.3147  3713.8103  3800.0762

(10,.,.) = 
 -3399.2629 -3357.7859 -3109.5134
 -3641.1772 -3606.5994 -3337.7771
 -3604.6646 -3561.0059 -3315.0283

(11,.,.) = 
   478.3703   637.8057   729.1689
   750.1147   939.6427  1027.2159
   840.6600  1076.2975  1166.6018

(12,.,.) = 
   445.8574   716.6650   950.1583
   513.5298   829.9612  1052.8400
   271.6891   587.0800   782.3841

(13,.,.) = 
 -2925.3311 -3092.7568 -2990.4907
 -2948.3887 -3102.6824 -2987.8374
 -2882.5991 -3027.7148 -2886.4431

(14,.,.) = 
  5040.3413  5340.9185  5145.5747
  5314.1392  5605.2251  5366.7632
  5259.0654  5573.0249  5303.9771

(15,.,.) = 
  3430.2153  3720.5505  3695.5100
  3998.2427  4385.2588  4336.6289
  4331.8467  4739.3428  4668.9756

(16,.,.) = 
 -2914.4377 -2995.1851 -2984.6365
 -3043.8284 -3158.7617 -3136.3318
 -3176.9810 -3319.7756 -3283.8494

(17,.,.) = 
 -7553.5967 -7951.3203 -7852.6060
 -8671.3467 -9179.1260 -9078.1992
 -9373.0166 -9943.1221 -9821.0576

(18,.,.) = 
  1636.4646  1585.3060  1489.3965
  1824.4923  1745.4165  1639.0720
  1820.1876  1727.3778  1624.6129
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 131
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 27510
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 131
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 131
[torch.LongStorage of size 2]

shift_y size:	
  70
 131
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 9170
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 27510
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 27510
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 27510
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  27510
[torch.LongStorage of size 1]
	
  first line: 3669.0795898438	
(fast bbox transform) src_w size:  27510
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 27510
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 27510
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 27510
     4
[torch.LongStorage of size 2]

scores size:	
 27510
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 27510
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 27510
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 27510
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 73360
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 18340
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 18340
[torch.LongStorage of size 1]

test img #50: time = 0.461112	
(proposal_test:boxes_filter) boxes & scores size:	
 18340
     4
[torch.LongStorage of size 2]

 18340
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 2099
    3
[torch.LongTensor of size 2]

mask size:	
 18340
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   4.8000e+02   4.8000e+02
        -inf         -inf   2.6311e+04   1.5516e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #51	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00135001/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 480
 480
[torch.LongStorage of size 3]

x_start = 1 / y_start = 61	
img_means:size() vs img:size():	
   3
 360
 480
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6666666666667	
(orep_img_for_blob) img size after scaling:	
   3
 600
 800
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x97
  2 : CudaTensor - size: 18x72x97
  3 : CudaTensor - size: 18x70x95
  4 : CudaTensor - size: 18x68x93
  5 : CudaTensor - size: 256x74x99
}
proposal_im_deteect: img_blob size:    3
 600
 800
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 360
 480
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6666666666667	
proposal_im_detect: scaled_img_size:	
   5
 600
 800
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1919.6016  -2162.0859  -2086.8213
  -2048.9551  -2283.6973  -2176.3628
  -2009.5365  -2201.1677  -2077.4956

(2,.,.) = 
   2874.4500   3040.4280   2930.8926
   3083.7007   3267.4521   3114.1033
   2978.4229   3129.9609   2962.0581

(3,.,.) = 
   3730.9424   4065.1384   4064.8201
   4573.6763   4995.0479   4987.2725
   4999.3613   5485.3921   5460.9175

(4,.,.) = 
   1073.3772   1196.6371   1174.1498
   1339.9064   1443.3639   1390.6587
   1454.3353   1510.5104   1416.1917

(5,.,.) = 
    760.2147    752.0461    671.9432
    746.6527    700.4567    592.7456
    762.5228    680.7446    571.8266

(6,.,.) = 
   1675.8019   1899.6873   1942.1193
   2055.1958   2368.7078   2412.3076
   2361.6133   2712.0071   2739.3208

(7,.,.) = 
  -2781.9443  -2956.7957  -2780.8564
  -3003.2981  -3157.8828  -2894.1836
  -2880.4744  -2959.8850  -2667.2056

(8,.,.) = 
   5831.1792   6248.5059   6004.5029
   6573.2383   7007.1680   6681.1699
   6838.5825   7218.3247   6842.7017

(9,.,.) = 
   2568.5327   3088.0088   3292.1318
   2960.4780   3494.1875   3625.1931
   3232.1619   3772.6316   3859.7498

(10,.,.) = 
  -3430.8386  -3390.7683  -3142.6460
  -3675.6362  -3642.7830  -3372.8074
  -3640.4756  -3598.4712  -3351.6960

(11,.,.) = 
    490.5917    652.1913    742.4730
    763.5115    954.9872   1042.0355
    853.5840   1092.1669   1182.5444

(12,.,.) = 
    449.6573    724.7368    960.3608
    518.9055    840.3499   1065.7296
    277.3743    597.9341    795.6564

(13,.,.) = 
  -2952.3103  -3122.2205  -3021.2288
  -2977.6262  -3135.1323  -3021.8936
  -2912.5623  -3060.2849  -2919.1941

(14,.,.) = 
   5094.3257   5399.5562   5203.7822
   5372.2500   5667.1411   5428.2651
   5318.1523   5636.0298   5365.5186

(15,.,.) = 
   3491.2317   3787.7188   3761.3394
   4066.3123   4460.1040   4409.6104
   4401.3418   4815.2329   4742.0596

(16,.,.) = 
  -2951.6838  -3034.5818  -3024.2102
  -3086.1958  -3202.9160  -3179.6421
  -3220.7490  -3366.0281  -3328.8835

(17,.,.) = 
  -7672.5767  -8077.4009  -7976.4287
  -8803.9609  -9320.1777  -9217.1387
  -9509.5293 -10088.2520  -9962.5830

(18,.,.) = 
   1652.6194   1601.4951   1505.6768
   1843.4626   1763.9603   1657.8877
   1840.6040   1747.4568   1644.8888
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 95
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 19950
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 95
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 95
[torch.LongStorage of size 2]

shift_y size:	
 70
 95
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6650
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 19950
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  19950
[torch.LongStorage of size 1]
	
  first line: 3730.9423828125	
(fast bbox transform) src_w size:  19950
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 19950
     4
[torch.LongStorage of size 2]

scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 19950
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 53200
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13300
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13300
[torch.LongStorage of size 1]

test img #51: time = 0.367665	
(proposal_test:boxes_filter) boxes & scores size:	
 13300
     4
[torch.LongStorage of size 2]

 13300
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 953
   3
[torch.LongTensor of size 2]

mask size:	
 13300
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   4.8000e+02   4.8000e+02
        -inf         -inf   3.6400e+04   2.1461e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #52	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00049001/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 358
 640
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 640
 640
[torch.LongStorage of size 3]

x_start = 1 / y_start = 142	
img_means:size() vs img:size():	
   3
 358
 640
[torch.LongStorage of size 3]

   3
 358
 640
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6759776536313	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1072
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x131
  2 : CudaTensor - size: 18x72x131
  3 : CudaTensor - size: 18x70x129
  4 : CudaTensor - size: 18x68x127
  5 : CudaTensor - size: 256x74x133
}
proposal_im_deteect: img_blob size:     3
  600
 1072
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 358
 640
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6759776536313	
proposal_im_detect: scaled_img_size:	
    5
  600
 1073
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1914.5009 -2154.7075 -2078.6833
 -2041.2386 -2273.8811 -2165.6914
 -2000.5735 -2190.1948 -2066.0886

(2,.,.) = 
  2866.4009  3029.9258  2918.3723
  3072.9409  3253.4827  3098.9380
  2966.6912  3115.1514  2946.0837

(3,.,.) = 
  3691.0522  4020.7200  4020.2122
  4526.5332  4942.0811  4934.1143
  4951.0342  5431.0186  5407.1582

(4,.,.) = 
  1055.2507  1175.8781  1153.5754
  1320.2041  1421.3322  1368.9617
  1435.3882  1489.5894  1396.4486

(5,.,.) = 
   750.7695   742.2871   663.2635
   737.0994   690.2383   583.4166
   753.7679   671.3735   562.1320

(6,.,.) = 
  1650.7233  1870.5049  1912.7092
  2026.4003  2335.5928  2378.8962
  2331.7957  2677.5637  2704.8003

(7,.,.) = 
 -2759.5137 -2931.3103 -2754.0469
 -2978.2739 -3129.5974 -2865.4849
 -2856.5195 -2933.0688 -2640.2432

(8,.,.) = 
  5777.6201  6189.4424  5945.8086
  6513.8735  6942.3052  6617.5796
  6780.2739  7154.7090  6781.1460

(9,.,.) = 
  2538.8606  3052.4612  3253.4094
  2924.6980  3452.5352  3581.3018
  3196.8350  3732.2664  3818.2219

(10,.,.) = 
 -3417.8164 -3375.7839 -3125.7659
 -3660.6865 -3625.5894 -3354.9055
 -3623.6350 -3579.4453 -3331.6814

(11,.,.) = 
   480.1633   640.1054   731.6961
   753.6888   943.7519  1031.4541
   844.5790  1081.0751  1171.5410

(12,.,.) = 
   447.6901   719.7595   954.4734
   516.1619   834.1208  1058.1561
   273.2749   590.2388   786.5675

(13,.,.) = 
 -2940.4785 -3108.6189 -3005.5310
 -2962.9602 -3117.9751 -3002.1343
 -2896.7300 -3042.5227 -2900.0515

(14,.,.) = 
  5066.3989  5367.8579  5170.7207
  5340.9287  5632.7095  5392.1562
  5285.3198  5600.0947  5328.6836

(15,.,.) = 
  3449.7268  3740.8911  3714.7742
  4020.0020  4408.2202  4358.3096
  4354.7573  4763.3638  4691.5396

(16,.,.) = 
 -2931.7349 -3012.3103 -3000.7002
 -3061.2327 -3175.9854 -3152.1995
 -3194.1165 -3336.7944 -3299.3640

(17,.,.) = 
 -7596.7915 -7995.0513 -7893.5962
 -8718.9443 -9227.2227 -9123.2314
 -9422.5176 -9993.0605 -9867.5400

(18,.,.) = 
  1645.3528  1593.8019  1497.2599
  1834.3062  1754.5773  1647.4893
  1829.6995  1736.0509  1632.5039
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 129
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 27090
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 129
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 129
[torch.LongStorage of size 2]

shift_y size:	
  70
 129
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 9030
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 27090
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 27090
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 27090
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  27090
[torch.LongStorage of size 1]
	
  first line: 3691.0522460938	
(fast bbox transform) src_w size:  27090
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 27090
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 27090
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 27090
     4
[torch.LongStorage of size 2]

scores size:	
 27090
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 27090
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 27090
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 27090
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 72240
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 18060
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 18060
[torch.LongStorage of size 1]

test img #52: time = 0.46024	
(proposal_test:boxes_filter) boxes & scores size:	
 18060
     4
[torch.LongStorage of size 2]

 18060
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1809
    3
[torch.LongTensor of size 2]

mask size:	
 18060
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   6.4000e+02   6.4000e+02
        -inf         -inf   3.5874e+04   2.1138e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #53	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00026000/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1907.6019 -2146.9734 -2071.3293
 -2032.9983 -2264.8877 -2157.2542
 -1990.9990 -2179.8394 -2056.4194

(2,.,.) = 
  2855.5852  3018.8723  2907.8232
  3060.2385  3240.6582  3086.8809
  2952.8831  3101.2070  2933.1653

(3,.,.) = 
  3675.9299  4003.7969  4002.9507
  4507.4922  4920.9463  4912.5347
  4928.3447  5406.1880  5382.1973

(4,.,.) = 
  1052.3787  1172.2819  1149.7006
  1315.7826  1416.2375  1363.8435
  1429.0010  1482.6189  1389.5856

(5,.,.) = 
   748.3719   739.8934   661.2766
   733.9948   687.3722   581.3013
   749.4890   667.5251   559.3215

(6,.,.) = 
  1643.7758  1863.1556  1905.1675
  2017.5833  2326.0913  2369.3127
  2321.6233  2666.4800  2693.7483

(7,.,.) = 
 -2748.5830 -2919.9949 -2743.5205
 -2965.0742 -3116.2632 -2853.7256
 -2842.0137 -2918.6860 -2627.7390

(8,.,.) = 
  5754.4653  6164.8022  5921.7202
  6484.9268  6911.8525  6588.5396
  6745.7930  7118.8018  6747.2656

(9,.,.) = 
  2527.9812  3039.6926  3239.9910
  2911.2405  3437.2383  3565.7988
  3180.5649  3713.8921  3799.6794

(10,.,.) = 
 -3402.1467 -3360.8918 -3112.3311
 -3641.8435 -3607.7927 -3338.8491
 -3602.8906 -3559.7117 -3313.8733

(11,.,.) = 
   478.3559   637.7244   728.6886
   750.5554   939.8885  1027.0133
   840.9395  1076.4781  1166.3914

(12,.,.) = 
   447.4689   718.8586   952.7435
   516.0400   833.2007  1056.4185
   274.2727   590.4158   785.9790

(13,.,.) = 
 -2928.8809 -3097.0417 -2994.9548
 -2949.7871 -3105.0593 -2990.6072
 -2881.9646 -3027.7493 -2886.9978

(14,.,.) = 
  5046.3237  5347.3438  5151.3071
  5316.6416  5608.1943  5369.3389
  5257.6104  5571.7354  5302.4653

(15,.,.) = 
  3435.9412  3725.8311  3699.3809
  4002.3687  4389.0127  4338.9282
  4333.1714  4739.8906  4668.1934

(16,.,.) = 
 -2919.4702 -2999.8428 -2988.3469
 -3047.0090 -3161.4680 -3138.0037
 -3177.0110 -3319.3655 -3282.3818

(17,.,.) = 
 -7567.7217 -7964.3013 -7862.6333
 -8682.2666 -9188.6045 -9084.7354
 -9377.3115 -9945.7773 -9821.0586

(18,.,.) = 
  1638.4083  1587.1213  1491.0406
  1825.9421  1746.7261  1640.3463
  1820.5447  1727.7572  1624.9730
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3675.9299316406	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #53: time = 0.574771	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1703e+04   4.2393e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #54	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00051001/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1908.6854 -2147.9756 -2071.9304
 -2034.5997 -2266.3340 -2158.0879
 -1993.8031 -2182.5674 -2058.5493

(2,.,.) = 
  2858.0408  3020.7949  2909.1270
  3063.4883  3243.1711  3088.7683
  2957.4841  3105.2219  2936.3271

(3,.,.) = 
  3675.7087  4003.7925  4003.1323
  4509.2295  4922.9102  4914.7363
  4933.2598  5411.3149  5387.3965

(4,.,.) = 
  1050.7147  1170.7883  1148.4028
  1314.4885  1415.2461  1362.9167
  1429.5875  1483.4048  1390.3132

(5,.,.) = 
   747.5046   738.8261   659.9949
   733.9470   686.9016   580.3152
   750.5557   668.1084   559.1212

(6,.,.) = 
  1643.7384  1862.6200  1904.6283
  2018.6969  2326.7588  2369.7844
  2323.7244  2668.3423  2695.4951

(7,.,.) = 
 -2751.1343 -2921.9326 -2744.5481
 -2968.9380 -3119.3418 -2855.5015
 -2847.6367 -2923.5657 -2631.0505

(8,.,.) = 
  5757.3452  6167.2778  5923.5630
  6491.3774  6917.8281  6593.4331
  6757.4390  7130.0879  6756.9985

(9,.,.) = 
  2528.5657  3040.6768  3241.0750
  2913.3899  3439.6575  3568.0181
  3185.6335  3719.4094  3804.9431

(10,.,.) = 
 -3405.8672 -3363.5999 -3113.8838
 -3647.7686 -3612.4292 -3342.1533
 -3610.8335 -3566.4675 -3319.1277

(11,.,.) = 
   478.8492   638.4410   729.7618
   751.3953   941.0859  1028.5652
   842.3566  1078.2698  1168.4940

(12,.,.) = 
   447.2928   718.8235   952.8628
   515.3030   832.5463  1055.9692
   273.0027   589.2031   784.8342

(13,.,.) = 
 -2932.1262 -3099.5942 -2996.6729
 -2954.6895 -3108.9419 -2993.2422
 -2888.5796 -3033.7151 -2891.5488

(14,.,.) = 
  5050.8301  5351.0830  5154.1616
  5324.2695  5614.9619  5374.6416
  5268.7554  5582.2842  5311.2065

(15,.,.) = 
  3436.0557  3725.7266  3699.4067
  4004.8076  4391.3525  4341.2007
  4339.0396  4745.9526  4673.9727

(16,.,.) = 
 -2920.0276 -3000.0571 -2988.5803
 -3048.8547 -3163.0508 -3139.4651
 -3181.6746 -3323.6995 -3286.4956

(17,.,.) = 
 -7567.0576 -7963.2319 -7861.8062
 -8686.3301 -9192.1689 -9087.9717
 -9388.8359 -9956.9004 -9831.3887

(18,.,.) = 
  1639.8479  1588.1506  1491.6415
  1828.1196  1748.4271  1641.4675
  1823.3929  1729.9321  1626.5508
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3675.7087402344	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #54: time = 0.587902	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1978e+04   4.2553e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #55	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00034006/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1904.1689 -2142.7234 -2066.9270
 -2029.1941 -2260.1223 -2152.1782
 -1987.9723 -2175.7854 -2052.2170

(2,.,.) = 
  2850.8799  3013.1553  2901.6660
  3055.2864  3234.1287  3080.1279
  2949.0115  3095.7139  2927.1782

(3,.,.) = 
  3657.5195  3984.5037  3984.7803
  4486.9463  4898.9976  4892.0010
  4908.9761  5385.4604  5363.0122

(4,.,.) = 
  1044.1705  1163.5160  1141.5315
  1306.6353  1406.9352  1355.1123
  1421.2969  1474.7286  1382.4539

(5,.,.) = 
   742.8564   734.2332   655.9825
   729.0237   681.8952   575.9717
   745.5591   663.1452   554.4527

(6,.,.) = 
  1633.2035  1850.7306  1893.1266
  2006.1444  2312.5813  2356.0750
  2309.9341  2652.9038  2680.5273

(7,.,.) = 
 -2739.5454 -2909.6633 -2732.6948
 -2956.0579 -3105.6538 -2842.5955
 -2834.3848 -2909.6123 -2617.8206

(8,.,.) = 
  5731.9688  6140.7632  5898.7793
  6462.4810  6887.5645  6565.4292
  6727.0317  7098.3989  6727.7656

(9,.,.) = 
  2515.4836  3025.5295  3225.3101
  2897.7156  3421.8928  3550.0603
  3168.8406  3700.7104  3786.3582

(10,.,.) = 
 -3395.5842 -3353.3555 -3104.1992
 -3636.1274 -3600.7644 -3331.3225
 -3598.4072 -3553.8457 -3307.2529

(11,.,.) = 
   475.3312   634.3076   725.9421
   747.3349   936.4334  1024.0770
   838.2958  1073.4800  1163.7355

(12,.,.) = 
   446.4641   716.8976   950.4324
   513.9465   829.8306  1052.6298
   271.3530   585.9037   780.8372

(13,.,.) = 
 -2923.6389 -3090.7410 -2987.9871
 -2945.5098 -3099.0559 -2983.3989
 -2878.5713 -3023.0410 -2881.2991

(14,.,.) = 
  5034.2070  5333.8296  5137.8369
  5305.9863  5596.0425  5356.6323
  5249.1943  5561.8184  5291.9233

(15,.,.) = 
  3418.0354  3706.3584  3680.9138
  3983.8528  4368.6680  4319.7119
  4316.4512  4721.6006  4651.1597

(16,.,.) = 
 -2908.6401 -2988.4922 -2977.3928
 -3035.3413 -3149.3999 -3126.5806
 -3167.0159 -3308.5452 -3272.2712

(17,.,.) = 
 -7532.1553 -7927.2109 -7827.6855
 -8645.1797 -9149.5938 -9047.4912
 -9344.1348 -9910.6250 -9787.7773

(18,.,.) = 
  1634.6254  1583.3206  1487.0311
  1821.8208  1742.7129  1635.8932
  1816.5282  1723.4904  1620.1506
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3657.51953125	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #55: time = 0.58018	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1656e+04   4.2332e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #56	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00033000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 358
 640
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 640
 640
[torch.LongStorage of size 3]

x_start = 1 / y_start = 142	
img_means:size() vs img:size():	
   3
 358
 640
[torch.LongStorage of size 3]

   3
 358
 640
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6759776536313	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1072
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x131
  2 : CudaTensor - size: 18x72x131
  3 : CudaTensor - size: 18x70x129
  4 : CudaTensor - size: 18x68x127
  5 : CudaTensor - size: 256x74x133
}
proposal_im_deteect: img_blob size:     3
  600
 1072
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 358
 640
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6759776536313	
proposal_im_detect: scaled_img_size:	
    5
  600
 1073
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1903.5857 -2141.0425 -2063.5537
 -2028.7708 -2258.7305 -2148.9814
 -1987.6051 -2174.5254 -2049.2876

(2,.,.) = 
  2850.6582  3011.1052  2897.1438
  3055.1687  3232.1445  3075.5403
  2948.9192  3094.1533  2923.2659

(3,.,.) = 
  3657.5190  3982.3884  3980.1794
  4488.3906  4898.0479  4888.0195
  4911.5430  5385.7905  5359.8931

(4,.,.) = 
  1044.6306  1163.5826  1141.0959
  1306.8535  1407.0159  1354.9950
  1421.9973  1475.0160  1382.4852

(5,.,.) = 
   744.9543   735.3810   656.1768
   731.0291   683.1796   576.4918
   747.5536   664.6823   555.5797

(6,.,.) = 
  1634.2939  1851.7137  1893.1718
  2008.3928  2314.2803  2356.3125
  2312.4954  2654.7710  2680.4565

(7,.,.) = 
 -2744.5090 -2913.2922 -2734.6013
 -2961.8276 -3109.9036 -2844.7932
 -2840.3752 -2914.1313 -2620.5132

(8,.,.) = 
  5735.7061  6141.5503  5895.4580
  6467.2944  6889.3931  6562.8955
  6733.0254  7101.6040  6726.5767

(9,.,.) = 
  2517.1216  3026.2351  3225.3396
  2900.7129  3423.9907  3551.1106
  3173.3469  3703.9446  3787.9863

(10,.,.) = 
 -3394.2297 -3350.2959 -3099.1667
 -3635.5356 -3598.5249 -3326.7493
 -3598.8538 -3553.0623 -3304.1794

(11,.,.) = 
   475.4470   634.3921   725.6290
   747.2984   936.2842  1023.6987
   838.5220  1073.6498  1163.6664

(12,.,.) = 
   447.0906   717.6813   951.0699
   514.6051   830.4489  1053.0093
   272.0377   586.3362   781.0356

(13,.,.) = 
 -2925.1812 -3090.4834 -2985.6201
 -2948.0486 -3099.9580 -2982.0300
 -2881.4192 -3024.5195 -2880.5327

(14,.,.) = 
  5035.3662  5331.8652  5132.3066
  5308.0537  5595.1763  5352.2173
  5252.3086  5562.5962  5289.2168

(15,.,.) = 
  3419.3652  3706.2610  3678.6414
  3986.6631  4369.9404  4318.3135
  4320.3809  4724.0239  4650.3916

(16,.,.) = 
 -2906.6985 -2984.0994 -2970.8557
 -3034.5425 -3146.4077 -3121.5195
 -3167.8967 -3307.6179 -3269.3108

(17,.,.) = 
 -7531.2266 -7922.0029 -7817.1489
 -8646.2246 -9146.5381 -9038.6338
 -9347.2959 -9909.6875 -9780.6035

(18,.,.) = 
  1634.3995  1581.7100  1484.5305
  1821.8794  1741.2250  1633.4985
  1816.9744  1722.7843  1618.7023
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 129
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 27090
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 129
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 129
[torch.LongStorage of size 2]

shift_y size:	
  70
 129
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 9030
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 27090
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 27090
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 27090
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  27090
[torch.LongStorage of size 1]
	
  first line: 3657.5190429688	
(fast bbox transform) src_w size:  27090
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 27090
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 27090
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 27090
     4
[torch.LongStorage of size 2]

scores size:	
 27090
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 27090
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 27090
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 27090
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 72240
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 18060
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 18060
[torch.LongStorage of size 1]

test img #56: time = 0.540248	
(proposal_test:boxes_filter) boxes & scores size:	
 18060
     4
[torch.LongStorage of size 2]

 18060
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1809
    3
[torch.LongTensor of size 2]

mask size:	
 18060
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   6.4000e+02   6.4000e+02
        -inf         -inf   3.5618e+04   2.0973e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #57	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00005002/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  576
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 353	
img_means:size() vs img:size():	
    3
  576
 1280
[torch.LongStorage of size 3]

    3
  576
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.0416666666667	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1333
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x164
  2 : CudaTensor - size: 18x72x164
  3 : CudaTensor - size: 18x70x162
  4 : CudaTensor - size: 18x68x160
  5 : CudaTensor - size: 256x74x166
}
proposal_im_deteect: img_blob size:     3
  600
 1333
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  576
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.0416666666667	
proposal_im_detect: scaled_img_size:	
    3
  600
 1333
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1902.7924 -2141.7371 -2067.2102
 -2027.5909 -2259.1558 -2152.5959
 -1986.9078 -2175.7197 -2053.2449

(2,.,.) = 
  2849.2988  3012.3606  2902.1228
  3053.5984  3233.2290  3080.3489
  2947.6375  3095.2671  2927.7683

(3,.,.) = 
  3659.0823  3986.8477  3987.6965
  4487.7485  4900.7720  4894.3101
  4909.5386  5386.4360  5364.2900

(4,.,.) = 
  1043.9026  1163.7686  1141.9242
  1307.2571  1407.8748  1356.0164
  1422.0791  1476.0317  1384.0078

(5,.,.) = 
   742.4716   734.2444   656.5836
   728.7437   682.0750   576.6136
   745.7563   663.8040   555.3452

(6,.,.) = 
  1633.5022  1851.0764  1893.6200
  2006.1788  2312.5198  2356.2820
  2309.8770  2652.3940  2680.1077

(7,.,.) = 
 -2736.8381 -2908.3591 -2732.8850
 -2953.3835 -3104.2673 -2842.5820
 -2832.3640 -2908.9021 -2618.5422

(8,.,.) = 
  5728.9404  6139.3574  5899.6836
  6459.6396  6886.2866  6565.9370
  6725.4136  7098.0879  6728.9771

(9,.,.) = 
  2515.8647  3026.6985  3226.6448
  2897.5486  3422.5906  3551.1313
  3169.1963  3701.7605  3787.6401

(10,.,.) = 
 -3397.1545 -3356.3184 -3107.9731
 -3638.1819 -3603.5945 -3334.9473
 -3600.0813 -3555.9944 -3309.7769

(11,.,.) = 
   475.0002   633.6837   725.3073
   747.7112   936.6541  1023.9646
   838.0166  1072.9067  1162.9174

(12,.,.) = 
   446.8835   717.1731   950.4548
   514.7285   830.6392  1053.4539
   272.0080   586.9108   782.2252

(13,.,.) = 
 -2921.3645 -3089.6619 -2987.6287
 -2942.0662 -3096.8672 -2981.9338
 -2876.2268 -3021.6658 -2880.2073

(14,.,.) = 
  5031.9058  5332.7285  5138.1807
  5303.8203  5594.9077  5356.7427
  5248.0444  5561.6787  5292.6108

(15,.,.) = 
  3417.8215  3707.1689  3682.6790
  3983.6755  4369.3691  4321.4116
  4316.8921  4722.8027  4653.0835

(16,.,.) = 
 -2911.0073 -2991.5061 -2980.4575
 -3037.9202 -3152.5742 -3129.3401
 -3169.8435 -3311.6794 -3274.5576

(17,.,.) = 
 -7533.9482 -7930.9565 -7832.3975
 -8647.7480 -9153.4395 -9051.9502
 -9347.1035 -9914.2939 -9791.2168

(18,.,.) = 
  1635.2399  1584.5586  1488.7390
  1822.3690  1743.6812  1636.9521
  1816.7549  1724.0250  1620.7638
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 162
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 34020
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 162
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 162
[torch.LongStorage of size 2]

shift_y size:	
  70
 162
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
     3
 11340
     4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 34020
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 34020
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 34020
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  34020
[torch.LongStorage of size 1]
	
  first line: 3659.0822753906	
(fast bbox transform) src_w size:  34020
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 34020
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 34020
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 34020
     4
[torch.LongStorage of size 2]

scores size:	
 34020
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 34020
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 34020
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 34020
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 90720
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 22680
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 22680
[torch.LongStorage of size 1]

test img #57: time = 0.754654	
(proposal_test:boxes_filter) boxes & scores size:	
 22680
     4
[torch.LongStorage of size 2]

 22680
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 3
[torch.LongStorage of size 1]

 1947
    3
    4
[torch.LongTensor of size 3]

mask size:	
 22680
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 12
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
  1.0000e+00   1.0000e+00   5.7600e+02   5.7600e+02
        -inf         -inf   5.7440e+04   3.3803e+04
[torch.CudaTensor of size 3x4]

(proposal_test:boxes_filter) boxes size returned:	
 3
 4
[torch.LongStorage of size 2]

img #58	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00013001/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1920
 1920
[torch.LongStorage of size 3]

x_start = 1 / y_start = 421	
img_means:size() vs img:size():	
    3
 1080
 1920
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.55555555555556	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
 1080
 1920
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.55555555555556	
proposal_im_detect: scaled_img_size:	
    2
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1916.0270 -2156.4375 -2080.3599
 -2042.7255 -2275.5591 -2167.3057
 -2001.7849 -2191.5591 -2067.3616

(2,.,.) = 
  2868.6797  3032.3679  2920.7568
  3075.1799  3255.9314  3101.2957
  2968.4849  3117.1270  2947.9885

(3,.,.) = 
  3694.2288  4024.1663  4023.6040
  4529.7461  4945.5757  4937.5688
  4953.4453  5433.5947  5409.6860

(4,.,.) = 
  1056.2125  1176.9358  1154.6064
  1321.1378  1422.3103  1369.8942
  1436.0795  1490.1804  1396.9530

(5,.,.) = 
   751.3272   742.8746   663.8069
   737.4589   690.5843   583.7454
   753.9265   671.4871   562.2543

(6,.,.) = 
  1652.0874  1872.0487  1914.2559
  2027.5969  2337.0002  2380.2961
  2332.4966  2678.5205  2705.7109

(7,.,.) = 
 -2761.4854 -2933.4468 -2756.0833
 -2979.7798 -3131.2319 -2866.9255
 -2856.9331 -2933.4812 -2640.3889

(8,.,.) = 
  5782.1587  6194.3579  5950.5518
  6517.8774  6946.6353  6621.6392
  6782.5273  7157.0601  6783.1660

(9,.,.) = 
  2540.8198  3054.8372  3256.0044
  2926.4590  3454.5918  3583.5044
  3197.8569  3733.4011  3819.3057

(10,.,.) = 
 -3420.5203 -3378.5181 -3128.3521
 -3663.1445 -3628.0605 -3357.1985
 -3625.0005 -3580.7805 -3332.8357

(11,.,.) = 
   480.5093   640.5748   732.2288
   754.0304   944.2164  1031.9734
   844.6533  1081.2584  1171.7500

(12,.,.) = 
   447.9899   720.2623   955.2164
   516.5251   834.7400  1058.9792
   273.5841   590.7109   787.1804

(13,.,.) = 
 -2942.7410 -3111.0566 -3007.9517
 -2964.9751 -3120.1213 -3004.2695
 -2898.0996 -3044.0337 -2901.5491

(14,.,.) = 
  5070.3809  5372.1396  5174.8989
  5344.4438  5636.4946  5395.8262
  5287.5186  5602.5532  5331.0107

(15,.,.) = 
  3452.5947  3743.9861  3717.8042
  4022.5530  4410.9883  4360.9766
  4356.3320  4765.0073  4693.0220

(16,.,.) = 
 -2934.1875 -3014.8545 -3003.2261
 -3063.5105 -3178.3232 -3154.5210
 -3195.8999 -3338.6509 -3301.1384

(17,.,.) = 
 -7603.3374 -8001.9673 -7900.4087
 -8725.2002 -9233.8760 -9129.8154
 -9427.2832 -9998.0381 -9872.3906

(18,.,.) = 
  1646.6525  1595.0878  1498.5013
  1835.5790  1755.8232  1648.6943
  1830.6085  1736.9172  1633.3281
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3694.2287597656	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #58: time = 0.840869	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.9200e+03   1.9200e+03
        -inf         -inf   1.0827e+05   6.4027e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #59	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00007000/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1908.8785 -2148.3652 -2072.5571
 -2034.9647 -2266.9084 -2159.0452
 -1994.0620 -2183.0767 -2059.3374

(2,.,.) = 
  2857.9102  3021.0037  2909.8066
  3063.4871  3243.5254  3089.4663
  2957.1006  3105.1045  2936.5723

(3,.,.) = 
  3678.4304  4006.9373  4006.4307
  4510.7368  4924.8174  4916.9077
  4933.2368  5411.5356  5387.8462

(4,.,.) = 
  1051.5305  1171.7102  1149.4879
  1315.4862  1416.2468  1364.0527
  1430.0997  1484.0249  1391.2103

(5,.,.) = 
   748.2209   739.7678   661.0495
   734.4082   687.6301   581.2422
   750.8373   668.6226   559.7917

(6,.,.) = 
  1644.8000  1863.8800  1906.0270
  2019.0231  2327.2659  2370.5159
  2323.2117  2667.8850  2695.1213

(7,.,.) = 
 -2750.6724 -2922.0239 -2745.4009
 -2968.3777 -3119.3391 -2856.2046
 -2846.5134 -2922.8835 -2631.1255

(8,.,.) = 
  5758.3818  6168.9541  5926.1675
  6491.4873  6918.5796  6595.0576
  6756.0244  7129.2466  6757.0879

(9,.,.) = 
  2530.0840  3042.0413  3242.4661
  2914.2615  3440.3779  3568.8572
  3185.1169  3718.7683  3804.5273

(10,.,.) = 
 -3406.7886 -3364.9380 -3115.7185
 -3648.3726 -3613.4651 -3343.6968
 -3610.8188 -3566.8015 -3319.9368

(11,.,.) = 
   478.1933   637.5968   728.9634
   750.8779   940.3489  1027.8059
   841.5020  1077.2339  1167.4313

(12,.,.) = 
   446.6414   717.9037   952.0308
   514.9819   832.0240  1055.4501
   272.6840   588.6661   784.4253

(13,.,.) = 
 -2931.5854 -3099.3213 -2996.6226
 -2953.5862 -3108.1880 -2992.8093
 -2887.0256 -3032.4343 -2890.5828

(14,.,.) = 
  5050.4536  5351.0840  5154.6528
  5323.3901  5614.3784  5374.6919
  5267.0234  5580.9067  5310.5210

(15,.,.) = 
  3437.7156  3727.8953  3701.9241
  4005.6335  4392.5620  4342.9033
  4338.7012  4745.9321  4674.4697

(16,.,.) = 
 -2922.1018 -3002.3503 -2990.7944
 -3050.5928 -3164.9229 -3141.2766
 -3182.4856 -3324.6274 -3287.4150

(17,.,.) = 
 -7571.1548 -7968.0933 -7866.9883
 -8688.6191 -9195.2373 -9091.6387
 -9388.5938 -9957.2422 -9832.2861

(18,.,.) = 
  1640.1589  1588.7767  1492.5612
  1828.2800  1748.8248  1642.1273
  1823.3696  1730.0559  1626.8868
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3678.4304199219	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #59: time = 0.691694	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1951e+04   4.2546e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #60	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00016000/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 360
 640
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 640
 640
[torch.LongStorage of size 3]

x_start = 1 / y_start = 141	
img_means:size() vs img:size():	
   3
 360
 640
[torch.LongStorage of size 3]

   3
 360
 640
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6666666666667	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 360
 640
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6666666666667	
proposal_im_detect: scaled_img_size:	
    5
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1916.0258 -2156.3342 -2080.3721
 -2042.6083 -2275.4451 -2167.2422
 -2001.6807 -2191.5388 -2067.3677

(2,.,.) = 
  2868.4292  3032.1423  2920.5659
  3075.1240  3255.8206  3101.3396
  2968.8613  3117.5088  2948.5129

(3,.,.) = 
  3691.3474  4020.5994  4019.5652
  4528.0122  4943.3682  4934.7749
  4953.8428  5433.8403  5409.3779

(4,.,.) = 
  1054.8354  1175.1809  1152.6503
  1319.8696  1420.6870  1368.0842
  1435.3031  1489.2048  1395.7878

(5,.,.) = 
   751.1957   742.7513   663.7671
   737.7130   690.9465   584.1259
   754.7698   672.4393   563.0602

(6,.,.) = 
  1650.4528  1870.0861  1912.1910
  2027.0276  2336.1907  2379.3367
  2333.5854  2679.3545  2706.4534

(7,.,.) = 
 -2760.0574 -2932.1121 -2754.9023
 -2979.3638 -3130.9558 -2867.0012
 -2858.4287 -2935.2778 -2642.5842

(8,.,.) = 
  5778.4683  6190.0781  5946.1309
  6515.9272  6944.2109  6619.1143
  6783.9316  7158.2437  6784.1768

(9,.,.) = 
  2538.1572  3051.7183  3252.4875
  2924.2434  3452.0522  3580.6924
  3197.4771  3732.9578  3818.6873

(10,.,.) = 
 -3419.4016 -3377.3782 -3127.2339
 -3662.8645 -3627.7053 -3356.8606
 -3626.4785 -3582.2239 -3334.0845

(11,.,.) = 
   480.0060   639.8613   731.4268
   753.9398   943.9100  1031.5015
   844.8768  1081.3241  1171.6576

(12,.,.) = 
   448.4598   720.7753   955.6585
   516.8288   835.0803  1059.3379
   273.6452   590.9902   787.6107

(13,.,.) = 
 -2941.5461 -3110.0396 -3007.0786
 -2963.8481 -3119.1619 -3003.3240
 -2898.1450 -3044.2014 -2901.5886

(14,.,.) = 
  5068.2793  5369.9404  5172.8423
  5343.1650  5635.0908  5394.3438
  5288.3853  5603.2261  5331.3667

(15,.,.) = 
  3449.7090  3740.5049  3714.0684
  4020.9805  4408.9648  4358.7246
  4357.1318  4765.5635  4693.3022

(16,.,.) = 
 -2932.9177 -3013.3081 -3001.3635
 -3062.7327 -3177.2937 -3153.0640
 -3196.2610 -3338.6833 -3300.6030

(17,.,.) = 
 -7598.1074 -7995.7979 -7893.6592
 -8721.8926 -9229.5850 -9124.6426
 -9427.7500 -9997.6816 -9870.9365

(18,.,.) = 
  1646.1864  1594.6378  1498.0092
  1835.6299  1755.8611  1648.5996
  1831.3643  1737.6102  1633.8815
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3691.3474121094	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #60: time = 0.483883	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   6.4000e+02   6.4000e+02
        -inf         -inf   3.6114e+04   2.1349e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #61	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00076000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 480
 480
[torch.LongStorage of size 3]

x_start = 1 / y_start = 61	
img_means:size() vs img:size():	
   3
 360
 480
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6666666666667	
(orep_img_for_blob) img size after scaling:	
   3
 600
 800
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x97
  2 : CudaTensor - size: 18x72x97
  3 : CudaTensor - size: 18x70x95
  4 : CudaTensor - size: 18x68x93
  5 : CudaTensor - size: 256x74x99
}
proposal_im_deteect: img_blob size:    3
 600
 800
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 360
 480
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6666666666667	
proposal_im_detect: scaled_img_size:	
   5
 600
 800
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1921.1809  -2163.5398  -2087.8086
  -2050.9968  -2285.7246  -2178.0269
  -2011.5171  -2203.2842  -2079.3562

(2,.,.) = 
   2876.5952   3042.1716   2932.0669
   3086.2686   3269.8354   3116.0352
   2980.8630   3132.4094   2964.2520

(3,.,.) = 
   3733.2944   4067.0779   4066.0491
   4577.2271   4998.1807   4989.7578
   5004.2900   5490.1045   5465.0566

(4,.,.) = 
   1073.2640   1196.3483   1173.7422
   1340.6455   1443.8628   1391.0201
   1455.8676   1511.8237   1417.3813

(5,.,.) = 
    761.4620    752.9906    672.6398
    748.1298    701.7632    593.8805
    764.0016    682.2027    573.1823

(6,.,.) = 
   1677.0449   1900.6375   1942.7568
   2056.5500   2369.9575   2413.2244
   2363.1948   2713.6304   2740.5945

(7,.,.) = 
  -2783.3792  -2957.5862  -2781.0381
  -3004.8838  -3159.1074  -2894.8926
  -2882.2166  -2961.3438  -2668.3213

(8,.,.) = 
   5835.0215   6251.3745   6006.4136
   6578.3936   7011.8389   6685.0068
   6844.5786   7224.1816   6848.0449

(9,.,.) = 
   2569.6814   3088.6287   3292.2295
   2962.1973   3495.4751   3626.0059
   3234.1453   3774.4907   3861.3647

(10,.,.) = 
  -3433.6780  -3393.0530  -3144.2600
  -3679.2334  -3646.0928  -3375.7114
  -3644.2820  -3602.3047  -3355.3560

(11,.,.) = 
    489.9417    651.4565    741.9407
    763.1790    954.5975   1041.8289
    853.6982   1092.2893   1182.7881

(12,.,.) = 
    448.1866    722.9944    958.6094
    517.5798    838.7402   1063.9208
    276.3316    596.6051    794.2452

(13,.,.) = 
  -2954.3562  -3123.9275  -3022.2593
  -2979.8098  -3137.1226  -3023.3145
  -2914.5132  -3062.3003  -2920.8628

(14,.,.) = 
   5097.6606   5402.2734   5205.5176
   5376.2471   5670.9160   5431.2246
   5322.3706   5640.3638   5369.3550

(15,.,.) = 
   3493.4189   3789.3916   3762.4585
   4069.4819   4463.0459   4412.0527
   4405.2856   4819.2788   4745.7500

(16,.,.) = 
  -2954.3665  -3036.9448  -3025.9573
  -3089.8835  -3206.4268  -3182.7095
  -3225.0339  -3370.3999  -3332.9141

(17,.,.) = 
  -7677.7607  -8081.4585  -7979.0654
  -8811.8018  -9327.2959  -9222.9033
  -9519.4131 -10097.8809  -9971.2314

(18,.,.) = 
   1653.6630   1602.1799   1506.1595
   1844.9036   1765.0643   1658.9233
   1842.4938   1749.0299   1646.4852
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 95
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 19950
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 95
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 95
[torch.LongStorage of size 2]

shift_y size:	
 70
 95
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6650
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 19950
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  19950
[torch.LongStorage of size 1]
	
  first line: 3733.2944335938	
(fast bbox transform) src_w size:  19950
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 19950
     4
[torch.LongStorage of size 2]

scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 19950
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 53200
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13300
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13300
[torch.LongStorage of size 1]

test img #61: time = 0.380582	
(proposal_test:boxes_filter) boxes & scores size:	
 13300
     4
[torch.LongStorage of size 2]

 13300
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 953
   3
[torch.LongTensor of size 2]

mask size:	
 13300
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   4.8000e+02   4.8000e+02
        -inf         -inf   3.6438e+04   2.1481e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #62	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00077000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1910.3622 -2150.4695 -2075.6240
 -2036.5508 -2269.1152 -2162.1855
 -1995.5432 -2185.2000 -2062.4941

(2,.,.) = 
  2860.4792  3024.3789  2913.8762
  3065.8179  3246.7168  3093.3289
  2959.3655  3108.1350  2940.2874

(3,.,.) = 
  3682.5974  4012.8958  4014.8008
  4515.2666  4931.6758  4926.3521
  4937.3857  5418.1270  5397.1284

(4,.,.) = 
  1053.1635  1174.3998  1152.8645
  1317.5751  1419.3588  1368.0889
  1431.8158  1486.8719  1395.1169

(5,.,.) = 
   749.0338   740.8491   662.6584
   734.7385   688.3568   582.6699
   750.6486   668.7909   560.9279

(6,.,.) = 
  1645.5297  1865.7656  1909.2637
  2019.1388  2328.6145  2373.6423
  2323.6587  2669.5171  2698.3645

(7,.,.) = 
 -2752.1111 -2925.0667 -2749.8687
 -2969.4062 -3121.8984 -2860.1306
 -2847.1289 -2924.9836 -2634.4453

(8,.,.) = 
  5763.5000  6177.6157  5938.0674
  6496.0557  6926.6890  6606.6934
  6759.7251  7136.2319  6767.5996

(9,.,.) = 
  2532.3328  3046.3052  3248.5063
  2916.8538  3445.3433  3575.9705
  3187.3645  3723.5391  3811.4272

(10,.,.) = 
 -3411.2175 -3370.7107 -3122.5728
 -3651.7620 -3618.4097 -3350.0571
 -3613.0322 -3570.5281 -3325.1582

(11,.,.) = 
   478.9196   638.8851   730.7413
   751.1773   941.3267  1029.3304
   841.8971  1078.2821  1168.8752

(12,.,.) = 
   447.6222   719.1387   953.5520
   516.0842   833.5024  1057.2800
   274.1183   590.6552   786.5980

(13,.,.) = 
 -2933.8018 -3102.6726 -3000.5464
 -2954.8489 -3110.5574 -2996.0154
 -2887.8264 -3034.2622 -2893.3010

(14,.,.) = 
  5055.5322  5358.4404  5163.6255
  5327.2705  5620.5757  5382.9512
  5269.9424  5586.0776  5317.8413

(15,.,.) = 
  3441.1863  3733.6904  3710.0203
  4008.5850  4398.1279  4351.2285
  4341.1499  4750.8022  4682.2119

(16,.,.) = 
 -2925.9983 -3007.7207 -2997.5308
 -3053.8057 -3169.8911 -3147.9846
 -3184.6790 -3328.4927 -3293.0769

(17,.,.) = 
 -7580.5249 -7981.6704 -7884.4814
 -8698.3857 -9209.7510 -9110.9238
 -9396.6836 -9970.2568 -9850.5469

(18,.,.) = 
  1642.6908  1591.7723  1495.9292
  1830.5175  1751.7783  1645.5815
  1825.0863  1732.6600  1630.0549
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3682.5974121094	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #62: time = 0.540606	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2031e+04   4.2580e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #63	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00050000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1902.0587 -2140.7463 -2065.2292
 -2027.9174 -2258.9878 -2151.3760
 -1987.6681 -2175.8372 -2052.4617

(2,.,.) = 
  2848.3149  3010.7703  2900.0483
  3053.6167  3232.7129  3079.3218
  2948.6775  3095.6919  2927.6750

(3,.,.) = 
  3660.8181  3988.2500  3988.6885
  4492.8525  4905.7314  4898.6743
  4918.0537  5395.2935  5372.2002

(4,.,.) = 
  1046.6575  1166.4895  1144.4266
  1309.8007  1410.7351  1358.9749
  1425.2465  1479.3962  1386.8196

(5,.,.) = 
   743.6131   734.6654   656.0292
   730.5421   683.1524   576.8555
   747.7480   665.3035   556.5188

(6,.,.) = 
  1637.6512  1855.9988  1898.3524
  2011.9172  2319.1958  2362.5132
  2317.0779  2660.8806  2687.9746

(7,.,.) = 
 -2741.8335 -2912.1106 -2735.6555
 -2959.5005 -3109.2866 -2846.4946
 -2839.3457 -2914.4778 -2622.6616

(8,.,.) = 
  5736.5737  6145.3896  5903.3081
  6470.2573  6895.4546  6573.0283
  6738.2695  7109.6694  6738.0898

(9,.,.) = 
  2519.0242  3029.7656  3230.0476
  2903.5464  3428.5786  3556.8569
  3176.2363  3708.8721  3794.2583

(10,.,.) = 
 -3393.4460 -3351.4417 -3103.3730
 -3635.5640 -3600.3054 -3331.4807
 -3600.2598 -3555.6270 -3309.1970

(11,.,.) = 
   477.8506   637.0962   728.1478
   749.6403   939.1155  1026.3958
   840.9412  1076.4608  1166.3860

(12,.,.) = 
   446.6088   717.9517   951.7222
   513.8984   830.8734  1053.9385
   271.8708   587.5178   782.8016

(13,.,.) = 
 -2922.6885 -3089.6748 -2987.4111
 -2946.0132 -3099.5774 -2984.4348
 -2880.3865 -3024.7151 -2883.0913

(14,.,.) = 
  5033.9668  5333.4541  5137.9839
  5308.0166  5597.7617  5358.7544
  5254.0747  5566.3789  5296.3267

(15,.,.) = 
  3423.2012  3712.1978  3686.6521
  3991.6101  4377.0439  4327.6709
  4326.6758  4732.5312  4661.0625

(16,.,.) = 
 -2908.8376 -2988.5867 -2977.5081
 -3038.2112 -3152.0286 -3128.9539
 -3172.2036 -3313.8301 -3277.1016

(17,.,.) = 
 -7538.0708 -7933.3984 -7834.1216
 -8656.1455 -9161.1768 -9058.9707
 -9360.6846 -9927.7783 -9803.9365

(18,.,.) = 
  1633.7181  1582.3055  1486.4847
  1821.6880  1742.3948  1636.1288
  1817.8672  1724.7124  1621.7404
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3660.8181152344	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #63: time = 0.55687	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1917e+04   4.2537e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #64	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00005003/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  576
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 353	
img_means:size() vs img:size():	
    3
  576
 1280
[torch.LongStorage of size 3]

    3
  576
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.0416666666667	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1333
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x164
  2 : CudaTensor - size: 18x72x164
  3 : CudaTensor - size: 18x70x162
  4 : CudaTensor - size: 18x68x160
  5 : CudaTensor - size: 256x74x166
}
proposal_im_deteect: img_blob size:     3
  600
 1333
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  576
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.0416666666667	
proposal_im_detect: scaled_img_size:	
    3
  600
 1333
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1903.7175 -2142.3911 -2067.2466
 -2028.4662 -2259.9155 -2152.9143
 -1987.3461 -2176.1960 -2053.3564

(2,.,.) = 
  2850.0981  3012.8936  2902.3591
  3054.1980  3233.7766  3080.5093
  2947.3625  3095.0396  2927.4688

(3,.,.) = 
  3666.4929  3993.6572  3993.0769
  4494.6616  4907.3032  4899.4268
  4914.8145  5391.4448  5368.0200

(4,.,.) = 
  1046.4822  1166.0515  1143.9329
  1309.9885  1410.0034  1358.0144
  1424.2531  1477.9264  1385.8679

(5,.,.) = 
   745.9238   737.7941   659.6480
   731.8889   685.5488   579.7491
   748.5619   666.7260   558.1238

(6,.,.) = 
  1638.1230  1856.3900  1898.4392
  2010.8334  2317.9548  2361.1389
  2314.0261  2657.1985  2684.4614

(7,.,.) = 
 -2739.9946 -2911.3550 -2736.1221
 -2956.6819 -3107.6047 -2846.1448
 -2835.3208 -2911.9905 -2622.2317

(8,.,.) = 
  5735.8740  6145.2607  5904.5210
  6465.5088  6891.5942  6570.2656
  6729.5674  7101.9722  6732.4888

(9,.,.) = 
  2520.4453  3030.1440  3229.5715
  2901.9976  3425.7983  3553.7532
  3171.9917  3703.6907  3789.3755

(10,.,.) = 
 -3398.4189 -3357.0374 -3108.7219
 -3638.8562 -3604.2256 -3335.7573
 -3600.6213 -3556.9006 -3311.0642

(11,.,.) = 
   474.4059   632.9642   724.3882
   747.3709   935.9335  1023.1747
   837.4462  1072.0581  1161.9657

(12,.,.) = 
   445.5028   715.4111   948.8486
   513.9896   829.5068  1052.2859
   271.8967   586.5300   781.9120

(13,.,.) = 
 -2921.6526 -3089.1880 -2986.8931
 -2941.6384 -3096.1113 -2981.1487
 -2875.3108 -3020.6436 -2879.3740

(14,.,.) = 
  5032.7578  5332.5171  5137.2417
  5303.6709  5593.8589  5355.4937
  5247.4980  5560.6221  5291.8174

(15,.,.) = 
  3423.9111  3713.0615  3687.7817
  3989.4683  4375.0845  4326.3467
  4321.9551  4727.9468  4657.5630

(16,.,.) = 
 -2914.9294 -2994.5967 -2982.6484
 -3041.6414 -3155.3713 -3131.2749
 -3172.3638 -3313.7192 -3276.1475

(17,.,.) = 
 -7544.6396 -7940.4058 -7839.7368
 -8657.2793 -9162.0840 -9059.0459
 -9354.4678 -9921.1514 -9796.8740

(18,.,.) = 
  1636.1794  1585.1685  1489.4850
  1823.3977  1744.3184  1637.9730
  1817.7610  1724.7515  1621.9191
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 162
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 34020
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 162
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 162
[torch.LongStorage of size 2]

shift_y size:	
  70
 162
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
     3
 11340
     4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 34020
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 34020
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 34020
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  34020
[torch.LongStorage of size 1]
	
  first line: 3666.4929199219	
(fast bbox transform) src_w size:  34020
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 34020
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 34020
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 34020
     4
[torch.LongStorage of size 2]

scores size:	
 34020
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 34020
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 34020
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 34020
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 90720
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 22680
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 22680
[torch.LongStorage of size 1]

test img #64: time = 0.627854	
(proposal_test:boxes_filter) boxes & scores size:	
 22680
     4
[torch.LongStorage of size 2]

 22680
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 3
[torch.LongStorage of size 1]

 1947
    3
    4
[torch.LongTensor of size 3]

mask size:	
 22680
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 12
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
  1.0000e+00   1.0000e+00   5.7600e+02   5.7600e+02
        -inf         -inf   5.7493e+04   3.3873e+04
[torch.CudaTensor of size 3x4]

(proposal_test:boxes_filter) boxes size returned:	
 3
 4
[torch.LongStorage of size 2]

img #65	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00013004/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1920
 1920
[torch.LongStorage of size 3]

x_start = 1 / y_start = 421	
img_means:size() vs img:size():	
    3
 1080
 1920
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.55555555555556	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
 1080
 1920
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.55555555555556	
proposal_im_detect: scaled_img_size:	
    2
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1915.9950 -2156.4062 -2080.3298
 -2042.6648 -2275.5054 -2167.2480
 -2001.6445 -2191.4004 -2067.1934

(2,.,.) = 
  2868.6436  3032.3311  2920.7229
  3075.0847  3255.8354  3101.2029
  2968.2600  3116.8904  2947.7644

(3,.,.) = 
  3694.1616  4024.0974  4023.5391
  4529.5239  4945.3438  4937.3550
  4952.9023  5433.0127  5409.1367

(4,.,.) = 
  1056.1880  1176.9082  1154.5881
  1321.0458  1422.2098  1369.8108
  1435.8843  1489.9528  1396.7501

(5,.,.) = 
   751.2915   742.8408   663.7732
   737.3925   690.5285   583.6935
   753.8067   671.3749   562.1633

(6,.,.) = 
  1652.0203  1871.9691  1914.1783
  2027.4086  2336.7803  2380.0710
  2332.0120  2677.9998  2705.1990

(7,.,.) = 
 -2761.3816 -2933.3340 -2755.9629
 -2979.4358 -3130.8608 -2866.5259
 -2856.2026 -2932.6846 -2639.5393

(8,.,.) = 
  5782.0151  6194.2090  5950.4116
  6517.4263  6946.1758  6621.1890
  6781.4624  7155.9478  6782.0718

(9,.,.) = 
  2540.7373  3054.7407  3255.9124
  2926.2224  3454.3008  3583.1987
  3197.2776  3732.7029  3818.5400

(10,.,.) = 
 -3420.4858 -3378.4807 -3128.3123
 -3663.0034 -3627.9009 -3357.0366
 -3624.5537 -3580.3164 -3332.3525

(11,.,.) = 
   480.4871   640.5564   732.2178
   753.9451   944.1288  1031.8988
   844.4554  1081.0670  1171.5603

(12,.,.) = 
   447.9676   720.2432   955.1938
   516.4461   834.6536  1058.8855
   273.5021   590.5905   787.0399

(13,.,.) = 
 -2942.7009 -3111.0125 -3007.8997
 -2964.8511 -3119.9719 -3004.1084
 -2897.7786 -3043.6890 -2901.1743

(14,.,.) = 
  5070.3086  5372.0625  5174.8140
  5344.1768  5636.2134  5395.5400
  5286.8813  5601.8896  5330.3364

(15,.,.) = 
  3452.5010  3743.8870  3717.7117
  4022.2644  4410.6699  4360.6797
  4355.6533  4764.2598  4692.3018

(16,.,.) = 
 -2934.1592 -3014.8154 -3003.1958
 -3063.4443 -3178.2463 -3154.4419
 -3195.6975 -3338.4360 -3300.9216

(17,.,.) = 
 -7603.2129 -8001.8613 -7900.3174
 -8724.8291 -9233.5215 -9129.5117
 -9426.4033 -9997.1465 -9871.5752

(18,.,.) = 
  1646.6343  1595.0714  1498.4839
  1835.5005  1755.7539  1648.6273
  1830.4503  1736.7751  1633.1697
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3694.1616210938	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #65: time = 0.854217	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.9200e+03   1.9200e+03
        -inf         -inf   1.0821e+05   6.3996e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #66	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00015000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 720
 960
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 960
 960
[torch.LongStorage of size 3]

x_start = 1 / y_start = 121	
img_means:size() vs img:size():	
   3
 720
 960
[torch.LongStorage of size 3]

   3
 720
 960
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
   3
 600
 800
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x97
  2 : CudaTensor - size: 18x72x97
  3 : CudaTensor - size: 18x70x95
  4 : CudaTensor - size: 18x68x93
  5 : CudaTensor - size: 256x74x99
}
proposal_im_deteect: img_blob size:    3
 600
 800
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 720
 960
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
   3
 600
 800
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1922.9580  -2165.5251  -2089.7366
  -2052.6689  -2287.6475  -2179.8772
  -2012.8914  -2204.8547  -2080.8577

(2,.,.) = 
   2879.1982   3044.9688   2934.7815
   3088.8152   3272.5879   3118.6826
   2983.0581   3134.7632   2966.4797

(3,.,.) = 
   3736.3816   4070.3416   4069.3367
   4580.8149   5002.0894   4993.7217
   5007.8809   5494.1499   5469.2349

(4,.,.) = 
   1074.1571   1197.3069   1174.7029
   1341.6447   1444.9110   1392.0612
   1456.7278   1512.7168   1418.2954

(5,.,.) = 
    762.1770    753.7106    673.3305
    748.6660    702.3252    594.4322
    764.3582    682.5334    573.5206

(6,.,.) = 
   1678.3282   1902.1504   1944.3684
   2058.1238   2371.8577   2415.2507
   2365.0532   2715.7729   2742.8721

(7,.,.) = 
  -2785.5186  -2959.9814  -2783.3257
  -3007.0518  -3161.4993  -2897.1562
  -2884.0427  -2963.3250  -2670.1758

(8,.,.) = 
   5839.4780   6256.2100   6011.1436
   6582.9927   7016.8530   6689.9341
   6848.8657   7228.8491   6852.6929

(9,.,.) = 
   2571.4941   3090.8926   3294.6763
   2964.1497   3497.9097   3628.6406
   3236.1489   3776.9800   3864.0261

(10,.,.) = 
  -3436.5291  -3396.0010  -3147.0789
  -3681.9500  -3648.9236  -3378.4226
  -3646.6580  -3604.7805  -3357.7239

(11,.,.) = 
    490.1523    651.7908    742.3991
    763.6549    955.1843   1042.5068
    854.2591   1093.0150   1183.6034

(12,.,.) = 
    448.7083    723.7505    959.5654
    518.2681    839.6702   1065.0059
    276.8237    597.3425    795.0897

(13,.,.) = 
  -2956.7080  -3126.5261  -3024.8035
  -2981.8630  -3139.4021  -3025.5183
  -2916.3242  -3064.2834  -2922.7561

(14,.,.) = 
   5101.6992   5406.6733   5209.8081
   5379.9917   5675.0059   5435.1880
   5325.6455   5643.9619   5372.8398

(15,.,.) = 
   3496.0933   3792.2859   3765.3704
   4072.3408   4466.2593   4415.3193
   4408.1499   4822.4814   4749.0679

(16,.,.) = 
  -2956.8896  -3039.5181  -3028.5352
  -3092.1472  -3208.7988  -3185.0811
  -3227.0188  -3372.5076  -3335.0452

(17,.,.) = 
  -7684.1621  -8088.1982  -7985.7593
  -8818.5078  -9334.4434  -9230.1279
  -9525.9248 -10104.9502  -9978.4941

(18,.,.) = 
   1655.1238   1603.6580   1507.5962
   1846.3989   1766.5490   1660.3718
   1843.7676   1750.3085   1647.7252
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 95
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 19950
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 95
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 95
[torch.LongStorage of size 2]

shift_y size:	
 70
 95
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6650
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 19950
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  19950
[torch.LongStorage of size 1]
	
  first line: 3736.3815917969	
(fast bbox transform) src_w size:  19950
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 19950
     4
[torch.LongStorage of size 2]

scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 19950
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 53200
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13300
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13300
[torch.LongStorage of size 1]

test img #66: time = 0.415851	
(proposal_test:boxes_filter) boxes & scores size:	
 13300
     4
[torch.LongStorage of size 2]

 13300
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 953
   3
[torch.LongTensor of size 2]

mask size:	
 13300
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   9.6000e+02   9.6000e+02
        -inf         -inf   7.2988e+04   4.3044e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #67	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0001/ILSVRC2015_train_00240001/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1909.7615 -2149.2441 -2073.3184
 -2035.6737 -2267.5466 -2159.5122
 -1994.5419 -2183.3562 -2059.5205

(2,.,.) = 
  2859.3496  3022.5444  2910.8555
  3064.8032  3244.9292  3090.5315
  2958.1545  3106.1592  2937.3950

(3,.,.) = 
  3677.4573  4005.0190  4003.2517
  4509.9121  4923.1582  4914.2329
  4932.4316  5410.4375  5386.2568

(4,.,.) = 
  1051.4294  1170.9786  1147.8965
  1315.2036  1415.4961  1362.3856
  1429.7797  1483.4860  1389.9641

(5,.,.) = 
   747.4576   738.8492   660.0995
   733.3642   686.3700   580.1627
   749.6321   667.3413   558.8290

(6,.,.) = 
  1643.6096  1862.2207  1903.6733
  2017.7794  2325.7092  2368.3647
  2322.2314  2666.7976  2693.5911

(7,.,.) = 
 -2751.2859 -2922.5999 -2745.3228
 -2968.5435 -3119.5183 -2856.0193
 -2846.2908 -2922.6562 -2630.6414

(8,.,.) = 
  5758.8130  6168.9941  5924.6504
  6491.4614  6918.3325  6593.8467
  6755.5669  7128.8037  6756.2349

(9,.,.) = 
  2529.7241  3041.5698  3241.2363
  2913.6609  3439.9326  3567.7449
  3184.6682  3718.6951  3804.1025

(10,.,.) = 
 -3407.6431 -3365.6262 -3115.5781
 -3648.6768 -3613.7769 -3343.6333
 -3610.5276 -3566.5984 -3319.6079

(11,.,.) = 
   478.3698   637.8422   729.0709
   751.2048   940.8434  1028.1752
   842.0626  1077.9325  1168.0109

(12,.,.) = 
   447.7796   719.3338   953.4963
   516.1182   833.3279  1056.7451
   273.5854   589.5886   785.0571

(13,.,.) = 
 -2933.4255 -3101.4922 -2998.5820
 -2955.0935 -3110.0776 -2994.6848
 -2887.9248 -3033.5771 -2891.9785

(14,.,.) = 
  5052.8203  5353.6084  5156.3730
  5325.1440  5616.5972  5376.5244
  5267.7964  5582.1411  5311.7271

(15,.,.) = 
  3436.9912  3726.3572  3699.1353
  4004.7830  4391.0874  4340.4053
  4337.7080  4744.5474  4672.4775

(16,.,.) = 
 -2922.2102 -3002.0283 -2989.6372
 -3049.9949 -3164.2776 -3140.1907
 -3181.4104 -3323.7778 -3286.5608

(17,.,.) = 
 -7570.8311 -7966.3613 -7862.5796
 -8687.8828 -9193.5996 -9087.8857
 -9387.3857 -9955.9346 -9830.0479

(18,.,.) = 
  1640.6492  1589.0012  1492.1780
  1828.4688  1748.9504  1641.7783
  1823.2261  1730.0142  1626.5470
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3677.4572753906	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #67: time = 0.565784	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1947e+04   4.2540e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #68	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0001/ILSVRC2015_train_00184006/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 480
 640
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 640
 640
[torch.LongStorage of size 3]

x_start = 1 / y_start = 81	
img_means:size() vs img:size():	
   3
 480
 640
[torch.LongStorage of size 3]

   3
 480
 640
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.25	
(orep_img_for_blob) img size after scaling:	
   3
 600
 800
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x97
  2 : CudaTensor - size: 18x72x97
  3 : CudaTensor - size: 18x70x95
  4 : CudaTensor - size: 18x68x93
  5 : CudaTensor - size: 256x74x99
}
proposal_im_deteect: img_blob size:    3
 600
 800
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 480
 640
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.25	
proposal_im_detect: scaled_img_size:	
   4
 600
 800
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1927.3674  -2170.5942  -2094.6965
  -2057.6213  -2293.1897  -2185.3589
  -2018.0226  -2210.5913  -2086.6799

(2,.,.) = 
   2885.6719   3051.9817   2941.8657
   3095.6738   3280.3267   3126.3394
   2989.1125   3142.0867   2973.8967

(3,.,.) = 
   3746.4146   4081.2952   4080.3506
   4591.2480   5013.1064   5004.5601
   5017.3940   5503.6089   5478.1763

(4,.,.) = 
   1077.2361   1200.6481   1177.9713
   1345.7321   1448.9181   1395.7301
   1461.4556   1517.0177   1422.0055

(5,.,.) = 
    764.3390    755.8741    675.3502
    750.8967    704.4747    596.4340
    766.7303    684.7802    575.8447

(6,.,.) = 
   1682.3434   1906.8184   1949.0297
   2061.6284   2376.4597   2420.2056
   2367.6968   2719.6265   2747.3621

(7,.,.) = 
  -2790.7683  -2965.5320  -2788.4653
  -3011.2605  -3166.3708  -2901.5671
  -2886.4658  -2966.7366  -2673.6560

(8,.,.) = 
   5853.0044   6270.6997   6025.1221
   6595.6992   7030.3018   6702.4346
   6859.1406   7239.6450   6862.7456

(9,.,.) = 
   2577.7727   3098.2617   3302.3794
   2969.9819   3504.5859   3635.4534
   3240.4661   3782.0928   3869.4585

(10,.,.) = 
  -3444.5356  -3403.8711  -3154.3201
  -3688.9468  -3656.1038  -3384.9436
  -3651.5312  -3610.4106  -3363.5215

(11,.,.) = 
    491.2165    653.2850    743.9626
    764.7377    956.6778   1043.9089
    855.3343   1094.4388   1184.7395

(12,.,.) = 
    449.4214    725.1511    961.5477
    519.8187    842.0357   1067.8680
    279.0324    600.5571    798.6508

(13,.,.) = 
  -2963.5173  -3133.8450  -3031.8093
  -2987.7517  -3146.2734  -3032.5796
  -2920.5205  -3069.9163  -2929.0320

(14,.,.) = 
   5113.6738   5419.4839   5222.0332
   5390.8462   5687.0283   5446.8262
   5334.0669   5654.1001   5382.9609

(15,.,.) = 
   3504.9580   3801.7842   3774.7104
   4081.0645   4475.5986   4424.3452
   4415.7842   4830.4766   4756.6353

(16,.,.) = 
  -2965.2610  -3048.2693  -3037.1716
  -3100.6211  -3217.6560  -3193.6084
  -3234.6707  -3380.7080  -3342.9761

(17,.,.) = 
  -7705.0444  -8110.0591  -8007.3560
  -8840.5723  -9357.1924  -9252.2627
  -9547.1562 -10126.5615  -9999.1094

(18,.,.) = 
   1659.0806   1607.4707   1511.2739
   1850.0708   1770.0295   1663.7261
   1846.5178   1753.0491   1650.5424
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 95
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 19950
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 95
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 95
[torch.LongStorage of size 2]

shift_y size:	
 70
 95
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6650
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 19950
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  19950
[torch.LongStorage of size 1]
	
  first line: 3746.4145507812	
(fast bbox transform) src_w size:  19950
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 19950
     4
[torch.LongStorage of size 2]

scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 19950
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 53200
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13300
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13300
[torch.LongStorage of size 1]

test img #68: time = 0.401383	
(proposal_test:boxes_filter) boxes & scores size:	
 13300
     4
[torch.LongStorage of size 2]

 13300
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 953
   3
[torch.LongTensor of size 2]

mask size:	
 13300
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   6.4000e+02   6.4000e+02
        -inf         -inf   4.8618e+04   2.8628e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #69	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0001/ILSVRC2015_train_00165002/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1907.2966 -2146.6360 -2070.8706
 -2033.4691 -2265.3003 -2157.3728
 -1993.1672 -2182.1267 -2058.4651

(2,.,.) = 
  2855.7590  3018.7358  2907.6089
  3061.4880  3241.4211  3087.5156
  2955.8406  3103.9443  2935.5928

(3,.,.) = 
  3674.6001  4002.5750  4001.7192
  4507.5898  4921.0337  4912.5649
  4931.7070  5409.3916  5385.0566

(4,.,.) = 
  1050.3486  1170.2770  1147.7845
  1314.3750  1414.8462  1362.3105
  1429.7477  1483.4248  1390.1648

(5,.,.) = 
   747.4346   738.7245   659.8943
   734.0906   687.1202   580.5355
   750.9629   668.7374   559.8476

(6,.,.) = 
  1643.1770  1861.8992  1903.7709
  2017.8481  2325.7437  2368.8521
  2322.7700  2667.2798  2694.5276

(7,.,.) = 
 -2748.5107 -2919.4294 -2742.5557
 -2966.5181 -3117.2141 -2853.9849
 -2845.5425 -2922.0098 -2630.3274

(8,.,.) = 
  5753.7515  6163.4336  5920.0098
  6487.9292  6914.1577  6589.9609
  6754.4902  7127.2144  6754.4736

(9,.,.) = 
  2527.1025  3038.6184  3238.5869
  2911.7649  3437.3838  3565.3940
  3183.9189  3717.2053  3802.6877

(10,.,.) = 
 -3403.8928 -3361.7920 -3112.4780
 -3646.0488 -3610.9751 -3341.0481
 -3609.5720 -3565.6169 -3318.6775

(11,.,.) = 
   478.5085   637.9404   729.0803
   750.8884   940.3895  1027.6702
   841.5597  1077.2028  1167.2218

(12,.,.) = 
   446.6732   718.1320   952.0944
   514.5953   831.7427  1055.1040
   272.6051   588.6399   784.2658

(13,.,.) = 
 -2929.3225 -3096.9082 -2994.2749
 -2951.8105 -3106.3313 -2991.0564
 -2885.8450 -3031.4041 -2889.7100

(14,.,.) = 
  5046.8677  5347.0874  5150.5205
  5320.5571  5611.3013  5371.4385
  5265.4668  5579.2734  5308.7603

(15,.,.) = 
  3434.6672  3724.2087  3697.7068
  4003.4788  4389.7500  4339.4995
  4338.0015  4744.8047  4672.7627

(16,.,.) = 
 -2919.4187 -2999.5266 -2987.7756
 -3048.6887 -3162.8384 -3138.8591
 -3181.6802 -3323.7551 -3286.2241

(17,.,.) = 
 -7564.1641 -7959.9438 -7858.1514
 -8683.5537 -9188.8057 -9083.9629
 -9386.6641 -9954.2354 -9827.9922

(18,.,.) = 
  1638.8418  1587.2876  1491.0145
  1827.2028  1747.6575  1640.8596
  1822.6399  1729.3204  1626.0870
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3674.6000976562	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #69: time = 0.540593	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1965e+04   4.2546e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #70	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00069003/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1910.1211 -2149.7097 -2073.7527
 -2037.0031 -2269.0229 -2160.8232
 -1996.7872 -2185.8643 -2061.8000

(2,.,.) = 
  2859.9023  3022.8630  2911.3433
  3066.2844  3246.3003  3091.9280
  2960.8489  3108.8687  2939.9058

(3,.,.) = 
  3681.9602  4010.9617  4010.3303
  4516.0410  4930.6548  4922.3442
  4940.1255  5418.8862  5394.5645

(4,.,.) = 
  1052.9723  1173.5836  1151.2440
  1317.4939  1418.6411  1366.2407
  1432.4917  1486.6903  1393.4908

(5,.,.) = 
   749.0081   740.5733   661.5593
   735.6168   688.7847   582.0305
   752.2815   670.0416   561.0199

(6,.,.) = 
  1646.4507  1865.7667  1907.8662
  2021.0961  2329.6584  2372.8452
  2325.8152  2671.0068  2698.0754

(7,.,.) = 
 -2753.6787 -2924.9690 -2747.8718
 -2971.9543 -3122.8291 -2859.1870
 -2850.7788 -2927.1091 -2634.7434

(8,.,.) = 
  5765.3799  6176.4961  5933.0088
  6500.2544  6927.7334  6603.2412
  6766.2246  7139.6343  6766.0933

(9,.,.) = 
  2532.9368  3045.5703  3246.0820
  2918.3701  3445.3564  3573.8726
  3190.1663  3724.6562  3810.4167

(10,.,.) = 
 -3410.6433 -3368.4387 -3118.5667
 -3652.6372 -3617.3154 -3346.8186
 -3615.2830 -3570.8403 -3323.1348

(11,.,.) = 
   479.4650   639.2166   730.6257
   751.7943   941.6477  1029.2607
   842.4047  1078.5559  1168.9073

(12,.,.) = 
   446.2885   717.9199   952.3052
   514.5751   832.1981  1056.0709
   272.8013   589.4960   785.7166

(13,.,.) = 
 -2934.7229 -3102.3115 -2999.2292
 -2957.5225 -3112.0166 -2996.2441
 -2891.3735 -3036.6250 -2894.2996

(14,.,.) = 
  5056.4766  5357.1763  5160.0923
  5330.4790  5621.5464  5381.0894
  5274.7524  5588.6104  5317.3247

(15,.,.) = 
  3442.0723  3732.7134  3706.5239
  4011.0693  4398.5566  4348.5073
  4344.8823  4752.5938  4680.5498

(16,.,.) = 
 -2924.8804 -3005.3462 -2993.7429
 -3054.4556 -3168.9897 -3145.2366
 -3187.0725 -3329.3994 -3291.8945

(17,.,.) = 
 -7579.6914 -7977.1851 -7875.5283
 -8699.9365 -9206.9961 -9102.4639
 -9401.7725 -9970.6689 -9844.3682

(18,.,.) = 
  1641.7795  1590.1460  1493.5543
  1830.2069  1750.4349  1643.3499
  1825.7240  1732.1617  1628.6967
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3681.9602050781	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #70: time = 0.542703	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2029e+04   4.2589e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #71	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00046001/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1905.9774 -2144.8914 -2068.7300
 -2031.6189 -2262.9458 -2154.7695
 -1990.4434 -2178.9993 -2055.0452

(2,.,.) = 
  2854.1292  3016.5503  2904.8623
  3059.0884  3238.4756  3083.8240
  2952.4182  3099.8694  2930.8479

(3,.,.) = 
  3674.3970  4000.6746  3998.0579
  4505.7490  4917.8545  4908.1538
  4927.4302  5404.4575  5379.4736

(4,.,.) = 
  1051.3337  1170.6982  1147.5399
  1314.9727  1414.8905  1361.8678
  1428.9678  1482.2664  1388.7101

(5,.,.) = 
   747.4648   738.4360   659.2608
   733.4021   686.2124   579.6577
   749.4555   667.0333   558.1960

(6,.,.) = 
  1643.2795  1861.7759  1902.9865
  2017.2272  2324.8142  2367.1938
  2320.8606  2664.7314  2691.0647

(7,.,.) = 
 -2747.7383 -2918.1421 -2740.6433
 -2965.1460 -3115.2524 -2851.2776
 -2843.1489 -2918.6240 -2626.3831

(8,.,.) = 
  5751.8325  6159.8638  5914.6040
  6483.6035  6908.4106  6582.9990
  6747.2002  7118.7227  6745.4082

(9,.,.) = 
  2527.6091  3038.0413  3236.4307
  2911.8457  3436.5852  3563.1333
  3182.1982  3714.7351  3798.8018

(10,.,.) = 
 -3401.9612 -3359.4851 -3109.4988
 -3642.5376 -3607.1917 -3337.0881
 -3604.3450 -3560.0334 -3313.0916

(11,.,.) = 
   478.1259   637.4345   728.3250
   750.6272   939.8270  1026.7515
   841.4594  1076.8617  1166.5969

(12,.,.) = 
   446.8080   718.0713   951.8078
   515.2416   832.0483  1054.9501
   273.1957   588.9396   784.1995

(13,.,.) = 
 -2928.5288 -3095.6511 -2992.4119
 -2950.1953 -3104.4138 -2988.5608
 -2883.2178 -3028.1067 -2885.9675

(14,.,.) = 
  5044.7178  5343.9771  5146.0615
  5316.5254  5606.4453  5365.6533
  5259.4849  5572.2935  5301.2344

(15,.,.) = 
  3434.3237  3722.8472  3694.8835
  4001.5710  4386.9517  4335.4780
  4333.6689  4739.6079  4666.8096

(16,.,.) = 
 -2918.9878 -2997.9526 -2984.8372
 -3046.8508 -3160.0833 -3135.1702
 -3178.0229 -3319.3474 -3281.2429

(17,.,.) = 
 -7564.0059 -7957.4976 -7852.3735
 -8679.4062 -9183.2012 -9076.3379
 -9376.5312 -9943.2861 -9816.1816

(18,.,.) = 
  1637.8770  1585.9705  1489.3015
  1825.3275  1745.4764  1638.5238
  1820.4901  1727.0537  1623.6595
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3674.3969726562	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #71: time = 0.556749	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1798e+04   4.2456e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #72	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00018002/000001.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1915.7677 -2156.2305 -2080.2231
 -2042.4247 -2275.2861 -2167.2202
 -2001.1266 -2190.8811 -2067.0701

(2,.,.) = 
  2868.1687  3032.0828  2920.7227
  3074.4316  3255.6255  3101.2810
  2966.9497  3116.2173  2947.5193

(3,.,.) = 
  3692.6013  4022.3613  4022.0525
  4526.9634  4942.4956  4935.0005
  4949.5420  5429.3745  5406.2524

(4,.,.) = 
  1055.8406  1176.3967  1154.0885
  1320.9844  1421.8793  1369.4788
  1436.1713  1489.9763  1396.8392

(5,.,.) = 
   751.2395   742.7105   663.7333
   737.4086   690.5338   583.9397
   753.7722   671.4290   562.7429

(6,.,.) = 
  1650.9053  1870.9850  1913.3746
  2025.5914  2335.4944  2379.4358
  2329.7483  2676.4683  2704.6682

(7,.,.) = 
 -2759.7888 -2931.8860 -2754.7224
 -2977.3662 -3129.3564 -2865.6135
 -2853.5903 -2931.1404 -2639.1970

(8,.,.) = 
  5779.2109  6191.4590  5947.9907
  6513.2896  6942.2905  6618.1450
  6775.8374  7151.1147  6778.9229

(9,.,.) = 
  2539.2092  3053.0610  3254.2651
  2923.7981  3451.8364  3581.1252
  3193.8074  3729.4465  3816.2456

(10,.,.) = 
 -3418.9814 -3377.1626 -3127.1396
 -3660.4480 -3626.1206 -3355.7720
 -3620.7834 -3578.0059 -3331.4504

(11,.,.) = 
   479.9764   640.0527   731.6675
   753.2801   943.5143  1031.1935
   843.7823  1080.4707  1170.9227

(12,.,.) = 
   448.2219   720.5143   955.4217
   517.3437   835.5132  1059.5413
   275.0999   592.2654   788.3953

(13,.,.) = 
 -2942.0300 -3110.5576 -3007.5222
 -2963.4771 -3119.1975 -3003.7588
 -2894.9402 -3041.7095 -2900.1646

(14,.,.) = 
  5068.8154  5370.7954  5173.6665
  5341.5068  5634.2778  5394.0801
  5282.2715  5598.5122  5328.1426

(15,.,.) = 
  3450.7761  3742.0625  3716.0593
  4019.7053  4408.2246  4358.7188
  4352.2529  4761.1938  4690.1685

(16,.,.) = 
 -2933.5720 -3014.3330 -3002.7122
 -3062.3914 -3177.4927 -3153.8401
 -3193.6060 -3336.9229 -3299.9473

(17,.,.) = 
 -7600.9897 -7999.4556 -7898.1338
 -8721.5498 -9230.2666 -9126.7793
 -9421.6523 -9992.9043 -9868.5254

(18,.,.) = 
  1646.1562  1594.6282  1498.1439
  1834.5951  1754.9993  1648.1541
  1829.1021  1735.9312  1632.9224
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3692.6013183594	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #72: time = 0.601106	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2016e+04   4.2572e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #73	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00060005/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1911.8135 -2151.5212 -2075.4480
 -2037.9529 -2270.0874 -2161.8623
 -1996.9067 -2185.9624 -2061.9231

(2,.,.) = 
  2862.2324  3025.4231  2913.7900
  3068.1394  3248.2070  3093.7974
  2961.6157  3109.5710  2940.6243

(3,.,.) = 
  3681.1018  4009.9756  4009.5840
  4514.7915  4929.3481  4921.6221
  4938.5088  5417.5562  5394.1562

(4,.,.) = 
  1051.7855  1171.8932  1149.6113
  1315.8801  1416.6642  1364.4087
  1430.9817  1484.9031  1392.0216

(5,.,.) = 
   748.4077   739.8504   661.1042
   734.6388   687.6635   581.1731
   751.2785   668.8550   559.8244

(6,.,.) = 
  1645.7797  1865.0399  1907.2699
  2020.9420  2329.4771  2372.8037
  2325.9150  2670.9827  2698.3347

(7,.,.) = 
 -2754.1121 -2925.4209 -2748.2483
 -2972.4409 -3123.2490 -2859.4478
 -2850.5842 -2926.6506 -2634.0945

(8,.,.) = 
  5764.0454  6174.9346  5931.6895
  6498.7456  6926.1699  6602.2148
  6764.6265  7138.1929  6765.5645

(9,.,.) = 
  2531.8718  3044.4822  3245.1677
  2916.7581  3443.5007  3572.1475
  3188.7017  3723.0281  3808.8682

(10,.,.) = 
 -3410.7803 -3368.8286 -3119.1577
 -3653.1750 -3618.2161 -3347.9788
 -3616.1572 -3572.0618 -3324.7964

(11,.,.) = 
   478.5760   638.1620   729.6747
   751.8318   941.5236  1029.1489
   842.8206  1078.8574  1169.2545

(12,.,.) = 
   447.8201   719.3756   953.6296
   516.1312   833.4166  1056.9047
   273.0080   589.1562   784.8778

(13,.,.) = 
 -2935.6724 -3103.5220 -3000.5859
 -2958.0894 -3112.5981 -2996.8933
 -2891.5720 -3036.9084 -2894.7339

(14,.,.) = 
  5056.7881  5357.6758  5160.9116
  5330.6235  5621.8130  5381.6665
  5274.5996  5588.7344  5317.8647

(15,.,.) = 
  3440.2139  3730.5225  3704.5288
  4009.3472  4396.5835  4346.8911
  4343.6230  4751.2832  4679.8364

(16,.,.) = 
 -2924.4189 -3004.6577 -2993.1880
 -3053.0266 -3167.5154 -3144.1060
 -3185.7349 -3328.1243 -3291.2129

(17,.,.) = 
 -7577.0811 -7974.3706 -7873.4136
 -8696.3389 -9203.5986 -9100.1709
 -9398.7559 -9968.4092 -9843.8633

(18,.,.) = 
  1642.0508  1590.5892  1494.1703
  1830.5923  1751.0781  1644.1282
  1825.8083  1732.4158  1628.9823
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3681.1018066406	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #73: time = 0.698059	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2098e+04   4.2630e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #74	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00118002/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1909.3220 -2148.3518 -2071.6885
 -2034.9847 -2266.4126 -2157.5227
 -1993.8254 -2182.2837 -2057.6665

(2,.,.) = 
  2858.8564  3021.0923  2908.6655
  3064.2324  3243.2759  3087.9836
  2957.8293  3104.8926  2935.1436

(3,.,.) = 
  3674.5298  4000.7751  3998.1963
  4506.8398  4918.5010  4908.6108
  4929.9150  5406.2593  5381.0352

(4,.,.) = 
  1050.1580  1169.4410  1146.4164
  1313.4498  1413.2784  1360.2980
  1427.9121  1480.8282  1387.2418

(5,.,.) = 
   747.3506   738.1149   658.6774
   733.5651   685.9459   578.8910
   750.2297   667.4090   557.9512

(6,.,.) = 
  1642.4058  1860.3148  1901.5422
  2017.0524  2324.1799  2366.4949
  2321.7856  2665.5571  2691.9717

(7,.,.) = 
 -2750.6462 -2920.7329 -2742.4053
 -2968.4231 -3118.0730 -2853.2183
 -2846.8586 -2921.9480 -2628.6084

(8,.,.) = 
  5755.5957  6163.2480  5917.1035
  6488.5337  6912.4888  6585.8657
  6753.9248  7124.4019  6749.5337

(9,.,.) = 
  2527.7742  3038.5745  3237.2217
  2911.8389  3436.7832  3563.5144
  3183.4814  3716.2092  3800.2886

(10,.,.) = 
 -3405.9839 -3362.6890 -3111.8215
 -3647.3582 -3610.9453 -3339.6763
 -3609.9224 -3564.4644 -3316.1484

(11,.,.) = 
   477.8843   637.3001   728.6835
   750.6441   940.0684  1027.4611
   841.7513  1077.4401  1167.5084

(12,.,.) = 
   447.7567   719.6292   954.0472
   515.8854   833.3352  1056.9030
   273.0110   589.2700   784.9888

(13,.,.) = 
 -2933.1404 -3100.1982 -2996.3696
 -2955.3394 -3109.1255 -2992.4092
 -2888.5530 -3033.1423 -2890.0559

(14,.,.) = 
  5051.1968  5350.2153  5151.5337
  5324.0283  5613.4224  5371.3433
  5267.4849  5579.7905  5307.0796

(15,.,.) = 
  3434.2358  3722.1973  3694.1821
  4002.2422  4386.9609  4335.2349
  4335.6851  4741.0127  4667.8433

(16,.,.) = 
 -2920.1863 -2998.7791 -2985.4993
 -3048.0239 -3160.7822 -3135.6890
 -3180.2976 -3321.0190 -3282.5068

(17,.,.) = 
 -7565.3862 -7958.2666 -7853.2446
 -8682.1807 -9184.7295 -9077.1436
 -9382.4463 -9947.3887 -9819.2021

(18,.,.) = 
  1639.7554  1587.5671  1490.3961
  1827.5022  1747.2637  1639.6779
  1822.6312  1728.6954  1624.6686
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3674.5297851562	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #74: time = 0.591536	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1932e+04   4.2511e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #75	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00018001/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1915.8530 -2156.3164 -2080.3215
 -2042.5176 -2275.4658 -2167.4333
 -2000.8495 -2190.8220 -2067.0771

(2,.,.) = 
  2868.3040  3032.2102  2920.8596
  3074.6216  3255.8074  3101.5063
  2966.7834  3116.0791  2947.4648

(3,.,.) = 
  3693.2170  4022.9402  4022.4216
  4528.6426  4944.1562  4936.2310
  4952.3374  5432.1035  5408.2529

(4,.,.) = 
  1056.0251  1176.5757  1154.1948
  1321.5580  1422.4543  1369.9625
  1437.0107  1490.8358  1397.5663

(5,.,.) = 
   751.3121   742.7529   663.7693
   737.6862   690.7845   584.0993
   754.1992   671.7585   562.7823

(6,.,.) = 
  1651.4658  1871.5332  1913.8245
  2026.8517  2336.6230  2380.3835
  2331.5066  2677.8706  2705.6768

(7,.,.) = 
 -2760.1523 -2932.1973 -2754.9915
 -2978.1606 -3130.0889 -2866.3103
 -2854.5168 -2931.9314 -2639.8315

(8,.,.) = 
  5779.9556  6192.0293  5948.3384
  6515.4331  6944.2163  6619.6279
  6779.1973  7154.1431  6781.2197

(9,.,.) = 
  2539.7185  3053.5518  3254.7122
  2925.2141  3453.3069  3582.5867
  3195.9741  3731.7178  3818.3630

(10,.,.) = 
 -3419.1782 -3377.2549 -3127.1426
 -3661.3328 -3626.7046 -3356.1016
 -3622.3848 -3579.0215 -3331.8750

(11,.,.) = 
   480.1419   640.2139   731.7686
   753.8954   944.1135  1031.6425
   844.9312  1081.5955  1171.8015

(12,.,.) = 
   448.2034   720.5405   955.4722
   517.3660   835.6015  1059.7196
   275.0232   592.2602   788.5419

(13,.,.) = 
 -2942.0083 -3110.5579 -3007.5667
 -2963.3264 -3119.1389 -3003.8601
 -2894.9370 -3041.8323 -2900.3828

(14,.,.) = 
  5068.9663  5370.9023  5173.7568
  5342.1187  5634.8193  5394.5752
  5283.5532  5599.6987  5329.1260

(15,.,.) = 
  3451.4495  3742.6628  3716.4673
  4021.4644  4409.8887  4360.0425
  4354.9697  4763.7329  4692.1387

(16,.,.) = 
 -2933.7578 -3014.4976 -3002.8215
 -3063.1685 -3178.2361 -3154.4602
 -3195.0396 -3338.2568 -3300.9822

(17,.,.) = 
 -7601.7764 -8000.0688 -7898.4551
 -8724.1357 -9232.5518 -9128.4756
 -9426.2588 -9996.9658 -9871.5039

(18,.,.) = 
  1646.2285  1594.6594  1498.1814
  1834.8916  1755.2327  1648.2903
  1829.6949  1736.3331  1633.0547
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3693.2170410156	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #75: time = 0.590347	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2074e+04   4.2603e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #76	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00001001/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1915.6613 -2155.8955 -2079.6079
 -2042.3433 -2274.9705 -2166.4832
 -2001.2616 -2190.8245 -2066.3779

(2,.,.) = 
  2868.0007  3031.4497  2919.6553
  3074.5376  3255.0764  3100.2588
  2967.8235  3116.3354  2946.9246

(3,.,.) = 
  3692.4631  4021.2620  4019.2859
  4527.2520  4941.5322  4931.8022
  4950.3267  5428.7485  5402.9243

(4,.,.) = 
  1055.7231  1176.0396  1153.2122
  1320.4840  1421.0525  1367.8878
  1435.2007  1488.5916  1394.4803

(5,.,.) = 
   751.2188   742.7269   663.6172
   737.4436   690.5538   583.6422
   753.9652   671.4854   562.0812

(6,.,.) = 
  1651.1382  1870.4904  1911.9594
  2026.4744  2335.2297  2377.7983
  2331.1821  2676.4900  2703.0618

(7,.,.) = 
 -2760.6260 -2932.2019 -2754.4990
 -2979.2898 -3130.4907 -2866.0027
 -2857.0579 -2933.5266 -2640.3528

(8,.,.) = 
  5779.5674  6190.3271  5944.9053
  6514.8452  6941.8379  6614.9624
  6779.3613  7152.0942  6776.1885

(9,.,.) = 
  2539.6890  3052.8311  3252.9307
  2925.1582  3452.2625  3579.9814
  3196.5222  3731.0894  3815.8721

(10,.,.) = 
 -3418.9434 -3376.2983 -3125.3958
 -3661.2217 -3625.3611 -3353.5981
 -3623.0173 -3577.9084 -3328.9883

(11,.,.) = 
   479.9664   639.6569   730.8510
   753.3499   943.0368  1030.2727
   843.9555  1080.0496  1170.0277

(12,.,.) = 
   448.1159   720.4946   955.5862
   517.0506   835.4203  1059.8656
   274.3984   591.7551   788.4395

(13,.,.) = 
 -2942.1907 -3110.3186 -3006.9673
 -2964.4241 -3119.4536 -3003.3430
 -2897.6375 -3043.3652 -2900.5906

(14,.,.) = 
  5068.7812  5369.7739  5171.6270
  5342.5981  5633.7358  5391.9746
  5285.6011  5599.5322  5326.7388

(15,.,.) = 
  3450.7468  3740.9509  3713.3657
  4020.2576  4407.2388  4355.5459
  4353.6309  4760.7480  4687.0405

(16,.,.) = 
 -2933.1868 -3013.2258 -3000.7336
 -3062.0928 -3176.0776 -3151.1091
 -3194.0449 -3335.7163 -3296.7864

(17,.,.) = 
 -7599.7549 -7996.1992 -7891.9727
 -8720.1816 -9225.9170 -9118.3965
 -9420.8076 -9988.2217 -9858.6504

(18,.,.) = 
  1646.0077  1594.1807  1497.3226
  1834.7576  1754.6683  1647.1638
  1829.7480  1735.7180  1631.6282
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3692.4631347656	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #76: time = 0.614447	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2080e+04   4.2598e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #77	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00108003/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 240
 320
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 320
 320
[torch.LongStorage of size 3]

x_start = 1 / y_start = 41	
img_means:size() vs img:size():	
   3
 240
 320
[torch.LongStorage of size 3]

   3
 240
 320
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 2.5	
(orep_img_for_blob) img size after scaling:	
   3
 600
 800
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x97
  2 : CudaTensor - size: 18x72x97
  3 : CudaTensor - size: 18x70x95
  4 : CudaTensor - size: 18x68x93
  5 : CudaTensor - size: 256x74x99
}
proposal_im_deteect: img_blob size:    3
 600
 800
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 240
 320
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 2.5	
proposal_im_detect: scaled_img_size:	
   8
 600
 800
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1916.9259  -2157.6863  -2079.9495
  -2046.8346  -2279.8069  -2169.7341
  -2007.7942  -2197.8135  -2071.6001

(2,.,.) = 
   2870.6829   3033.6904   2920.7239
   3080.4258   3261.1165   3104.3293
   2976.1323   3124.9954   2953.6760

(3,.,.) = 
   3718.9460   4048.5964   4044.6970
   4560.8809   4976.6987   4964.9648
   4987.8813   5468.4600   5440.0610

(4,.,.) = 
   1068.1666   1190.1831   1167.2145
   1334.2264   1436.6954   1383.7410
   1449.6249   1504.6564   1410.1682

(5,.,.) = 
    760.0515    750.2137    668.4746
    747.0367    699.4073    590.1802
    763.3927    680.5166    570.2177

(6,.,.) = 
   1670.2699   1891.4934   1932.3134
   2048.8979   2359.3179   2400.8831
   2354.7603   2702.0405   2727.2039

(7,.,.) = 
  -2780.0071  -2951.8115  -2772.7764
  -3001.5854  -3153.2773  -2886.7148
  -2880.1355  -2957.0051  -2661.7151

(8,.,.) = 
   5820.6265   6231.5708   5981.7622
   6563.0005   6990.4858   6658.9272
   6830.3384   7204.2349   6823.4844

(9,.,.) = 
   2562.2163   3078.4424   3280.1155
   2953.9480   3484.4429   3612.8953
   3226.3838   3763.7910   3848.4963

(10,.,.) = 
  -3424.9553  -3381.2163  -3129.6243
  -3670.6411  -3634.2817  -3360.9238
  -3636.8086  -3591.9216  -3342.0791

(11,.,.) = 
    487.7002    648.4060    738.8175
    760.1288    950.6928   1037.9231
    850.8574   1088.4445   1178.9496

(12,.,.) = 
    446.8216    721.1613    956.4069
    515.9043    836.7388   1061.6097
    274.8121    594.6846    792.0764

(13,.,.) = 
  -2950.6841  -3117.6938  -3013.1450
  -2977.6030  -3132.2646  -3014.9980
  -2913.2510  -3058.4946  -2913.5381

(14,.,.) = 
   5087.6392   5387.6772   5186.3364
   5367.0322   5657.3110   5412.7568
   5314.6265   5628.4731   5352.5908

(15,.,.) = 
   3481.3931   3773.8103   3744.2781
   4056.2871   4445.8994   4392.0762
   4391.9023   4801.9902   4725.7451

(16,.,.) = 
  -2943.8706  -3023.1924  -3009.7297
  -3079.6060  -3192.9141  -3166.8445
  -3216.0811  -3358.0466  -3318.2224

(17,.,.) = 
  -7649.5620  -8045.6118  -7937.0073
  -8781.3018  -9288.4199  -9177.1807
  -9489.0908 -10058.9277  -9925.6592

(18,.,.) = 
   1649.3602   1596.1886   1498.5525
   1840.3411   1758.6835   1650.9613
   1838.3539   1743.2122   1639.2327
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 95
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 19950
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 95
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 95
[torch.LongStorage of size 2]

shift_y size:	
 70
 95
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6650
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 19950
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  19950
[torch.LongStorage of size 1]
	
  first line: 3718.9460449219	
(fast bbox transform) src_w size:  19950
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 19950
     4
[torch.LongStorage of size 2]

scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 19950
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 53200
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13300
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13300
[torch.LongStorage of size 1]

test img #77: time = 0.37694399999999	
(proposal_test:boxes_filter) boxes & scores size:	
 13300
     4
[torch.LongStorage of size 2]

 13300
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 953
   3
[torch.LongTensor of size 2]

mask size:	
 13300
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   3.2000e+02   3.2000e+02
        -inf         -inf   2.4194e+04   1.4257e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #78	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00034008/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1903.4486 -2141.9661 -2066.1360
 -2028.5045 -2259.3970 -2151.5107
 -1987.1906 -2174.9634 -2051.4722

(2,.,.) = 
  2849.8208  3012.1013  2900.6880
  3054.2644  3233.1797  3079.3169
  2947.9333  3094.7341  2926.3953

(3,.,.) = 
  3657.1394  3984.1301  3984.4468
  4486.5342  4898.5708  4891.6074
  4908.4097  5384.8828  5362.4683

(4,.,.) = 
  1044.4043  1163.7709  1141.8088
  1306.7372  1407.0876  1355.3529
  1421.2407  1474.7383  1382.5027

(5,.,.) = 
   742.8460   734.1194   655.8130
   729.0084   681.8348   575.8868
   745.4492   663.0726   554.5056

(6,.,.) = 
  1633.6475  1851.2528  1893.6586
  2006.7141  2313.2200  2356.7102
  2310.5027  2653.5400  2681.1594

(7,.,.) = 
 -2739.3660 -2909.4927 -2732.6335
 -2955.9570 -3105.6162 -2842.7061
 -2834.2795 -2909.5535 -2617.8850

(8,.,.) = 
  5731.4062  6140.1616  5898.2388
  6461.8057  6886.8433  6564.8203
  6726.0181  7097.3511  6726.8413

(9,.,.) = 
  2515.5745  3025.7600  3225.7170
  2897.8159  3422.1169  3550.4492
  3168.6807  3700.5452  3786.2646

(10,.,.) = 
 -3393.8633 -3351.7988 -3102.9736
 -3634.3083 -3599.1736 -3330.0115
 -3596.7156 -3552.3977 -3306.1333

(11,.,.) = 
   475.6195   634.6260   726.1464
   747.5420   936.6193  1024.1831
   838.5087  1073.6588  1163.8279

(12,.,.) = 
   446.5132   717.0538   950.4718
   514.1755   830.1876  1052.8663
   271.7638   586.4227   781.2136

(13,.,.) = 
 -2922.9204 -3090.0427 -2987.4673
 -2944.9500 -3098.5447 -2983.1526
 -2877.8975 -3022.3601 -2880.8281

(14,.,.) = 
  5032.9814  5332.6631  5136.8789
  5304.7002  5594.7783  5355.6582
  5247.7417  5560.3472  5290.6997

(15,.,.) = 
  3418.0579  3706.3979  3680.9761
  3983.8081  4368.6279  4319.6577
  4316.2080  4721.3179  4650.8447

(16,.,.) = 
 -2907.5388 -2987.4717 -2976.5703
 -3034.3608 -3148.4822 -3125.8718
 -3165.9941 -3307.6624 -3271.6221

(17,.,.) = 
 -7531.4019 -7926.4722 -7827.1221
 -8644.0342 -9148.5029 -9046.6748
 -9342.5811 -9909.1143 -9786.5469

(18,.,.) = 
  1633.8326  1582.5703  1486.4188
  1821.0509  1742.0176  1635.3801
  1815.9009  1723.0045  1619.8717
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3657.1394042969	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #78: time = 0.56372	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1641e+04   4.2329e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #79	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00001002/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1915.3488 -2155.7139 -2079.7170
 -2042.1211 -2274.9307 -2166.7869
 -2001.3677 -2191.1648 -2067.0840

(2,.,.) = 
  2867.6548  3031.3567  2919.8901
  3074.2498  3255.0464  3100.5291
  2967.7949  3116.5161  2947.4890

(3,.,.) = 
  3693.8076  4023.5737  4022.9148
  4529.5679  4945.3271  4937.2432
  4953.9990  5434.2427  5410.2676

(4,.,.) = 
  1056.1671  1176.8210  1154.4603
  1321.2981  1422.4041  1369.9597
  1436.4747  1490.6786  1397.4738

(5,.,.) = 
   751.3727   742.9073   663.8721
   737.6044   690.7852   583.9850
   754.1739   671.7991   562.6114

(6,.,.) = 
  1652.0931  1872.0549  1914.2037
  2027.9073  2337.3481  2380.6118
  2333.3899  2679.3960  2706.5728

(7,.,.) = 
 -2760.7546 -2932.7913 -2755.6245
 -2979.5173 -3131.1174 -2867.1096
 -2857.5557 -2934.3789 -2641.6467

(8,.,.) = 
  5780.8984  6192.9839  5949.2925
  6517.2480  6946.0015  6621.2070
  6783.3306  7158.0952  6784.5088

(9,.,.) = 
  2540.4817  3054.3335  3255.3792
  2926.5020  3454.5862  3583.4246
  3198.5713  3734.2629  3820.2576

(10,.,.) = 
 -3419.4602 -3377.5664 -3127.5586
 -3662.2935 -3627.3687 -3356.7317
 -3624.9651 -3580.9873 -3333.3411

(11,.,.) = 
   480.4647   640.4396   731.9974
   754.1164   944.1943  1031.8473
   844.9885  1081.5293  1171.9778

(12,.,.) = 
   447.8198   720.0267   954.8651
   516.4854   834.5927  1058.7120
   273.6768   590.7959   787.1871

(13,.,.) = 
 -2941.6489 -3109.9985 -3006.9880
 -2963.9573 -3119.2419 -3003.5420
 -2897.5525 -3043.6011 -2901.2949

(14,.,.) = 
  5068.7285  5370.4624  5173.3457
  5343.1099  5635.1973  5394.7256
  5287.1943  5602.3042  5331.0161

(15,.,.) = 
  3452.1748  3743.5195  3717.2891
  4022.6104  4411.0811  4361.0532
  4357.2959  4766.1650  4694.2280

(16,.,.) = 
 -2933.7053 -3014.3398 -3002.6252
 -3063.2236 -3178.0510 -3154.1677
 -3195.9229 -3338.7119 -3301.2163

(17,.,.) = 
 -7602.1606 -8000.5986 -7898.8662
 -8724.6309 -9233.1641 -9128.9619
 -9427.9619 -9998.8779 -9873.2051

(18,.,.) = 
  1646.1770  1594.6564  1498.1696
  1835.1708  1755.4637  1648.4491
  1830.4738  1736.8679  1633.4055
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3693.8076171875	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #79: time = 0.54543600000001	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2273e+04   4.2741e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #80	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00017000/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1906.5996 -2145.6931 -2069.8992
 -2032.3628 -2263.9119 -2156.0254
 -1991.4749 -2180.0850 -2056.3972

(2,.,.) = 
  2854.5496  3017.2839  2905.9944
  3059.7659  3239.3091  3085.2932
  2953.5483  3101.0613  2932.5222

(3,.,.) = 
  3670.7656  3998.6370  3998.1975
  4501.9170  4915.1382  4907.2822
  4924.2485  5401.6191  5378.0063

(4,.,.) = 
  1048.8241  1168.6844  1146.4812
  1312.3029  1412.8402  1360.7085
  1426.9575  1480.7043  1388.0105

(5,.,.) = 
   746.3473   737.8470   659.2609
   732.6010   685.7344   579.4593
   749.1694   666.9155   558.0631

(6,.,.) = 
  1640.7386  1859.2003  1901.3087
  2014.4495  2321.9409  2365.1223
  2318.3801  2662.3059  2689.4851

(7,.,.) = 
 -2746.2915 -2917.1301 -2740.4211
 -2963.6672 -3114.0828 -2850.9902
 -2842.0925 -2917.9773 -2626.2324

(8,.,.) = 
  5748.1904  6157.9219  5915.3022
  6480.4355  6906.5981  6583.3691
  6745.2080  7117.5151  6745.6250

(9,.,.) = 
  2524.8154  3035.9084  3235.9463
  2908.2991  3433.5354  3561.7129
  3179.2542  3712.0459  3797.5776

(10,.,.) = 
 -3402.1843 -3360.1438 -3110.9287
 -3643.5312 -3608.3508 -3338.6570
 -3606.0894 -3561.7578 -3314.8860

(11,.,.) = 
   477.1159   636.2874   727.6656
   749.5540   938.8038  1026.2421
   840.2371  1075.6305  1165.7739

(12,.,.) = 
   446.2968   717.1741   951.0217
   514.3631   830.9167  1054.0770
   272.0115   587.4684   782.9589

(13,.,.) = 
 -2928.0393 -3095.4246 -2992.6792
 -2950.0535 -3104.1921 -2988.6765
 -2883.5747 -3028.5679 -2886.6887

(14,.,.) = 
  5043.5210  5343.5825  5147.2280
  5316.2197  5606.6587  5366.9673
  5260.0078  5573.2480  5302.8989

(15,.,.) = 
  3430.4543  3719.8975  3693.9836
  3997.6577  4383.7056  4334.1064
  4330.6099  4736.9570  4665.6045

(16,.,.) = 
 -2916.9607 -2996.9792 -2985.4556
 -3044.9905 -3159.0828 -3135.5471
 -3176.9023 -3318.7073 -3281.5938

(17,.,.) = 
 -7556.3145 -7952.3823 -7851.4810
 -8672.2832 -9177.7861 -9074.2646
 -9372.0420 -9939.4824 -9814.6426

(18,.,.) = 
  1637.8718  1586.4747  1490.2255
  1825.7001  1746.2881  1639.5157
  1820.7311  1727.4305  1624.1361
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3670.765625	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #80: time = 0.530225	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1849e+04   4.2473e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #81	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00054000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 240
 320
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 320
 320
[torch.LongStorage of size 3]

x_start = 1 / y_start = 41	
img_means:size() vs img:size():	
   3
 240
 320
[torch.LongStorage of size 3]

   3
 240
 320
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 2.5	
(orep_img_for_blob) img size after scaling:	
   3
 600
 800
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x97
  2 : CudaTensor - size: 18x72x97
  3 : CudaTensor - size: 18x70x95
  4 : CudaTensor - size: 18x68x93
  5 : CudaTensor - size: 256x74x99
}
proposal_im_deteect: img_blob size:    3
 600
 800
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 240
 320
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 2.5	
proposal_im_detect: scaled_img_size:	
   8
 600
 800
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1921.3746  -2163.7341  -2087.8855
  -2051.2681  -2286.0022  -2178.1519
  -2011.8821  -2203.6392  -2079.5806

(2,.,.) = 
   2876.9917   3042.4578   2932.1360
   3086.7588   3270.2061   3116.1941
   2981.5256   3132.9709   2964.5774

(3,.,.) = 
   3732.9995   4066.7122   4065.6858
   4577.1626   4998.0146   4989.5488
   5004.6323   5490.3408   5465.1958

(4,.,.) = 
   1073.0405   1196.1272   1173.5540
   1340.4407   1443.6725   1390.8612
   1455.8275   1511.7588   1417.2627

(5,.,.) = 
    761.4056    752.9484    672.5568
    748.1203    701.7394    593.8040
    764.0528    682.2402    573.1682

(6,.,.) = 
   1676.8828   1900.3688   1942.4717
   2056.4116   2369.6750   2412.9460
   2363.2434   2713.5396   2740.4775

(7,.,.) = 
  -2783.7734  -2957.9478  -2781.2134
  -3005.3833  -3159.5552  -2895.1377
  -2882.9126  -2961.9805  -2668.7312

(8,.,.) = 
   5835.3916   6251.6602   6006.4805
   6579.0986   7012.3989   6685.3428
   6845.8125   7225.2676   6848.7617

(9,.,.) = 
   2569.7002   3088.7217   3292.2849
   2962.3662   3495.7422   3626.2134
   3234.6865   3775.1284   3861.8662

(10,.,.) = 
  -3434.1182  -3393.2324  -3144.1494
  -3679.8821  -3646.4548  -3375.7334
  -3645.1680  -3602.8884  -3355.5786

(11,.,.) = 
    489.9120    651.3989    741.9449
    763.1267    954.5428   1041.8405
    853.7764   1092.3605   1182.8929

(12,.,.) = 
    448.1558    722.9817    958.6301
    517.5174    838.7122   1063.9237
    276.2377    596.5737    794.2239

(13,.,.) = 
  -2954.9194  -3124.4192  -3022.5234
  -2980.5950  -3137.8188  -3023.7478
  -2915.4790  -3063.1880  -2921.4631

(14,.,.) = 
   5098.4326   5402.8965   5205.8022
   5377.3530   5671.8877   5431.7910
   5323.7969   5641.6685   5370.2051

(15,.,.) = 
   3493.3530   3789.2314   3762.2358
   4069.5933   4463.0640   4412.0103
   4405.7173   4819.6060   4745.9321

(16,.,.) = 
  -2954.3684  -3036.8130  -3025.7117
  -3090.0334  -3206.4575  -3182.6184
  -3225.4675  -3370.7229  -3333.0535

(17,.,.) = 
  -7677.5586  -8080.9648  -7978.3892
  -8812.1221  -9327.2383  -9222.5566
  -9520.4512 -10098.4814  -9971.3994

(18,.,.) = 
   1653.8589   1602.2465   1506.0510
   1845.1652   1765.1984   1658.8667
   1842.8417   1749.2590   1646.5201
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 95
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 19950
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 95
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 95
[torch.LongStorage of size 2]

shift_y size:	
 70
 95
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6650
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 19950
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  19950
[torch.LongStorage of size 1]
	
  first line: 3732.9995117188	
(fast bbox transform) src_w size:  19950
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 19950
     4
[torch.LongStorage of size 2]

scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 19950
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 53200
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13300
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13300
[torch.LongStorage of size 1]

test img #81: time = 0.38118399999999	
(proposal_test:boxes_filter) boxes & scores size:	
 13300
     4
[torch.LongStorage of size 2]

 13300
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 953
   3
[torch.LongTensor of size 2]

mask size:	
 13300
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   3.2000e+02   3.2000e+02
        -inf         -inf   2.4272e+04   1.4303e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #82	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00045000/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1907.6155 -2147.1826 -2071.3164
 -2034.4047 -2266.3970 -2158.4890
 -1994.0081 -2183.0637 -2059.3101

(2,.,.) = 
  2856.3201  3019.4446  2908.3862
  3062.5603  3242.8203  3088.8738
  2956.8909  3105.1721  2936.8020

(3,.,.) = 
  3680.6890  4009.5420  4008.8958
  4514.6323  4929.1548  4921.0146
  4938.5854  5417.4277  5393.2686

(4,.,.) = 
  1053.3506  1173.8468  1151.5640
  1317.4503  1418.6001  1366.3558
  1432.3933  1486.6681  1393.5101

(5,.,.) = 
   749.0090   740.4199   661.4331
   735.6051   688.7836   582.1492
   752.0992   670.0008   561.2605

(6,.,.) = 
  1647.9210  1867.4164  1909.5006
  2023.0381  2331.6689  2374.8213
  2327.7456  2672.9546  2700.0159

(7,.,.) = 
 -2752.9971 -2924.3848 -2747.7356
 -2971.4666 -3122.5862 -2859.3850
 -2850.0835 -2926.6511 -2634.7981

(8,.,.) = 
  5762.8315  6173.5303  5930.2192
  6497.7314  6924.9673  6600.8369
  6763.4160  7136.9009  6763.9424

(9,.,.) = 
  2532.8313  3045.4697  3246.3069
  2918.6243  3445.4404  3574.1270
  3190.1138  3724.3289  3810.0437

(10,.,.) = 
 -3404.8254 -3362.9910 -3114.0288
 -3647.2529 -3612.5054 -3342.7905
 -3610.9880 -3567.2178 -3320.4937

(11,.,.) = 
   480.0964   639.6810   730.5978
   752.3135   941.9201  1029.1383
   843.0893  1079.0551  1169.1395

(12,.,.) = 
   446.5913   718.2726   952.1663
   514.8871   832.4145  1055.7299
   273.2101   589.6804   785.3439

(13,.,.) = 
 -2931.3643 -3099.0190 -2996.5886
 -2954.7896 -3109.4143 -2994.4172
 -2888.8181 -3034.2556 -2892.6060

(14,.,.) = 
  5050.9907  5351.6509  5155.1763
  5325.3735  5616.3594  5376.7212
  5270.2681  5584.1719  5313.7070

(15,.,.) = 
  3441.6113  3732.2429  3705.9602
  4010.8752  4398.2915  4348.1987
  4344.8115  4752.5586  4680.4600

(16,.,.) = 
 -2921.3298 -3001.7883 -2990.4514
 -3051.5107 -3166.0286 -3142.5408
 -3184.7009 -3327.2371 -3290.1677

(17,.,.) = 
 -7575.5142 -7972.6597 -7871.3145
 -8695.5693 -9202.6875 -9098.8096
 -9397.9355 -9967.1934 -9841.7158

(18,.,.) = 
  1639.3759  1587.8668  1491.6753
  1828.0050  1748.4598  1641.9327
  1823.9554  1730.6605  1627.6864
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3680.6889648438	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #82: time = 0.517566	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2062e+04   4.2629e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #83	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00010003/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1920
 1920
[torch.LongStorage of size 3]

x_start = 1 / y_start = 421	
img_means:size() vs img:size():	
    3
 1080
 1920
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.55555555555556	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
 1080
 1920
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.55555555555556	
proposal_im_detect: scaled_img_size:	
    2
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1908.4076 -2147.5105 -2071.0601
 -2035.2048 -2266.8540 -2158.3523
 -1995.3367 -2184.2803 -2059.9207

(2,.,.) = 
  2858.4019  3020.7957  2908.6233
  3064.7393  3244.2771  3089.1492
  2959.0356  3106.9055  2937.5405

(3,.,.) = 
  3685.7073  4012.6106  4009.4250
  4521.0586  4933.8540  4922.8052
  4946.5776  5423.9995  5397.0649

(4,.,.) = 
  1054.7300  1174.5422  1151.3207
  1319.8433  1420.2144  1366.9570
  1435.8783  1489.5433  1395.5779

(5,.,.) = 
   750.6061   741.4283   661.8282
   737.0397   689.5656   582.3042
   753.8165   671.2324   561.9877

(6,.,.) = 
  1650.2977  1869.2107  1909.8248
  2025.8176  2333.8235  2375.4863
  2331.3350  2675.9365  2701.4668

(7,.,.) = 
 -2755.6609 -2926.6064 -2749.0408
 -2973.6926 -3124.4121 -2860.0496
 -2851.8081 -2927.9297 -2635.3254

(8,.,.) = 
  5768.4414  6177.0518  5930.9297
  6504.1060  6929.4741  6602.2788
  6771.1348  7142.9199  6767.2900

(9,.,.) = 
  2536.0759  3047.9507  3247.0278
  2922.1394  3448.3330  3575.3010
  3194.4822  3728.4504  3812.8301

(10,.,.) = 
 -3408.6885 -3366.0151 -3115.3916
 -3651.4514 -3615.8145 -3344.7583
 -3614.8452 -3570.5391 -3322.7856

(11,.,.) = 
   480.6609   640.0635   730.5134
   753.4910   943.0380  1029.7847
   844.2502  1080.3511  1170.0817

(12,.,.) = 
   447.2521   719.1454   952.8008
   515.5653   833.3637  1056.5547
   273.4913   590.3650   786.0681

(13,.,.) = 
 -2933.9736 -3101.4460 -2997.7727
 -2956.7542 -3111.6436 -2995.6929
 -2890.7874 -3036.5381 -2893.9714

(14,.,.) = 
  5055.7573  5355.1968  5156.3589
  5330.2539  5620.3281  5378.6763
  5275.3574  5588.7393  5316.4819

(15,.,.) = 
  3445.8718  3735.0334  3706.5386
  4016.4048  4402.5176  4350.1211
  4351.9814  4758.6777  4684.2603

(16,.,.) = 
 -2925.6973 -3004.4753 -2990.8147
 -3056.7607 -3169.6946 -3143.9360
 -3191.3384 -3332.6299 -3293.3625

(17,.,.) = 
 -7585.8613 -7979.3018 -7872.6470
 -8709.1914 -9212.6885 -9103.2686
 -9414.6855 -9980.9746 -9850.2148

(18,.,.) = 
  1641.4670  1589.1544  1492.3022
  1830.0656  1749.4923  1642.2344
  1825.7649  1731.5892  1628.1166
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3685.7072753906	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #83: time = 0.827416	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.9200e+03   1.9200e+03
        -inf         -inf   1.0830e+05   6.4140e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #84	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00074003/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1913.6376 -2153.7778 -2077.8940
 -2040.4106 -2273.0156 -2164.9312
 -1999.8689 -2189.4854 -2065.5068

(2,.,.) = 
  2865.1318  3028.6284  2917.2446
  3071.6353  3252.1816  3097.8130
  2965.5908  3114.1045  2945.1853

(3,.,.) = 
  3689.8328  4019.5347  4019.1873
  4525.0293  4940.6045  4932.8052
  4949.4385  5429.3711  5405.6641

(4,.,.) = 
  1054.9791  1175.7129  1153.4597
  1319.9407  1421.1688  1368.8485
  1435.0863  1489.4049  1396.2944

(5,.,.) = 
   750.4152   742.0267   663.0570
   736.7986   690.0252   583.2578
   753.4811   671.1615   561.9879

(6,.,.) = 
  1650.1150  1869.8447  1912.0822
  2025.5237  2334.6597  2378.0217
  2330.7910  2676.5105  2703.7964

(7,.,.) = 
 -2758.3262 -2930.1145 -2752.9944
 -2976.9661 -3128.3413 -2864.4258
 -2855.4287 -2932.0781 -2639.4116

(8,.,.) = 
  5775.6709  6187.5752  5944.2388
  6511.7144  6940.2144  6615.7974
  6778.1392  7152.6499  6779.3389

(9,.,.) = 
  2538.0840  3051.5747  3252.5234
  2923.8364  3451.6506  3580.4888
  3195.9285  3731.3330  3817.3799

(10,.,.) = 
 -3416.8174 -3374.8206 -3124.9451
 -3659.5376 -3624.4368 -3353.9382
 -3622.4316 -3578.2344 -3330.5938

(11,.,.) = 
   480.1306   640.0569   731.6401
   753.4564   943.4963  1031.1906
   844.3123  1080.7531  1171.2104

(12,.,.) = 
   447.2900   719.2292   953.9402
   515.7118   833.5840  1057.6390
   273.1377   590.0568   786.4288

(13,.,.) = 
 -2939.3572 -3107.4507 -3004.4700
 -2961.7742 -3116.7795 -3001.0732
 -2895.6562 -3041.4292 -2899.0898

(14,.,.) = 
  5064.6768  5366.1274  5169.1982
  5339.0884  5630.8965  5390.5664
  5283.6079  5598.3735  5327.1772

(15,.,.) = 
  3448.7029  3739.9275  3713.9346
  4018.7390  4407.0059  4357.2402
  4353.3433  4761.9897  4690.2954

(16,.,.) = 
 -2930.8999 -3011.6091 -3000.1353
 -3060.4158 -3175.2605 -3151.6150
 -3193.1816 -3335.9236 -3298.6064

(17,.,.) = 
 -7594.4292 -7992.8657 -7891.7144
 -8716.3564 -9224.7295 -9121.0156
 -9419.6211 -9990.1738 -9864.8682

(18,.,.) = 
  1644.8104  1593.2990  1496.8054
  1833.6777  1753.9850  1646.9622
  1829.0896  1735.5156  1632.0432
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3689.8327636719	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #84: time = 0.556966	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2230e+04   4.2713e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #85	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00027002/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 480
 480
[torch.LongStorage of size 3]

x_start = 1 / y_start = 61	
img_means:size() vs img:size():	
   3
 360
 480
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6666666666667	
(orep_img_for_blob) img size after scaling:	
   3
 600
 800
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x97
  2 : CudaTensor - size: 18x72x97
  3 : CudaTensor - size: 18x70x95
  4 : CudaTensor - size: 18x68x93
  5 : CudaTensor - size: 256x74x99
}
proposal_im_deteect: img_blob size:    3
 600
 800
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 360
 480
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6666666666667	
proposal_im_detect: scaled_img_size:	
   5
 600
 800
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1925.2074  -2168.1587  -2092.6099
  -2053.4211  -2288.6926  -2181.1011
  -2011.9855  -2203.7715  -2079.7371

(2,.,.) = 
   2882.0010   3048.5713   2938.6367
   3090.0374   3274.4446   3120.6638
   2982.2153   3133.9719   2965.6509

(3,.,.) = 
   3736.9663   4071.3948   4071.4771
   4579.1348   5000.9556   4993.8071
   5001.2202   5487.9302   5464.4639

(4,.,.) = 
   1075.1034   1198.1023   1175.7068
   1340.9442   1443.9047   1391.4119
   1453.7499   1509.2260   1415.3175

(5,.,.) = 
    762.5178    754.4194    674.6185
    747.4922    701.3987    594.0619
    761.4031    679.4434    570.8278

(6,.,.) = 
   1677.0204   1901.8461   1944.8358
   2056.0029   2370.7620   2415.0271
   2361.9231   2713.1260   2741.1091

(7,.,.) = 
  -2785.2505  -2960.3171  -2784.2576
  -3005.4656  -3160.1260  -2896.5024
  -2880.7036  -2959.6670  -2667.0354

(8,.,.) = 
   5838.6846   6256.6880   6012.9995
   6577.3682   7012.0269   6686.6782
   6837.1548   7217.1289   6842.6436

(9,.,.) = 
   2569.8962   3089.6433   3293.9001
   2960.4209   3494.2410   3625.6282
   3230.2095   3770.7007   3858.3408

(10,.,.) = 
  -3436.5422  -3397.1917  -3149.4407
  -3678.8506  -3647.0479  -3377.6433
  -3640.7756  -3599.7195  -3353.8628

(11,.,.) = 
    489.3200    651.0858    741.8972
    762.7023    954.2847   1041.8273
    852.7598   1091.3154   1182.0032

(12,.,.) = 
    451.0953    726.4121    962.4763
    521.1954    842.8716   1068.4335
    279.0804    599.6516    797.3408

(13,.,.) = 
  -2957.8982  -3128.3972  -3027.1296
  -2981.0898  -3138.9893  -3025.6147
  -2913.8438  -3061.6831  -2920.8643

(14,.,.) = 
   5102.7798   5408.9727   5213.0903
   5376.8174   5672.6196   5433.8540
   5318.3413   5636.8218   5366.8267

(15,.,.) = 
   3494.9058   3791.5969   3765.6274
   4067.9041   4462.2334   4412.3145
   4399.9341   4814.0244   4741.6494

(16,.,.) = 
  -2957.5828  -3040.6895  -3030.2996
  -3089.1082  -3206.1199  -3182.9863
  -3219.7534  -3365.3396  -3328.6187

(17,.,.) = 
  -7685.8047  -8091.8540  -7991.6235
  -8812.4570  -9330.2676  -9228.5410
  -9510.3604 -10090.8428  -9967.3262

(18,.,.) = 
   1656.0283   1605.0918   1509.5164
   1846.1920   1766.9449   1661.2034
   1841.4652   1748.6350   1646.2938
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 95
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 19950
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 95
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 95
[torch.LongStorage of size 2]

shift_y size:	
 70
 95
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6650
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 19950
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  19950
[torch.LongStorage of size 1]
	
  first line: 3736.9663085938	
(fast bbox transform) src_w size:  19950
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 19950
     4
[torch.LongStorage of size 2]

scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 19950
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 53200
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13300
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13300
[torch.LongStorage of size 1]

test img #85: time = 0.32361400000001	
(proposal_test:boxes_filter) boxes & scores size:	
 13300
     4
[torch.LongStorage of size 2]

 13300
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 953
   3
[torch.LongTensor of size 2]

mask size:	
 13300
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   4.8000e+02   4.8000e+02
        -inf         -inf   3.6304e+04   2.1387e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #86	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00027000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 480
 480
[torch.LongStorage of size 3]

x_start = 1 / y_start = 61	
img_means:size() vs img:size():	
   3
 360
 480
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6666666666667	
(orep_img_for_blob) img size after scaling:	
   3
 600
 800
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x97
  2 : CudaTensor - size: 18x72x97
  3 : CudaTensor - size: 18x70x95
  4 : CudaTensor - size: 18x68x93
  5 : CudaTensor - size: 256x74x99
}
proposal_im_deteect: img_blob size:    3
 600
 800
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 360
 480
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6666666666667	
proposal_im_detect: scaled_img_size:	
   5
 600
 800
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1927.7083  -2170.9985  -2095.1470
  -2058.1685  -2293.8245  -2185.9089
  -2018.7714  -2211.3801  -2087.1494

(2,.,.) = 
   2886.3818   3052.6462   2942.3621
   3096.9849   3281.3345   3127.1575
   2991.4270   3143.7119   2975.1057

(3,.,.) = 
   3748.7874   4084.1321   4083.2695
   4595.8228   5018.7246   5010.4917
   5024.3472   5512.2891   5487.3159

(4,.,.) = 
   1077.9136   1201.6389   1179.0276
   1346.4246   1450.1565   1397.1993
   1462.0200   1518.3774   1423.6924

(5,.,.) = 
    764.6414    756.2747    675.6810
    751.2780    704.9703    596.7516
    767.2248    685.3126    575.9838

(6,.,.) = 
   1684.2871   1908.8636   1951.1646
   2065.1348   2379.8103   2423.2930
   2372.8486   2724.6411   2751.7397

(7,.,.) = 
  -2793.3950  -2968.4426  -2791.4761
  -3015.8135  -3170.8159  -2905.8254
  -2892.9363  -2972.5969  -2678.7205

(8,.,.) = 
   5857.4429   6275.6577   6030.2310
   6603.6758   7039.0723   6711.4106
   6870.9897   7252.3804   6875.1992

(9,.,.) = 
   2580.1953   3101.1951   3305.5957
   2974.2244   3509.6726   3640.8042
   3247.0842   3789.6040   3876.9380

(10,.,.) = 
  -3446.5989  -3406.0476  -3156.6028
  -3693.2114  -3660.1553  -3388.9995
  -3658.3008  -3616.4097  -3368.7419

(11,.,.) = 
    492.0077    654.1253    744.9028
    766.1949    958.2711   1045.7936
    856.9107   1096.3429   1187.1606

(12,.,.) = 
    449.3220    725.0310    961.3877
    519.0356    841.2623   1067.1793
    277.2522    598.6411    796.9860

(13,.,.) = 
  -2964.3921  -3134.6504  -3032.7139
  -2989.9380  -3147.9834  -3033.9163
  -2924.7583  -3073.2036  -2931.3135

(14,.,.) = 
   5115.8823   5421.7666   5224.5093
   5395.6655   5691.5659   5451.2632
   5342.0469   5661.3862   5389.6221

(15,.,.) = 
   3507.8181   3805.2188   3778.3464
   4086.0476   4481.3774   4430.3901
   4423.1357   4838.9189   4765.2783

(16,.,.) = 
  -2966.1702  -3049.2810  -3038.3267
  -3102.5081  -3219.6680  -3195.8765
  -3238.1777  -3384.2727  -3346.6523

(17,.,.) = 
  -7708.8486  -8114.6045  -8012.1460
  -8847.3350  -9365.2490  -9260.8623
  -9557.5859 -10138.6533 -10011.8125

(18,.,.) = 
   1659.8060   1608.2751   1512.0132
   1851.8468   1771.8138   1665.3756
   1849.5209   1755.8369   1653.0194
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 95
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 19950
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 95
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 95
[torch.LongStorage of size 2]

shift_y size:	
 70
 95
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6650
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 19950
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  19950
[torch.LongStorage of size 1]
	
  first line: 3748.7873535156	
(fast bbox transform) src_w size:  19950
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 19950
     4
[torch.LongStorage of size 2]

scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 19950
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 53200
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13300
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13300
[torch.LongStorage of size 1]

test img #86: time = 0.37089	
(proposal_test:boxes_filter) boxes & scores size:	
 13300
     4
[torch.LongStorage of size 2]

 13300
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 953
   3
[torch.LongTensor of size 2]

mask size:	
 13300
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   4.8000e+02   4.8000e+02
        -inf         -inf   3.6589e+04   2.1573e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #87	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00100001/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 480
 480
[torch.LongStorage of size 3]

x_start = 1 / y_start = 61	
img_means:size() vs img:size():	
   3
 360
 480
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6666666666667	
(orep_img_for_blob) img size after scaling:	
   3
 600
 800
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x97
  2 : CudaTensor - size: 18x72x97
  3 : CudaTensor - size: 18x70x95
  4 : CudaTensor - size: 18x68x93
  5 : CudaTensor - size: 256x74x99
}
proposal_im_deteect: img_blob size:    3
 600
 800
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 360
 480
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6666666666667	
proposal_im_detect: scaled_img_size:	
   5
 600
 800
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1913.6628  -2155.0435  -2079.6130
  -2042.4674  -2276.1799  -2168.8125
  -2002.7598  -2193.6052  -2070.2339

(2,.,.) = 
   2865.6926   3030.5037   2920.6650
   3074.0667   3256.5679   3103.2871
   2968.9551   3119.3547   2951.7371

(3,.,.) = 
   3713.5527   4046.2371   4046.3381
   4554.3140   4973.9556   4966.9634
   4980.6587   5465.1313   5441.8750

(4,.,.) = 
   1066.7266   1189.3607   1167.2144
   1332.8936   1436.0159   1383.9453
   1448.0248   1504.1735   1410.6918

(5,.,.) = 
    756.6280    748.1073    668.2522
    743.3123    696.9154    589.5170
    759.1400    677.4537    568.8035

(6,.,.) = 
   1667.3799   1889.7979   1932.3458
   2045.5160   2357.3379   2400.9734
   2351.3545   2699.9929   2727.3689

(7,.,.) = 
  -2771.2427  -2944.5505  -2768.4778
  -2991.7891  -3144.9180  -2881.4612
  -2869.8162  -2947.9128  -2655.5542

(8,.,.) = 
   5807.5127   6222.5693   5979.4849
   6548.5225   6980.5498   6656.2627
   6815.1064   7193.4985   6820.0928

(9,.,.) = 
   2556.5247   3073.6040   3276.8579
   2947.5110   3479.0200   3609.5078
   3219.4570   3758.1765   3845.1853

(10,.,.) = 
  -3419.7278  -3379.2119  -3131.3770
  -3664.5886  -3631.4089  -3362.1318
  -3630.4893  -3588.2654  -3342.1704

(11,.,.) = 
    487.4165    648.4296    739.0860
    760.0101    950.9919   1038.4541
    850.9550   1088.8632   1179.5321

(12,.,.) = 
    447.0055    720.5994    955.3304
    515.7094    835.3652   1059.6324
    274.7385    593.4305    790.2033

(13,.,.) = 
  -2942.8135  -3111.6338  -3010.2305
  -2968.1440  -3124.4314  -3010.7114
  -2903.3242  -3050.1257  -2908.9377

(14,.,.) = 
   5076.6250   5380.1660   5184.5444
   5354.3525   5647.9795   5409.4561
   5301.4722   5618.2959   5348.6431

(15,.,.) = 
   3475.0466   3769.8987   3744.0833
   4049.1167   4441.3301   4391.7905
   4384.5049   4797.1924   4725.3564

(16,.,.) = 
  -2939.9788  -3022.3911  -3012.1304
  -3074.4792  -3190.9421  -3168.2649
  -3209.6167  -3354.7446  -3318.5151

(17,.,.) = 
  -7638.6196  -8041.2974  -7941.3188
  -8768.4902  -9282.9062  -9181.3721
  -9475.3613 -10052.7832  -9929.6582

(18,.,.) = 
   1646.8376   1595.6359   1499.9521
   1837.3351   1757.9773   1652.1765
   1834.9752   1741.9490   1639.6671
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 95
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 19950
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 95
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 95
[torch.LongStorage of size 2]

shift_y size:	
 70
 95
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6650
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 19950
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  19950
[torch.LongStorage of size 1]
	
  first line: 3713.552734375	
(fast bbox transform) src_w size:  19950
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 19950
     4
[torch.LongStorage of size 2]

scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 19950
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 53200
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13300
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13300
[torch.LongStorage of size 1]

test img #87: time = 0.35015299999999	
(proposal_test:boxes_filter) boxes & scores size:	
 13300
     4
[torch.LongStorage of size 2]

 13300
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 953
   3
[torch.LongTensor of size 2]

mask size:	
 13300
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   4.8000e+02   4.8000e+02
        -inf         -inf   3.6309e+04   2.1404e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #88	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00046006/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1898.7690 -2136.8362 -2061.1399
 -2023.7030 -2254.1851 -2146.4956
 -1983.1630 -2170.9373 -2047.7493

(2,.,.) = 
  2843.5757  3005.4099  2894.1826
  3047.8147  3226.3079  3072.5786
  2942.4468  3089.1204  2921.0813

(3,.,.) = 
  3652.1941  3978.2244  3977.9084
  4481.4316  4892.9336  4885.5723
  4904.3354  5380.5889  5358.0825

(4,.,.) = 
  1043.5065  1162.6232  1140.3524
  1305.8881  1405.9485  1353.9775
  1420.6638  1474.2863  1381.8752

(5,.,.) = 
   742.1879   733.1882   654.6687
   728.5783   681.2772   575.0939
   745.2375   662.9251   554.3762

(6,.,.) = 
  1632.0215  1849.3005  1891.3118
  2005.0505  2311.1077  2354.2209
  2309.0825  2651.6665  2679.0015

(7,.,.) = 
 -2734.8921 -2904.4121 -2727.5542
 -2951.7268 -3101.0154 -2838.2156
 -2831.4368 -2906.6924 -2615.5876

(8,.,.) = 
  5722.8052  6130.2021  5887.7896
  6453.6396  6877.7012  6555.5737
  6720.0703  7091.3403  6721.3682

(9,.,.) = 
  2512.0986  3020.9966  3219.6426
  2894.8914  3418.1648  3545.5681
  3166.7849  3698.1897  3783.6128

(10,.,.) = 
 -3388.1887 -3345.9521 -3097.2312
 -3628.7708 -3593.6299 -3324.8816
 -3592.3279 -3548.2644 -3302.5308

(11,.,.) = 
   475.7502   634.7973   726.0807
   747.3792   936.3794  1023.7009
   838.4240  1073.4172  1163.4227

(12,.,.) = 
   445.5641   715.8477   948.8566
   512.8233   828.4580  1050.7990
   271.0079   585.4952   780.0797

(13,.,.) = 
 -2917.0332 -3083.6013 -2981.0378
 -2939.1863 -3092.5835 -2977.3271
 -2873.1667 -3017.6050 -2876.2539

(14,.,.) = 
  5023.9536  5322.6699  5126.7090
  5296.0522  5585.5474  5346.5991
  5241.0679  5553.6509  5284.6250

(15,.,.) = 
  3413.7766  3701.4758  3675.5139
  3979.9746  4364.3350  4315.0791
  4313.5820  4718.7993  4648.3745

(16,.,.) = 
 -2903.4788 -2982.7705 -2971.1509
 -3030.9619 -3144.5513 -3121.2681
 -3163.3713 -3304.9521 -3268.6675

(17,.,.) = 
 -7521.3174 -7914.8208 -7814.2568
 -8634.4521 -9138.0771 -9035.5674
 -9334.7783 -9901.4756 -9778.7861

(18,.,.) = 
  1631.2777  1579.8503  1483.6234
  1818.4919  1739.3140  1632.6650
  1813.9854  1721.1603  1618.1193
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3652.1940917969	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #88: time = 0.567031	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1715e+04   4.2418e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #89	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00006002/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1911.1149 -2151.3289 -2075.9880
 -2038.1616 -2271.0308 -2163.6265
 -1998.2231 -2188.4060 -2064.9861

(2,.,.) = 
  2861.5562  3025.5186  2915.0471
  3068.2605  3249.4475  3095.8367
  2962.7231  3111.9604  2943.9348

(3,.,.) = 
  3693.3923  4023.1501  4022.4641
  4528.8604  4944.9214  4936.6885
  4953.4429  5433.7700  5409.3008

(4,.,.) = 
  1056.9701  1177.8920  1155.5488
  1322.3015  1423.5566  1371.2415
  1437.4080  1491.9985  1398.9387

(5,.,.) = 
   752.1630   743.8080   664.8102
   738.6982   692.1940   585.4842
   755.5321   673.5380   564.6580

(6,.,.) = 
  1653.3441  1873.6526  1915.7301
  2029.2372  2338.8164  2381.9211
  2334.8130  2680.9287  2707.9124

(7,.,.) = 
 -2757.7468 -2930.4148 -2754.7739
 -2976.9021 -3129.2761 -2866.7095
 -2856.1458 -2933.8840 -2642.7273

(8,.,.) = 
  5776.2446  6188.4565  5946.0840
  6512.7051  6941.7095  6617.9873
  6779.9448  7155.0972  6782.4619

(9,.,.) = 
  2539.9087  3053.4741  3254.6807
  2926.3167  3454.2058  3583.2905
  3198.3555  3733.9021  3820.0591

(10,.,.) = 
 -3414.1641 -3373.0442 -3124.3945
 -3657.1868 -3622.9810 -3353.6221
 -3620.9827 -3577.7241 -3331.0745

(11,.,.) = 
   480.7803   640.6091   731.7627
   753.8350   943.6463  1030.9569
   844.2134  1080.4482  1170.5286

(12,.,.) = 
   446.7579   718.9616   953.6447
   515.3392   833.5389  1057.6677
   273.5263   590.9294   787.4385

(13,.,.) = 
 -2935.5479 -3104.0425 -3001.8853
 -2957.9834 -3113.6853 -2998.9080
 -2892.7568 -3039.1343 -2897.4939

(14,.,.) = 
  5060.2622  5362.0386  5166.1323
  5334.9155  5627.0034  5387.8501
  5280.9814  5596.0337  5325.8984

(15,.,.) = 
  3451.8125  3743.6926  3717.8452
  4022.4639  4411.2847  4361.5547
  4357.8486  4767.0474  4695.1963

(16,.,.) = 
 -2931.6182 -3012.3408 -3000.6790
 -3062.2856 -3177.0200 -3152.8853
 -3195.6875 -3338.3530 -3300.5103

(17,.,.) = 
 -7598.5430 -7997.3706 -7895.9214
 -8721.7744 -9230.5791 -9126.5645
 -9425.9961 -9996.8896 -9870.8301

(18,.,.) = 
  1644.0505  1592.7759  1496.9041
  1833.1163  1753.6183  1647.2627
  1828.9974  1735.6560  1632.7932
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3693.3923339844	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #89: time = 0.55601200000001	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2326e+04   4.2822e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #90	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00016000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 360
 640
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 640
 640
[torch.LongStorage of size 3]

x_start = 1 / y_start = 141	
img_means:size() vs img:size():	
   3
 360
 640
[torch.LongStorage of size 3]

   3
 360
 640
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6666666666667	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 360
 640
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6666666666667	
proposal_im_detect: scaled_img_size:	
    5
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1915.9058 -2156.1157 -2080.0920
 -2042.6160 -2275.4233 -2167.2947
 -2001.6436 -2191.5205 -2067.5422

(2,.,.) = 
  2868.0928  3031.7312  2920.0679
  3074.7952  3255.5237  3101.0974
  2968.4419  3117.2146  2948.3518

(3,.,.) = 
  3690.2615  4019.4624  4018.5540
  4526.6118  4941.7944  4933.2856
  4952.6816  5432.5337  5408.0781

(4,.,.) = 
  1054.6110  1174.9484  1152.4019
  1319.8477  1420.6862  1368.0685
  1435.1868  1489.1371  1395.8319

(5,.,.) = 
   750.9316   742.4244   663.4988
   737.4769   690.6252   583.9382
   754.5365   672.1995   562.9885

(6,.,.) = 
  1649.7817  1869.4594  1911.5824
  2026.1453  2335.3862  2378.5808
  2332.6904  2678.5747  2705.7322

(7,.,.) = 
 -2759.6853 -2931.6370 -2754.3743
 -2978.8157 -3130.4729 -2866.6331
 -2857.4475 -2934.3914 -2641.8687

(8,.,.) = 
  5777.2349  6188.7798  5944.8721
  6514.5156  6942.8169  6617.9375
  6782.2192  7156.5962  6782.8521

(9,.,.) = 
  2537.5649  3051.1567  3251.9731
  2923.6355  3451.5349  3580.3223
  3196.5544  3732.1819  3818.1187

(10,.,.) = 
 -3418.8401 -3376.8149 -3126.5759
 -3662.0618 -3627.0269 -3356.3899
 -3625.1748 -3581.0728 -3333.2383

(11,.,.) = 
   479.8122   639.7473   731.3337
   753.7156   943.6951  1031.2028
   844.8356  1081.2908  1171.5372

(12,.,.) = 
   448.4480   720.8248   955.6827
   517.0473   835.3364  1059.4755
   273.9431   591.3072   787.7448

(13,.,.) = 
 -2941.5503 -3110.0457 -3007.1172
 -2963.7375 -3119.1318 -3003.5215
 -2897.3232 -3043.4868 -2901.1941

(14,.,.) = 
  5067.7432  5369.4312  5172.3252
  5342.4854  5634.5796  5394.0576
  5286.9814  5602.0308  5330.5566

(15,.,.) = 
  3448.7195  3739.4290  3713.0225
  4019.8550  4407.8398  4357.6357
  4355.9175  4764.3599  4692.2725

(16,.,.) = 
 -2932.2437 -3012.5842 -3000.6958
 -3061.9458 -3176.5938 -3152.6155
 -3195.4241 -3338.0000 -3300.2229

(17,.,.) = 
 -7596.3315 -7993.9229 -7891.7842
 -8720.0977 -9227.7471 -9122.9199
 -9425.7227 -9995.8096 -9869.3955

(18,.,.) = 
  1645.8545  1594.2548  1497.6238
  1835.0184  1755.2679  1648.0992
  1830.7469  1737.1024  1633.4324
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3690.2614746094	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #90: time = 0.48031499999999	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   6.4000e+02   6.4000e+02
        -inf         -inf   3.6120e+04   2.1352e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #91	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00138000/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  816
 1920
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1920
 1920
[torch.LongStorage of size 3]

x_start = 1 / y_start = 553	
img_means:size() vs img:size():	
    3
  816
 1920
[torch.LongStorage of size 3]

    3
  816
 1920
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.73529411764706	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1411
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x174
  2 : CudaTensor - size: 18x72x174
  3 : CudaTensor - size: 18x70x172
  4 : CudaTensor - size: 18x68x170
  5 : CudaTensor - size: 256x74x176
}
proposal_im_deteect: img_blob size:     3
  600
 1411
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  816
 1920
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.73529411764706	
proposal_im_detect: scaled_img_size:	
    2
  600
 1412
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1902.4990 -2140.8140 -2065.7104
 -2026.4890 -2257.4285 -2150.2827
 -1985.1617 -2173.1724 -2050.3811

(2,.,.) = 
  2848.5715  3010.9783  2900.1252
  3052.0054  3230.7913  3077.5166
  2945.3069  3092.0364  2924.2480

(3,.,.) = 
  3651.2900  3978.0764  3979.0830
  4478.2388  4890.1460  4883.9976
  4899.0693  5375.0732  5353.6313

(4,.,.) = 
  1040.6658  1159.7275  1137.9590
  1303.2236  1403.1726  1351.5642
  1417.9192  1471.3364  1379.6873

(5,.,.) = 
   741.0530   732.9120   655.3925
   727.1031   680.4391   575.0930
   744.1268   662.0278   553.4313

(6,.,.) = 
  1628.7593  1845.8312  1888.4158
  2000.6858  2306.6116  2350.4204
  2304.1960  2646.3413  2674.3254

(7,.,.) = 
 -2733.7668 -2904.2065 -2728.2405
 -2949.5569 -3099.3403 -2837.4329
 -2828.4207 -2904.0227 -2613.5000

(8,.,.) = 
  5719.5122  6128.3330  5888.5581
  6448.1343  6873.3813  6553.3848
  6713.2363  7084.6670  6716.3174

(9,.,.) = 
  2510.4036  3019.5183  3218.7769
  2890.3750  3413.6609  3541.7605
  3161.3579  3692.5862  3778.5547

(10,.,.) = 
 -3394.1809 -3352.5190 -3103.9580
 -3634.1313 -3599.0305 -3330.5303
 -3595.5396 -3551.0762 -3305.0820

(11,.,.) = 
   472.6771   631.2063   723.1608
   745.4594   934.2103  1021.8423
   836.1689  1070.7531  1160.8691

(12,.,.) = 
   446.6119   716.2703   949.4664
   514.1876   829.2393  1051.8340
   271.1888   585.1274   780.1039

(13,.,.) = 
 -2919.7192 -3087.1062 -2984.6409
 -2939.5977 -3093.3845 -2978.0212
 -2872.8491 -3017.5547 -2876.1628

(14,.,.) = 
  5026.7935  5326.5176  5131.6118
  5297.1704  5587.2935  5348.9390
  5240.4287  5553.0972  5284.3267

(15,.,.) = 
  3409.8757  3697.8965  3673.5256
  3974.2874  4358.7129  4311.0264
  4307.0645  4711.8384  4642.7124

(16,.,.) = 
 -2906.6565 -2986.5256 -2975.4890
 -3031.7314 -3145.7634 -3122.8979
 -3162.4927 -3303.7334 -3267.3667

(17,.,.) = 
 -7518.6763 -7914.0884 -7815.9985
 -8629.0693 -9133.3193 -9032.7764
 -9326.9023 -9892.9033 -9771.5039

(18,.,.) = 
  1633.9081  1583.0845  1487.2740
  1820.5806  1741.9286  1635.2631
  1814.5508  1721.7909  1618.5728
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 172
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 36120
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 172
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 172
[torch.LongStorage of size 2]

shift_y size:	
  70
 172
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
     3
 12040
     4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 36120
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 36120
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 36120
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  36120
[torch.LongStorage of size 1]
	
  first line: 3651.2900390625	
(fast bbox transform) src_w size:  36120
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 36120
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 36120
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 36120
     4
[torch.LongStorage of size 2]

scores size:	
 36120
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 36120
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 36120
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 36120
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 96320
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 24080
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 24080
[torch.LongStorage of size 1]

test img #91: time = 0.893238	
(proposal_test:boxes_filter) boxes & scores size:	
 24080
     4
[torch.LongStorage of size 2]

 24080
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 3
[torch.LongStorage of size 1]

 1379
    3
    4
[torch.LongTensor of size 3]

mask size:	
 24080
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 12
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.9200e+03   1.9200e+03
  1.0000e+00   1.0000e+00   8.1600e+02   8.1600e+02
        -inf         -inf   8.1159e+04   4.7620e+04
[torch.CudaTensor of size 3x4]

(proposal_test:boxes_filter) boxes size returned:	
 3
 4
[torch.LongStorage of size 2]

img #92	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00003000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 480
 640
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 640
 640
[torch.LongStorage of size 3]

x_start = 1 / y_start = 81	
img_means:size() vs img:size():	
   3
 480
 640
[torch.LongStorage of size 3]

   3
 480
 640
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.25	
(orep_img_for_blob) img size after scaling:	
   3
 600
 800
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x97
  2 : CudaTensor - size: 18x72x97
  3 : CudaTensor - size: 18x70x95
  4 : CudaTensor - size: 18x68x93
  5 : CudaTensor - size: 256x74x99
}
proposal_im_deteect: img_blob size:    3
 600
 800
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 480
 640
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.25	
proposal_im_detect: scaled_img_size:	
   4
 600
 800
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1927.7191  -2171.0085  -2095.1396
  -2058.1077  -2293.7454  -2185.8201
  -2018.5171  -2211.0977  -2086.8831

(2,.,.) = 
   2886.4326   3052.6738   2942.3635
   3096.9624   3281.2830   3127.0723
   2991.1831   3143.4429   2974.8584

(3,.,.) = 
   3748.8521   4084.1616   4083.2532
   4595.5649   5018.3418   5010.0063
   5023.1836   5510.7788   5485.6187

(4,.,.) = 
   1077.9434   1201.6536   1179.0333
   1346.3422   1450.0253   1397.0170
   1461.7178   1517.9025   1423.1074

(5,.,.) = 
    764.6202    756.2473    675.6384
    751.1493    704.8012    596.5600
    766.9368    684.9443    575.5625

(6,.,.) = 
   1684.2963   1908.8396   1951.1102
   2064.9229   2379.4963   2422.8584
   2372.0842   2723.7104   2750.6147

(7,.,.) = 
  -2793.4407  -2968.4556  -2791.4548
  -3015.6558  -3170.5950  -2905.5361
  -2892.3213  -2971.8640  -2677.9050

(8,.,.) = 
   5857.5093   6275.6699   6030.1768
   6603.2617   7038.4976   6710.6646
   6869.2744   7250.2852   6872.7617

(9,.,.) = 
   2580.2173   3101.1963   3305.5776
   2974.0647   3509.3899   3640.4338
   3246.3811   3788.6116   3875.7913

(10,.,.) = 
  -3446.6582  -3406.0908  -3156.6121
  -3693.1621  -3660.0400  -3388.8142
  -3657.6870  -3615.6150  -3367.7966

(11,.,.) = 
    492.0047    654.1095    744.8843
    766.0659    958.1006   1045.5831
    856.4803   1095.8286   1186.5505

(12,.,.) = 
    449.3145    725.0168    961.3851
    519.0436    841.2595   1067.2096
    277.4262    598.7910    797.2087

(13,.,.) = 
  -2964.4551  -3134.7009  -3032.7349
  -2989.9529  -3147.9792  -3033.8635
  -2924.5647  -3073.0134  -2931.1340

(14,.,.) = 
   5115.9756   5421.8389   5224.5298
   5395.5674   5691.3872   5451.0010
   5341.3003   5660.5176   5388.6299

(15,.,.) = 
   3507.8708   3805.2251   3778.3086
   4085.7607   4480.9434   4429.8198
   4421.9551   4837.3979   4763.4834

(16,.,.) = 
  -2966.2134  -3049.3003  -3038.3103
  -3102.3999  -3219.4731  -3195.5872
  -3237.6248  -3383.5229  -3345.7278

(17,.,.) = 
  -7708.9736  -8114.6592  -8012.1084
  -8846.8975  -9364.5713  -9259.9541
  -9555.5957 -10136.0723 -10008.7285

(18,.,.) = 
   1659.8458   1608.3047   1512.0326
   1851.8413   1771.7864   1665.3243
   1849.3202   1755.5754   1652.6921
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 95
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 19950
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 95
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 95
[torch.LongStorage of size 2]

shift_y size:	
 70
 95
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6650
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 19950
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  19950
[torch.LongStorage of size 1]
	
  first line: 3748.8520507812	
(fast bbox transform) src_w size:  19950
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 19950
     4
[torch.LongStorage of size 2]

scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 19950
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 53200
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13300
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13300
[torch.LongStorage of size 1]

test img #92: time = 0.386836	
(proposal_test:boxes_filter) boxes & scores size:	
 13300
     4
[torch.LongStorage of size 2]

 13300
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 953
   3
[torch.LongTensor of size 2]

mask size:	
 13300
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   6.4000e+02   6.4000e+02
        -inf         -inf   4.8708e+04   2.8731e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #93	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00108000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 240
 320
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 320
 320
[torch.LongStorage of size 3]

x_start = 1 / y_start = 41	
img_means:size() vs img:size():	
   3
 240
 320
[torch.LongStorage of size 3]

   3
 240
 320
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 2.5	
(orep_img_for_blob) img size after scaling:	
   3
 600
 800
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x97
  2 : CudaTensor - size: 18x72x97
  3 : CudaTensor - size: 18x70x95
  4 : CudaTensor - size: 18x68x93
  5 : CudaTensor - size: 256x74x99
}
proposal_im_deteect: img_blob size:    3
 600
 800
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 240
 320
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 2.5	
proposal_im_detect: scaled_img_size:	
   8
 600
 800
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1918.9028  -2160.2148  -2083.2734
  -2047.7825  -2281.5420  -2172.7012
  -2007.1309  -2197.9419  -2073.2451

(2,.,.) = 
   2872.8994   3037.0945   2925.4746
   3081.4280   3263.4961   3108.4309
   2974.9966   3125.1550   2955.9502

(3,.,.) = 
   3722.8213   4054.3738   4052.4263
   4563.9233   4982.2217   4972.8589
   4988.4766   5471.8467   5446.2285

(4,.,.) = 
   1069.8695   1192.1400   1169.6077
   1335.9777   1438.5679   1386.0970
   1450.2694   1505.5624   1411.7849

(5,.,.) = 
    760.3882    751.2072    670.7664
    746.4655    699.6260    591.8599
    761.7421    679.6316    570.7813

(6,.,.) = 
   1671.6367   1894.3456   1936.1090
   2050.1421   2362.1768   2404.8896
   2355.5679   2704.3315   2730.8735

(7,.,.) = 
  -2779.3748  -2952.6201  -2775.4707
  -2999.8218  -3153.0051  -2888.4316
  -2875.7180  -2954.1387  -2661.0669

(8,.,.) = 
   5821.7349   6235.7188   5989.6401
   6561.6929   6992.6333   6665.2822
   6824.9292   7202.3315   6826.4463

(9,.,.) = 
   2562.6260   3080.0923   3283.3013
   2953.5808   3485.1853   3615.2012
   3223.9092   3762.4973   3848.8120

(10,.,.) = 
  -3425.6738  -3384.3843  -3134.9592
  -3670.1235  -3636.4324  -3365.4370
  -3634.7209  -3592.3533  -3345.1619

(11,.,.) = 
    486.9614    648.0581    738.7633
    759.8864    950.6653   1038.1447
    850.4916   1088.3180   1178.9423

(12,.,.) = 
    447.8756    721.7936    956.9372
    517.2560    837.4277   1061.9773
    275.4027    594.7003    791.7116

(13,.,.) = 
  -2949.9492  -3118.4626  -3015.9363
  -2975.1797  -3131.3115  -3016.3865
  -2908.9395  -3055.6216  -2913.2644

(14,.,.) = 
   5087.4185   5390.2124   5192.1558
   5364.4365   5657.3911   5416.5669
   5309.0381   5625.5176   5353.7285

(15,.,.) = 
   3483.4160   3777.5820   3749.9924
   4057.1763   4448.7695   4397.1875
   4390.9282   4802.9268   4729.2612

(16,.,.) = 
  -2945.8457  -3026.8857  -3015.4431
  -3079.9980  -3195.2517  -3171.3491
  -3214.5754  -3358.6101  -3320.9941

(17,.,.) = 
  -7656.6914  -8056.8667  -7952.3848
  -8785.9717  -9297.9277  -9191.7207
  -9489.4365 -10064.6328  -9937.0879

(18,.,.) = 
   1650.2972   1598.2402   1501.9602
   1840.7732   1760.4756   1654.2133
   1837.8467   1744.1865   1641.5708
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 95
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 19950
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 95
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 95
[torch.LongStorage of size 2]

shift_y size:	
 70
 95
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6650
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 19950
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  19950
[torch.LongStorage of size 1]
	
  first line: 3722.8212890625	
(fast bbox transform) src_w size:  19950
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 19950
     4
[torch.LongStorage of size 2]

scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 19950
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 53200
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13300
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13300
[torch.LongStorage of size 1]

test img #93: time = 0.36081899999999	
(proposal_test:boxes_filter) boxes & scores size:	
 13300
     4
[torch.LongStorage of size 2]

 13300
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 953
   3
[torch.LongTensor of size 2]

mask size:	
 13300
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   3.2000e+02   3.2000e+02
        -inf         -inf   2.4182e+04   1.4252e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #94	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00013002/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1920
 1920
[torch.LongStorage of size 3]

x_start = 1 / y_start = 421	
img_means:size() vs img:size():	
    3
 1080
 1920
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.55555555555556	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
 1080
 1920
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.55555555555556	
proposal_im_detect: scaled_img_size:	
    2
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1916.0416 -2156.4539 -2080.3723
 -2042.7911 -2275.6309 -2167.3623
 -2001.9076 -2191.6782 -2067.4780

(2,.,.) = 
  2868.6885  3032.3777  2920.7644
  3075.2542  3256.0046  3101.3647
  2968.6416  3117.2864  2948.1277

(3,.,.) = 
  3694.2815  4024.2148  4023.6453
  4529.9673  4945.8188  4937.8169
  4953.9521  5434.1958  5410.3154

(4,.,.) = 
  1056.2354  1176.9559  1154.6224
  1321.2263  1422.4058  1369.9860
  1436.2421  1490.3876  1397.1653

(5,.,.) = 
   751.3685   742.9113   663.8401
   737.5373   690.6601   583.8217
   754.0338   671.5901   562.3517

(6,.,.) = 
  1652.1222  1872.0963  1914.3044
  2027.7825  2337.2202  2380.5264
  2332.8672  2678.9292  2706.1501

(7,.,.) = 
 -2761.5337 -2933.5042 -2756.1414
 -2980.0186 -3131.5020 -2867.2070
 -2857.4399 -2934.0449 -2640.9934

(8,.,.) = 
  5782.2520  6194.4434  5950.6309
  6518.2910  6947.0605  6622.0913
  6783.4556  7158.0928  6784.2700

(9,.,.) = 
  2540.8691  3054.8896  3256.0518
  2926.6570  3454.8455  3583.7708
  3198.2773  3733.9573  3819.9214

(10,.,.) = 
 -3420.5237 -3378.5178 -3128.3503
 -3663.2639 -3628.1887 -3357.3416
 -3625.4265 -3581.2520 -3333.3494

(11,.,.) = 
   480.5293   640.5920   732.2441
   754.1202   944.3066  1032.0647
   844.8389  1081.4783  1171.9861

(12,.,.) = 
   447.9996   720.2808   955.2264
   516.5463   834.7675  1058.9969
   273.5739   590.7290   787.1921

(13,.,.) = 
 -2942.7561 -3111.0664 -3007.9666
 -2965.0591 -3120.2285 -3004.3796
 -2898.3296 -3044.2844 -2901.8101

(14,.,.) = 
  5070.4043  5372.1611  5174.9219
  5344.6416  5636.7104  5396.0474
  5288.0610  5603.1377  5331.6182

(15,.,.) = 
  3452.6492  3744.0398  3717.8518
  4022.8296  4411.3052  4361.2969
  4356.9370  4765.7236  4693.7754

(16,.,.) = 
 -2934.2173 -3014.8804 -3003.2522
 -3063.6116 -3178.4390 -3154.6458
 -3196.1277 -3338.9119 -3301.4380

(17,.,.) = 
 -7603.4141 -8002.0327 -7900.4609
 -8725.6035 -9234.2998 -9130.2256
 -9428.2109 -9999.1084 -9873.4980

(18,.,.) = 
  1646.6562  1595.0897  1498.4985
  1835.6167  1755.8560  1648.7289
  1830.7482  1737.0713  1633.4827
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3694.2814941406	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #94: time = 0.77269000000001	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.9200e+03   1.9200e+03
        -inf         -inf   1.0833e+05   6.4070e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #95	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00010004/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1920
 1920
[torch.LongStorage of size 3]

x_start = 1 / y_start = 421	
img_means:size() vs img:size():	
    3
 1080
 1920
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.55555555555556	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
 1080
 1920
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.55555555555556	
proposal_im_detect: scaled_img_size:	
    2
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1906.5696 -2145.5715 -2069.9338
 -2031.9012 -2263.3091 -2155.5332
 -1990.7417 -2179.1726 -2055.6465

(2,.,.) = 
  2854.4104  3017.1646  2905.9663
  3059.2424  3238.6421  3084.7893
  2952.8242  3100.1165  2931.6946

(3,.,.) = 
  3666.0049  3993.6609  3993.8000
  4496.4302  4909.3960  4902.2578
  4918.6880  5395.9092  5373.2432

(4,.,.) = 
  1046.7291  1166.3376  1144.2665
  1309.9125  1410.3121  1358.3489
  1424.5912  1478.2258  1385.8215

(5,.,.) = 
   744.6912   736.1545   657.7827
   730.8616   683.8586   577.7709
   747.5015   665.0975   556.2499

(6,.,.) = 
  1637.3199  1855.3602  1897.6417
  2010.6702  2317.7715  2361.1968
  2314.6509  2658.2268  2685.7778

(7,.,.) = 
 -2743.2275 -2913.8411 -2737.0754
 -2960.2046 -3110.3118 -2847.2615
 -2838.6370 -2914.2173 -2622.4451

(8,.,.) = 
  5741.8345  6151.4131  5909.4458
  6473.4204  6899.4268  6577.0332
  6738.3008  7110.4932  6739.5654

(9,.,.) = 
  2520.8315  3031.5090  3231.4246
  2903.4900  3428.3010  3556.5330
  3174.6177  3707.1411  3792.8508

(10,.,.) = 
 -3401.2996 -3359.3684 -3110.3098
 -3642.3130 -3607.2075 -3337.8013
 -3604.4927 -3560.1646 -3313.5330

(11,.,.) = 
   476.1771   635.3115   726.9869
   748.7223   937.9998  1025.6711
   839.5216  1074.8743  1165.1847

(12,.,.) = 
   446.5591   717.3005   951.2121
   514.3683   830.6607  1053.8381
   271.5811   586.6835   782.0445

(13,.,.) = 
 -2927.0374 -3094.5325 -2991.8411
 -2948.5522 -3102.5796 -2987.0093
 -2881.7319 -3026.6350 -2884.8135

(14,.,.) = 
  5041.1094  5341.3154  5145.3940
  5313.2051  5603.7925  5364.4277
  5256.4561  5569.7886  5299.8511

(15,.,.) = 
  3425.3833  3714.4146  3688.9202
  3992.0161  4377.6533  4328.6030
  4324.9219  4730.9653  4660.3794

(16,.,.) = 
 -2914.9885 -2995.1152 -2983.9026
 -3042.0581 -3156.3223 -3133.1919
 -3173.5752 -3315.4189 -3278.7583

(17,.,.) = 
 -7547.9766 -7944.0410 -7844.2485
 -8662.6816 -9168.1230 -9065.7754
 -9362.1289 -9929.6797 -9806.3691

(18,.,.) = 
  1637.2815  1586.0540  1489.8904
  1824.8392  1745.6909  1638.9377
  1819.5376  1726.4371  1623.1433
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3666.0048828125	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #95: time = 0.94479699999999	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.9200e+03   1.9200e+03
        -inf         -inf   1.0772e+05   6.3674e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #96	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00013004/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1920
 1920
[torch.LongStorage of size 3]

x_start = 1 / y_start = 421	
img_means:size() vs img:size():	
    3
 1080
 1920
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.55555555555556	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
 1080
 1920
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.55555555555556	
proposal_im_detect: scaled_img_size:	
    2
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1915.9877 -2156.3997 -2080.3220
 -2042.6307 -2275.4758 -2167.2234
 -2001.5636 -2191.3284 -2067.1252

(2,.,.) = 
  2868.6299  3032.3176  2920.7161
  3075.0305  3255.7957  3101.1641
  2968.1631  3116.7942  2947.6716

(3,.,.) = 
  3694.1399  4024.0735  4023.5176
  4529.4727  4945.2832  4937.3042
  4952.7549  5432.8755  5409.0322

(4,.,.) = 
  1056.1841  1176.9022  1154.5808
  1321.0282  1422.1926  1369.7917
  1435.8490  1489.9148  1396.7168

(5,.,.) = 
   751.2921   742.8397   663.7710
   737.3848   690.5164   583.6777
   753.7589   671.3284   562.1255

(6,.,.) = 
  1651.9954  1871.9464  1914.1606
  2027.3644  2336.7361  2380.0381
  2331.9216  2677.9119  2705.1411

(7,.,.) = 
 -2761.3550 -2933.3066 -2755.9385
 -2979.3843 -3130.8103 -2866.4775
 -2856.1211 -2932.6001 -2639.4729

(8,.,.) = 
  5781.9775  6194.1753  5950.3813
  6517.3252  6946.0840  6621.1069
  6781.2559  7155.7622  6781.9297

(9,.,.) = 
  2540.7151  3054.7161  3255.8860
  2926.1826  3454.2554  3583.1509
  3197.2141  3732.6414  3818.4939

(10,.,.) = 
 -3420.4675 -3378.4678 -3128.3022
 -3662.9534 -3627.8552 -3356.9990
 -3624.4497 -3580.2119 -3332.2627

(11,.,.) = 
   480.4794   640.5505   732.2147
   753.9175   944.1058  1031.8800
   844.4179  1081.0259  1171.5245

(12,.,.) = 
   447.9656   720.2419   955.1944
   516.4401   834.6442  1058.8765
   273.5045   590.5747   787.0289

(13,.,.) = 
 -2942.6860 -3110.9995 -3007.8918
 -2964.8057 -3119.9290 -3004.0730
 -2897.6799 -3043.5881 -2901.0815

(14,.,.) = 
  5070.2808  5372.0396  5174.7993
  5344.0835  5636.1294  5395.4692
  5286.6987  5601.7168  5330.1880

(15,.,.) = 
  3452.4712  3743.8560  3717.6855
  4022.1917  4410.6079  4360.6245
  4355.4985  4764.1265  4692.2031

(16,.,.) = 
 -2934.1477 -3014.8081 -3003.1895
 -3063.3940 -3178.2007 -3154.4041
 -3195.5537 -3338.3040 -3300.8052

(17,.,.) = 
 -7603.1802 -8001.8301 -7900.2915
 -8724.7080 -9233.4189 -9129.4199
 -9426.0850 -9996.8740 -9871.3691

(18,.,.) = 
  1646.6288  1595.0673  1498.4812
  1835.4823  1755.7329  1648.6089
  1830.4015  1736.7273  1633.1421
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3694.1398925781	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #96: time = 0.78752200000001	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.9200e+03   1.9200e+03
        -inf         -inf   1.0818e+05   6.3985e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #97	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00127000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1907.7240 -2147.2119 -2071.6580
 -2033.6277 -2265.5710 -2157.9895
 -1992.5731 -2181.5066 -2058.0640

(2,.,.) = 
  2856.3540  3019.6934  2908.7402
  3061.7646  3242.0464  3088.3281
  2955.3386  3103.4980  2935.3423

(3,.,.) = 
  3675.2737  4003.8682  4003.7183
  4507.5215  4921.8198  4914.3687
  4930.2266  5409.0498  5385.8833

(4,.,.) = 
  1050.8347  1171.0334  1148.8284
  1314.4492  1415.3596  1363.1906
  1428.9945  1483.1552  1390.3069

(5,.,.) = 
   747.1185   738.7366   660.3444
   733.2084   686.5167   580.4678
   749.4850   667.4380   558.9988

(6,.,.) = 
  1643.7041  1862.7362  1904.9822
  2018.1171  2326.2739  2369.6682
  2322.5757  2667.2559  2694.6604

(7,.,.) = 
 -2748.9028 -2920.5337 -2744.2251
 -2966.6484 -3117.8010 -2855.0513
 -2844.9355 -2921.3457 -2629.8171

(8,.,.) = 
  5754.3203  6165.3677  5923.2817
  6487.3462  6914.8574  6592.2114
  6751.9731  7125.6309  6754.2383

(9,.,.) = 
  2528.1057  3040.3340  3240.9578
  2912.3843  3438.7917  3567.5156
  3183.4531  3717.3835  3803.3521

(10,.,.) = 
 -3403.6697 -3362.4075 -3113.7290
 -3645.0405 -3610.7434 -3341.6208
 -3607.6648 -3564.1130 -3317.9570

(11,.,.) = 
   478.5154   637.9009   729.1338
   751.0555   940.4715  1027.8209
   841.9368  1077.6620  1167.7979

(12,.,.) = 
   447.3872   718.7921   952.5295
   515.7435   832.8270  1055.8557
   273.5050   589.5220   784.8145

(13,.,.) = 
 -2929.9873 -3098.1208 -2995.9041
 -2952.2458 -3107.1111 -2992.3672
 -2885.6406 -3031.1426 -2889.9675

(14,.,.) = 
  5047.6768  5348.9487  5153.2451
  5320.5195  5611.9971  5373.1777
  5264.0571  5578.2300  5308.7310

(15,.,.) = 
  3435.0938  3725.4141  3699.7073
  4002.9131  4389.9951  4340.7031
  4336.0229  4743.4302  4672.3760

(16,.,.) = 
 -2919.2332 -2999.8425 -2988.6409
 -3047.5005 -3162.2708 -3139.1755
 -3179.3992 -3322.0610 -3285.5356

(17,.,.) = 
 -7565.8311 -7963.3398 -7863.0562
 -8682.5469 -9190.1055 -9087.6230
 -9382.2979 -9952.1777 -9828.6992

(18,.,.) = 
  1638.8315  1587.7947  1491.7428
  1826.8817  1747.8855  1641.3970
  1822.0411  1729.2266  1626.2574
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3675.2736816406	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #97: time = 0.557275	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1932e+04   4.2533e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #98	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00012001/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 480
 480
[torch.LongStorage of size 3]

x_start = 1 / y_start = 61	
img_means:size() vs img:size():	
   3
 360
 480
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6666666666667	
(orep_img_for_blob) img size after scaling:	
   3
 600
 800
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x97
  2 : CudaTensor - size: 18x72x97
  3 : CudaTensor - size: 18x70x95
  4 : CudaTensor - size: 18x68x93
  5 : CudaTensor - size: 256x74x99
}
proposal_im_deteect: img_blob size:    3
 600
 800
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 360
 480
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6666666666667	
proposal_im_detect: scaled_img_size:	
   5
 600
 800
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1927.7015  -2170.9736  -2095.1169
  -2058.1831  -2293.8159  -2185.9600
  -2018.6875  -2211.3071  -2087.2139

(2,.,.) = 
   2886.2590   3052.5730   2942.3467
   3096.7595   3281.2695   3127.1943
   2990.8982   3143.4653   2975.0701

(3,.,.) = 
   3748.1709   4083.3113   4082.3931
   4594.5864   5017.0586   5008.6592
   5022.4414   5509.7300   5484.4873

(4,.,.) = 
   1077.8175   1201.4196   1178.7620
   1346.3502   1449.8721   1396.7960
   1461.9104   1517.9601   1423.1348

(5,.,.) = 
    764.6796    756.2647    675.6875
    751.3709    705.0126    596.8526
    767.3438    685.4382    576.2708

(6,.,.) = 
   1683.7942   1908.3859   1950.6783
   2064.2107   2378.9905   2422.5725
   2371.5884   2723.4927   2750.7568

(7,.,.) = 
  -2792.7302  -2967.7759  -2790.8359
  -3014.7874  -3169.9470  -2905.1223
  -2891.4910  -2971.4949  -2678.0095

(8,.,.) = 
   5856.2827   6274.3325   6028.8535
   6601.5718   7036.7163   6708.9917
   6867.6797   7248.7993   6871.6543

(9,.,.) = 
   2579.4744   3100.3557   3304.6902
   2972.9341   3508.1531   3639.2852
   3245.0767   3787.3245   3874.7253

(10,.,.) = 
  -3445.9670  -3405.4377  -3156.0005
  -3691.9553  -3659.0791  -3388.0291
  -3656.1465  -3614.5930  -3367.2712

(11,.,.) = 
    491.7592    653.8653    744.6051
    765.7404    957.7607   1045.1743
    856.3088   1095.6167   1186.2351

(12,.,.) = 
    449.4430    725.1973    961.5793
    519.4401    841.7388   1067.6578
    278.0471    599.5867    797.8796

(13,.,.) = 
  -2964.2075  -3134.5723  -3032.6570
  -2989.3838  -3147.6929  -3033.8374
  -2923.4226  -3072.2358  -2930.7566

(14,.,.) = 
   5115.3628   5421.2881   5223.9893
   5394.4014   5690.4795   5450.2754
   5339.5679   5659.1655   5387.6602

(15,.,.) = 
   3507.0818   3804.3174   3777.3660
   4084.6899   4479.8037   4428.6807
   4421.0166   4836.4736   4762.6948

(16,.,.) = 
  -2966.0117  -3049.0803  -3038.0439
  -3102.0081  -3219.1201  -3195.2288
  -3237.0256  -3383.1025  -3345.4001

(17,.,.) = 
  -7708.0781  -8113.5435  -8010.9014
  -8845.6934  -9363.0928  -9258.3916
  -9554.5127 -10134.8701 -10007.6143

(18,.,.) = 
   1659.6023   1608.0348   1511.8066
   1851.3690   1771.3264   1664.9659
   1848.7524   1755.1442   1652.4807
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 95
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 19950
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 95
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 95
[torch.LongStorage of size 2]

shift_y size:	
 70
 95
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6650
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 19950
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  19950
[torch.LongStorage of size 1]
	
  first line: 3748.1708984375	
(fast bbox transform) src_w size:  19950
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 19950
     4
[torch.LongStorage of size 2]

scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 19950
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 53200
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13300
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13300
[torch.LongStorage of size 1]

test img #98: time = 0.40229500000001	
(proposal_test:boxes_filter) boxes & scores size:	
 13300
     4
[torch.LongStorage of size 2]

 13300
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 953
   3
[torch.LongTensor of size 2]

mask size:	
 13300
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   4.8000e+02   4.8000e+02
        -inf         -inf   3.6545e+04   2.1536e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #99	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00096004/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1913.8044  -2154.2029  -2078.5771
  -2041.1926  -2274.2087  -2166.5164
  -2001.3295  -2191.5774  -2067.8757

(2,.,.) = 
   2865.4456   3029.3335   2918.4502
   3072.6338   3253.7581   3099.7810
   2967.0583   3116.3120   2947.9341

(3,.,.) = 
   3697.1460   4027.3179   4026.6265
   4533.6963   4950.1470   4941.9873
   4959.0518   5439.9033   5415.6074

(4,.,.) = 
   1057.5945   1178.5924   1156.2703
   1323.3669   1424.7358   1372.3628
   1438.9243   1493.5381   1400.3608

(5,.,.) = 
    752.8079    744.5397    665.4534
    739.4882    693.0388    586.1639
    756.4867    674.4998    565.3717

(6,.,.) = 
   1654.9774   1875.4031   1917.5314
   2031.2231   2341.0713   2384.3079
   2336.9160   2683.3696   2710.4956

(7,.,.) = 
  -2761.4385  -2933.9856  -2757.6836
  -2981.0691  -3133.3455  -2870.0977
  -2860.0820  -2937.6907  -2645.8872

(8,.,.) = 
   5783.3198   6195.8447   5952.8447
   6521.1992   6950.6035   6626.2993
   6788.9907   7164.5894   6791.3569

(9,.,.) = 
   2542.9753   3056.9675   3258.1848
   2930.0146   3458.3442   3587.3916
   3202.5161   3738.5168   3824.7500

(10,.,.) = 
  -3418.9460  -3377.4121  -3128.0889
  -3662.7087  -3628.1113  -3358.0046
  -3626.5610  -3583.0029  -3335.6873

(11,.,.) = 
    481.0677    640.9683    732.2677
    754.6672    944.5984   1032.0085
    845.1861   1081.6622   1171.9142

(12,.,.) = 
    446.9253    719.0861    953.7953
    515.7609    833.9590   1058.0739
    273.6952    591.0877    787.7023

(13,.,.) = 
  -2939.7910  -3108.1685  -3005.5159
  -2962.6091  -3118.2012  -3002.9441
  -2897.3074  -3043.6902  -2901.6167

(14,.,.) = 
   5067.1602   5368.9028   5172.3120
   5342.8047   5634.9233   5395.0527
   5288.8677   5604.1475   5333.3325

(15,.,.) = 
   3455.5764   3747.6575   3721.7188
   4027.1453   4416.3599   4366.5928
   4363.0332   4772.7085   4700.7939

(16,.,.) = 
  -2935.0032  -3015.7283  -3003.9402
  -3066.0972  -3180.9590  -3156.8105
  -3199.9050  -3342.8638  -3304.9905

(17,.,.) = 
  -7606.8208  -8005.8857  -7904.2485
  -8731.6875  -9240.9141  -9136.7764
  -9437.2461 -10008.7998  -9882.6904

(18,.,.) = 
   1646.0592   1594.6527   1498.4783
   1835.5750   1755.8947   1649.1820
   1831.5688   1738.0171   1634.8593
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3697.1459960938	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #99: time = 0.581838	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2421e+04   4.2870e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #100	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00040000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1920
 1920
[torch.LongStorage of size 3]

x_start = 1 / y_start = 421	
img_means:size() vs img:size():	
    3
 1080
 1920
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.55555555555556	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
 1080
 1920
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.55555555555556	
proposal_im_detect: scaled_img_size:	
    2
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1897.6392 -2135.6052 -2060.1145
 -2022.6335 -2253.0491 -2145.5791
 -1981.7084 -2169.2874 -2046.1803

(2,.,.) = 
  2841.2559  3003.2175  2892.3708
  3045.3101  3223.9502  3070.6714
  2939.4749  3086.1782  2918.4490

(3,.,.) = 
  3649.7600  3975.9934  3975.9988
  4477.1709  4888.3560  4881.0503
  4898.0918  5373.3291  5350.4854

(4,.,.) = 
  1042.6804  1161.9279  1139.9563
  1304.6394  1404.8326  1353.1166
  1418.9117  1472.4675  1380.2993

(5,.,.) = 
   741.7958   733.1993   655.0028
   728.1494   681.2542   575.4955
   744.6088   662.5652   554.2880

(6,.,.) = 
  1631.2490  1848.5452  1890.7024
  2003.3400  2309.2932  2352.5688
  2306.1221  2648.4863  2675.9067

(7,.,.) = 
 -2732.9097 -2902.8049 -2726.7371
 -2949.1558 -3098.6946 -2836.7607
 -2828.0637 -2903.4041 -2612.8770

(8,.,.) = 
  5718.3496  6126.1694  5884.7939
  6447.2407  6871.3726  6550.0151
  6711.0322  7081.6343  6711.8828

(9,.,.) = 
  2510.7227  3019.5569  3218.9429
  2892.4346  3415.3569  3543.2375
  3162.5686  3693.0325  3778.4197

(10,.,.) = 
 -3384.6006 -3342.6975 -3094.6655
 -3624.7043 -3589.6975 -3321.3257
 -3587.5151 -3543.3762 -3297.7886

(11,.,.) = 
   474.7742   633.2989   724.3802
   745.8508   934.3916  1021.5939
   836.4490  1070.9065  1160.7886

(12,.,.) = 
   444.8879   714.7064   947.4959
   512.4368   827.6848  1049.8479
   270.9268   584.9855   779.4485

(13,.,.) = 
 -2914.5317 -3081.1660 -2978.9656
 -2936.6709 -3089.9373 -2975.0161
 -2870.1812 -3014.3940 -2873.3069

(14,.,.) = 
  5019.2720  5318.0576  5122.7803
  5290.6577  5579.8511  5341.4199
  5234.3970  5546.2617  5277.3628

(15,.,.) = 
  3411.3623  3699.3071  3673.8005
  3975.9465  4360.1123  4311.1191
  4307.5508  4712.0420  4641.4937

(16,.,.) = 
 -2900.7227 -2980.4048 -2969.3350
 -3027.8726 -3141.5725 -3118.6797
 -3159.3677 -3300.6787 -3264.3496

(17,.,.) = 
 -7514.8057 -7908.9536 -7809.3013
 -8625.3955 -9128.7012 -9026.5381
 -9322.4424 -9887.6279 -9764.5322

(18,.,.) = 
  1629.5011  1578.3235  1482.4907
  1816.3892  1737.4437  1631.1766
  1811.4575  1718.7052  1615.9381
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3649.7600097656	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #100: time = 0.79141799999999	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.9200e+03   1.9200e+03
        -inf         -inf   1.0726e+05   6.3420e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #101	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00030002/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1914.9242 -2155.1814 -2079.1313
 -2041.6460 -2274.3267 -2166.0957
 -2000.8368 -2190.4758 -2066.3445

(2,.,.) = 
  2866.9993  3030.5747  2919.0200
  3073.5220  3254.1279  3099.5664
  2967.1045  3115.6245  2946.5142

(3,.,.) = 
  3691.6479  4021.3567  4020.8237
  4527.1714  4942.7661  4934.7993
  4951.5674  5431.6250  5407.7642

(4,.,.) = 
  1055.4462  1176.0798  1153.7642
  1320.3966  1421.5300  1369.1443
  1435.5267  1489.7189  1396.5513

(5,.,.) = 
   750.8373   742.3638   663.3547
   737.0969   690.2305   583.4371
   753.6959   671.2788   562.0587

(6,.,.) = 
  1650.9601  1870.7841  1912.9993
  2026.6646  2335.9343  2379.2358
  2332.0630  2677.9067  2705.1233

(7,.,.) = 
 -2759.8865 -2931.7371 -2754.4592
 -2978.6079 -3130.0120 -2865.8882
 -2856.6687 -2933.2798 -2640.4155

(8,.,.) = 
  5778.4980  6190.4209  5946.7583
  6514.7026  6943.2144  6618.4653
  6780.8091  7155.3169  6781.7183

(9,.,.) = 
  2539.1375  3052.8567  3253.8984
  2924.9736  3452.9290  3581.7930
  3197.0483  3732.5789  3818.5791

(10,.,.) = 
 -3418.2996 -3376.3044 -3126.2830
 -3661.0913 -3626.0410 -3355.3596
 -3623.8445 -3579.7031 -3331.9658

(11,.,.) = 
   480.2291   640.1837   731.7927
   753.7714   943.8542  1031.5597
   844.7084  1081.2343  1171.7051

(12,.,.) = 
   447.8186   719.9532   954.7521
   516.3374   834.3693  1058.4535
   273.4308   590.4379   786.7825

(13,.,.) = 
 -2941.0122 -3109.2300 -3006.1899
 -2963.4202 -3118.5005 -3002.7290
 -2896.9946 -3042.8494 -2900.4734

(14,.,.) = 
  5067.2866  5368.8662  5171.7568
  5341.6572  5633.5649  5393.0449
  5285.7476  5600.6343  5329.2603

(15,.,.) = 
  3450.2441  3741.4302  3715.2866
  4020.5024  4408.7725  4358.8149
  4355.1182  4763.7661  4691.8921

(16,.,.) = 
 -2932.1912 -3012.8022 -3001.2014
 -3061.5769 -3176.3591 -3152.6179
 -3194.2981 -3337.0227 -3299.6411

(17,.,.) = 
 -7598.1221 -7996.4668 -7894.9951
 -8720.1836 -9228.5518 -9124.5371
 -9423.4600 -9994.1230 -9868.6016

(18,.,.) = 
  1645.6011  1594.0597  1497.5159
  1834.5250  1754.8080  1647.7352
  1829.8317  1736.2175  1632.6831
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3691.6479492188	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #101: time = 0.604906	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2247e+04   4.2721e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #102	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00102008/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 360
 640
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 640
 640
[torch.LongStorage of size 3]

x_start = 1 / y_start = 141	
img_means:size() vs img:size():	
   3
 360
 640
[torch.LongStorage of size 3]

   3
 360
 640
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6666666666667	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 360
 640
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6666666666667	
proposal_im_detect: scaled_img_size:	
    5
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1897.2068 -2135.1956 -2059.7329
 -2022.5116 -2252.9041 -2145.4385
 -1981.8046 -2169.3855 -2046.2749

(2,.,.) = 
  2840.6199  3002.5889  2891.7683
  3044.8982  3223.5879  3070.3579
  2939.3235  3086.1416  2918.4861

(3,.,.) = 
  3649.9375  3976.4214  3976.7402
  4478.0029  4889.5127  4882.4683
  4899.5103  5375.1030  5352.4214

(4,.,.) = 
  1043.2020  1162.5791  1140.6769
  1305.1681  1405.5931  1353.9736
  1419.5779  1473.2893  1381.1062

(5,.,.) = 
   741.8270   733.2053   655.0764
   728.2798   681.3749   575.7028
   744.7811   662.7482   554.6815

(6,.,.) = 
  1631.7982  1849.3790  1891.6863
  2004.1671  2310.3821  2353.8052
  2307.1545  2649.8857  2677.4978

(7,.,.) = 
 -2733.5420 -2903.4846 -2727.5491
 -2950.0085 -3099.6536 -2837.8542
 -2829.0894 -2904.5623 -2614.1423

(8,.,.) = 
  5719.3701  6127.4956  5886.2778
  6448.8599  6873.3521  6552.1631
  6713.1167  7084.0991  6714.3701

(9,.,.) = 
  2511.1274  3020.2712  3220.0320
  2893.4697  3416.8145  3545.0725
  3163.9602  3694.8123  3780.5317

(10,.,.) = 
 -3383.6721 -3342.0308 -3094.2827
 -3624.0178 -3589.3574 -3321.1575
 -3587.4072 -3543.5698 -3298.1504

(11,.,.) = 
   475.3915   634.0173   724.9711
   746.2949   934.9315  1022.0944
   836.9684  1071.5272  1161.4038

(12,.,.) = 
   444.9557   714.8651   947.5877
   512.4139   827.7591  1049.8881
   271.0776   585.2242   779.6642

(13,.,.) = 
 -2914.3508 -3080.9580 -2978.8433
 -2936.9495 -3090.2632 -2975.4690
 -2870.5947 -3014.9253 -2873.9800

(14,.,.) = 
  5019.1621  5318.0894  5122.9302
  5291.0166  5580.3799  5342.1294
  5235.1626  5547.2690  5278.5415

(15,.,.) = 
  3412.2002  3700.5225  3675.2031
  3977.2568  4361.8555  4312.9907
  4309.1997  4714.1152  4643.5903

(16,.,.) = 
 -2899.9761 -2979.8159 -2968.9739
 -3027.6941 -3141.6008 -3118.9961
 -3159.6753 -3301.2549 -3265.1987

(17,.,.) = 
 -7515.1294 -7909.7788 -7810.5952
 -8626.6289 -9130.6240 -9028.9072
 -9324.5938 -9890.4922 -9767.7480

(18,.,.) = 
  1629.1178  1577.9517  1482.2031
  1816.1406  1737.2419  1631.1063
  1811.4734  1718.7932  1616.1488
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3649.9375	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #102: time = 0.477723	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   6.4000e+02   6.4000e+02
        -inf         -inf   3.5729e+04   2.1110e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #103	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00004000/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 480
 480
[torch.LongStorage of size 3]

x_start = 1 / y_start = 61	
img_means:size() vs img:size():	
   3
 360
 480
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6666666666667	
(orep_img_for_blob) img size after scaling:	
   3
 600
 800
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x97
  2 : CudaTensor - size: 18x72x97
  3 : CudaTensor - size: 18x70x95
  4 : CudaTensor - size: 18x68x93
  5 : CudaTensor - size: 256x74x99
}
proposal_im_deteect: img_blob size:    3
 600
 800
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 360
 480
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6666666666667	
proposal_im_detect: scaled_img_size:	
   5
 600
 800
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1922.9620  -2164.8308  -2087.7258
  -2052.8193  -2286.9929  -2177.7700
  -2012.8486  -2203.8857  -2078.4221

(2,.,.) = 
   2879.2004   3043.7241   2931.8047
   3089.0015   3271.4182   3115.5835
   2982.9817   3133.4114   2963.2495

(3,.,.) = 
   3733.8096   4065.6929   4062.4739
   4577.2295   4995.9341   4985.1089
   5003.3071   5487.0405   5459.6143

(4,.,.) = 
   1073.1471   1195.6223   1172.3854
   1339.9510   1442.5085   1389.1528
   1454.7953   1509.8677   1415.0938

(5,.,.) = 
    762.7257    753.5970    672.5201
    748.9339    701.9050    593.5305
    764.2299    681.8909    572.6099

(6,.,.) = 
   1677.0920   1900.1500   1941.5781
   2056.3005   2369.2234   2411.7202
   2362.4795   2712.4734   2738.5852

(7,.,.) = 
  -2786.7661  -2960.2351  -2782.1064
  -3008.1448  -3161.5735  -2895.8411
  -2884.7642  -2962.9827  -2668.6768

(8,.,.) = 
   5838.4165   6252.5186   6004.1313
   6580.6240   7011.6763   6681.5576
   6844.8862   7222.1611   6843.1299

(9,.,.) = 
   2570.7512   3089.0339   3291.5957
   2962.8735   3495.2644   3624.6125
   3234.1951   3773.4258   3858.9822

(10,.,.) = 
  -3434.9973  -3392.8455  -3142.3640
  -3679.8625  -3645.3940  -3373.3928
  -3643.8977  -3601.0024  -3352.7991

(11,.,.) = 
    489.0634    650.3528    740.7597
    762.1572    953.4636   1040.6215
    852.7706   1091.3260   1181.7440

(12,.,.) = 
    448.5997    723.7361    959.5554
    518.6340    840.0548   1065.1439
    277.3885    597.6290    794.8862

(13,.,.) = 
  -2958.3308  -3126.8936  -3023.2791
  -2983.7747  -3140.1431  -3024.3362
  -2917.5435  -3064.3721  -2921.1411

(14,.,.) = 
   5102.0864   5404.6016   5204.6548
   5379.8550   5672.6069   5429.8657
   5324.2051   5640.5054   5366.7949

(15,.,.) = 
   3494.0200   3788.5149   3759.6750
   4069.2478   4461.4004   4408.4736
   4403.8716   4816.4858   4741.1724

(16,.,.) = 
  -2955.1567  -3035.8184  -3022.9124
  -3090.0161  -3204.7710  -3179.2935
  -3224.3486  -3368.0701  -3329.0181

(17,.,.) = 
  -7679.5127  -8079.3887  -7972.3320
  -8811.6943  -9323.2793  -9214.1982
  -9516.7598 -10091.4219  -9960.5439

(18,.,.) = 
   1654.3368   1601.7654   1504.8711
   1845.3345   1764.3568   1657.4871
   1842.4174   1748.0726   1645.0303
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 95
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 19950
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 95
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 95
[torch.LongStorage of size 2]

shift_y size:	
 70
 95
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6650
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 19950
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  19950
[torch.LongStorage of size 1]
	
  first line: 3733.8095703125	
(fast bbox transform) src_w size:  19950
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 19950
     4
[torch.LongStorage of size 2]

scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 19950
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 53200
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13300
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13300
[torch.LongStorage of size 1]

test img #103: time = 0.37313	
(proposal_test:boxes_filter) boxes & scores size:	
 13300
     4
[torch.LongStorage of size 2]

 13300
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 953
   3
[torch.LongTensor of size 2]

mask size:	
 13300
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   4.8000e+02   4.8000e+02
        -inf         -inf   3.6383e+04   2.1440e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #104	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00018001/000001.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1915.8488 -2156.3162 -2080.3206
 -2042.5038 -2275.4548 -2167.4263
 -2000.8278 -2190.7974 -2067.0620

(2,.,.) = 
  2868.2935  3032.2051  2920.8586
  3074.6011  3255.7847  3101.4958
  2966.7346  3116.0403  2947.4485

(3,.,.) = 
  3693.2188  4022.9377  4022.4275
  4528.6069  4944.1162  4936.2188
  4952.2275  5431.9927  5408.1865

(4,.,.) = 
  1056.0289  1176.5732  1154.1942
  1321.5497  1422.4415  1369.9523
  1436.9763  1490.7943  1397.5342

(5,.,.) = 
   751.3139   742.7545   663.7733
   737.6790   690.7745   584.0901
   754.1620   671.7228   562.7546

(6,.,.) = 
  1651.4561  1871.5272  1913.8190
  2026.8197  2336.5940  2380.3618
  2331.4268  2677.8000  2705.6187

(7,.,.) = 
 -2760.1482 -2932.2019 -2754.9995
 -2978.1433 -3130.0723 -2866.3120
 -2854.4492 -2931.8792 -2639.8008

(8,.,.) = 
  5779.9561  6192.0381  5948.3530
  6515.3862  6944.1763  6619.6201
  6779.0562  7154.0151  6781.1440

(9,.,.) = 
  2539.7180  3053.5527  3254.7161
  2925.1870  3453.2815  3582.5791
  3195.8943  3731.6423  3818.3201

(10,.,.) = 
 -3419.1726 -3377.2546 -3127.1521
 -3661.3069 -3626.6858 -3356.1033
 -3622.3113 -3578.9626 -3331.8479

(11,.,.) = 
   480.1411   640.2145   731.7713
   753.8802   944.1000  1031.6379
   844.8946  1081.5637  1171.7833

(12,.,.) = 
   448.2049   720.5444   955.4743
   517.3648   835.6039  1059.7279
   275.0236   592.2666   788.5539

(13,.,.) = 
 -2942.0017 -3110.5583 -3007.5710
 -2963.3071 -3119.1250 -3003.8596
 -2894.8987 -3041.8093 -2900.3701

(14,.,.) = 
  5068.9565  5370.9058  5173.7642
  5342.0776  5634.7876  5394.5698
  5283.4570  5599.6206  5329.0879

(15,.,.) = 
  3451.4407  3742.6597  3716.4692
  4021.4233  4409.8501  4360.0273
  4354.8516  4763.6182  4692.0640

(16,.,.) = 
 -2933.7471 -3014.4917 -3002.8203
 -3063.1267 -3178.1963 -3154.4419
 -3194.9631 -3338.1770 -3300.9248

(17,.,.) = 
 -7601.7656 -8000.0625 -7898.4634
 -8724.0654 -9232.4863 -9128.4355
 -9426.0439 -9996.7705 -9871.3789

(18,.,.) = 
  1646.2251  1594.6614  1498.1851
  1834.8843  1755.2228  1648.2920
  1829.6547  1736.3019  1633.0374
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3693.21875	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #104: time = 0.57986	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2071e+04   4.2601e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #105	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00006003/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1915.2301  -2155.8977  -2080.1250
  -2042.6886  -2275.9604  -2168.1404
  -2002.5660  -2193.0779  -2069.1670

(2,.,.) = 
   2867.5098   3031.5466   2920.5642
   3074.7246   3256.1294   3101.8850
   2968.6003   3118.1028   2949.4519

(3,.,.) = 
   3704.2466   4034.4592   4032.9944
   4540.7793   4957.2495   4948.1699
   4964.6011   5445.2422   5419.9531

(4,.,.) = 
   1060.2770   1181.4542   1158.8702
   1326.4573   1427.7817   1375.0504
   1441.5745   1496.0802   1402.5677

(5,.,.) = 
    754.7626    746.5073    667.1382
    741.1469    694.7639    587.6374
    757.5971    675.5676    566.3371

(6,.,.) = 
   1658.2568   1878.9541   1920.6602
   2034.1934   2344.3040   2387.1106
   2339.2571   2685.8562   2712.4392

(7,.,.) = 
  -2764.5540  -2937.2419  -2760.7256
  -2983.7332  -3136.1738  -2872.5415
  -2861.7080  -2939.4214  -2647.3369

(8,.,.) = 
   5791.7603   6204.4204   5960.5186
   6528.9038   6958.4111   6632.9082
   6794.3638   7169.8389   6795.4790

(9,.,.) = 
   2547.7800   3061.9836   3262.9248
   2934.8264   3463.2998   3591.8794
   3206.1050   3742.1338   3827.8418

(10,.,.) = 
  -3422.6653  -3381.0615  -3131.2932
  -3665.9197  -3631.2173  -3360.6460
  -3628.6677  -3585.0300  -3337.3591

(11,.,.) = 
    481.7896    641.7919    732.9719
    755.3461    945.3297   1032.6389
    845.4534   1081.9573   1172.1123

(12,.,.) = 
    446.6898    718.9515    953.7793
    515.7793    834.1215   1058.3376
    273.9364    591.5345    788.3256

(13,.,.) = 
  -2942.1226  -3110.5977  -3007.7344
  -2964.4053  -3120.3188  -3004.9246
  -2898.6455  -3045.2815  -2903.0073

(14,.,.) = 
   5072.1450   5374.0386   5176.7861
   5347.0708   5639.3379   5398.9033
   5291.9028   5607.3027   5335.9102

(15,.,.) = 
   3462.0012   3754.3274   3727.6316
   4033.1619   4422.6064   4371.9932
   4367.5806   4777.2944   4704.4790

(16,.,.) = 
  -2939.7000  -3020.4792  -3008.2852
  -3070.8826  -3185.6484  -3160.8921
  -3203.6646  -3346.4280  -3307.8557

(17,.,.) = 
  -7619.9966  -8019.0312  -7915.7588
  -8744.7969  -9253.8457  -9147.9814
  -9447.6699 -10018.8047  -9890.7451

(18,.,.) = 
   1647.9573   1596.3265   1500.0212
   1837.3425   1757.3423   1650.5181
   1832.8733   1739.0112   1635.7987
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3704.2465820312	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #105: time = 0.55673899999999	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2310e+04   4.2803e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #106	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00016004/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 360
 640
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 640
 640
[torch.LongStorage of size 3]

x_start = 1 / y_start = 141	
img_means:size() vs img:size():	
   3
 360
 640
[torch.LongStorage of size 3]

   3
 360
 640
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6666666666667	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 360
 640
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6666666666667	
proposal_im_detect: scaled_img_size:	
    5
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1915.0177 -2155.2935 -2079.3416
 -2041.6527 -2274.3452 -2166.1931
 -2000.9701 -2190.6179 -2066.6531

(2,.,.) = 
  2867.1831  3030.7791  2919.2729
  3073.6272  3254.1819  3099.8010
  2967.3125  3115.8396  2946.9221

(3,.,.) = 
  3688.8979  4018.8723  4019.0986
  4524.2651  4940.0078  4932.7461
  4948.8291  5428.7954  5405.4595

(4,.,.) = 
  1054.1660  1174.7556  1152.6681
  1319.0803  1420.2690  1368.1199
  1434.4730  1488.6475  1395.6840

(5,.,.) = 
   750.0134   741.6289   662.8469
   736.4036   689.5317   582.9078
   753.3147   670.8295   561.6730

(6,.,.) = 
  1649.1287  1868.8947  1911.4348
  2024.7032  2333.9207  2377.5342
  2330.1091  2675.9294  2703.4285

(7,.,.) = 
 -2759.1418 -2931.0105 -2753.8208
 -2977.7349 -3129.0940 -2865.1421
 -2855.8721 -2932.5122 -2639.7961

(8,.,.) = 
  5775.8115  6187.9995  5945.0425
  6511.8984  6940.5928  6616.5386
  6778.2134  7152.7231  6779.6196

(9,.,.) = 
  2537.2146  3050.9587  3252.2949
  2922.8113  3450.7961  3580.0159
  3195.0078  3730.6013  3816.9336

(10,.,.) = 
 -3418.1609 -3376.3464 -3126.4602
 -3660.9065 -3625.9553 -3355.4114
 -3623.4202 -3579.3049 -3331.6289

(11,.,.) = 
   479.8326   639.7981   731.5466
   753.3448   943.4553  1031.2502
   844.2156  1080.7178  1171.1605

(12,.,.) = 
   448.2631   720.2923   955.0948
   516.6995   834.6554  1058.8135
   273.7077   590.7241   787.1588

(13,.,.) = 
 -2940.7786 -3109.1084 -3006.1489
 -2963.2783 -3118.4082 -3002.6675
 -2896.9282 -3042.9578 -2900.7292

(14,.,.) = 
  5066.5620  5368.3999  5171.6514
  5341.0181  5633.1694  5392.8950
  5285.0786  5600.2017  5329.0664

(15,.,.) = 
  3447.6738  3738.9248  3713.3701
  4017.7891  4406.0991  4356.7046
  4352.4922  4761.0596  4689.6177

(16,.,.) = 
 -2930.8828 -3011.6821 -3000.4626
 -3060.1006 -3175.0522 -3151.6848
 -3193.0215 -3335.7407 -3298.5962

(17,.,.) = 
 -7593.2993 -7992.1084 -7891.8916
 -8715.2441 -9223.9385 -9120.9668
 -9418.9619 -9989.6152 -9864.8506

(18,.,.) = 
  1645.5834  1594.1969  1497.7355
  1834.4381  1754.8506  1647.8003
  1829.6029  1735.9777  1632.4354
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3688.8979492188	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #106: time = 0.507126	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   6.4000e+02   6.4000e+02
        -inf         -inf   3.6084e+04   2.1310e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #107	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00060004/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1909.6172 -2149.2063 -2073.3191
 -2035.8772 -2267.8928 -2159.8975
 -1995.0784 -2184.1223 -2060.2778

(2,.,.) = 
  2859.0891  3022.2168  2910.9163
  3064.9019  3244.9968  3090.8179
  2958.6934  3106.7156  2938.0369

(3,.,.) = 
  3679.7271  4008.4177  4007.9111
  4512.7998  4927.1133  4919.1582
  4936.0322  5414.6387  5390.8394

(4,.,.) = 
  1051.9452  1172.1919  1149.9489
  1316.0118  1416.8700  1364.6428
  1430.8320  1484.8453  1391.9122

(5,.,.) = 
   748.3599   739.8469   661.0812
   734.6308   687.7773   581.3110
   751.1519   668.8892   559.9937

(6,.,.) = 
  1645.5391  1864.7078  1906.8630
  2020.1742  2328.5361  2371.7659
  2324.7251  2669.5891  2696.7988

(7,.,.) = 
 -2752.0569 -2923.3972 -2746.5491
 -2970.1099 -3121.0122 -2857.5686
 -2848.4709 -2924.7334 -2632.5701

(8,.,.) = 
  5761.0527  6171.7642  5928.7085
  6495.0430  6922.2642  6598.3784
  6760.3716  7133.7036  6761.0479

(9,.,.) = 
  2531.1650  3043.4443  3243.9607
  2915.8518  3442.2781  3570.7729
  3187.2192  3721.2048  3806.9143

(10,.,.) = 
 -3408.0532 -3366.1133 -3116.7192
 -3650.0378 -3615.0386 -3345.0330
 -3612.9055 -3568.7725 -3321.6235

(11,.,.) = 
   478.6812   638.2145   729.5728
   751.4550   941.0443  1028.5192
   842.2400  1078.1064  1168.3329

(12,.,.) = 
   446.8942   718.3468   952.5085
   515.1873   832.4003  1055.8672
   272.8193   588.9591   784.7213

(13,.,.) = 
 -2932.9229 -3100.6887 -2997.9614
 -2955.3062 -3109.8835 -2994.4343
 -2888.9646 -3034.3411 -2892.3613

(14,.,.) = 
  5052.7798  5353.5449  5156.9966
  5326.3130  5617.3906  5377.4961
  5270.4277  5584.3516  5313.6660

(15,.,.) = 
  3439.2356  3729.5317  3703.4771
  4007.7988  4394.8867  4345.0796
  4341.4316  4748.8623  4677.1948

(16,.,.) = 
 -2922.9595 -3003.3230 -2991.8474
 -3051.7861 -3166.2419 -3142.6621
 -3184.1323 -3326.4177 -3289.2288

(17,.,.) = 
 -7574.0830 -7971.1675 -7870.0308
 -8692.6768 -9199.5254 -9095.8262
 -9393.9102 -9962.8818 -9837.7285

(18,.,.) = 
  1640.7500  1589.3298  1493.0316
  1829.1001  1749.6036  1642.7867
  1824.4042  1731.0208  1627.6898
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3679.7270507812	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #107: time = 0.543353	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2017e+04   4.2584e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #108	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00118001/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1904.3884 -2142.9380 -2066.7058
 -2029.8893 -2260.8259 -2152.4924
 -1988.9401 -2177.0298 -2053.0210

(2,.,.) = 
  2851.4915  3013.5798  2901.7461
  3056.4719  3235.3162  3080.7751
  2950.4238  3097.3452  2928.3914

(3,.,.) = 
  3664.9150  3991.1694  3989.5105
  4495.6265  4907.2344  4898.3506
  4918.2573  5394.4292  5370.2354

(4,.,.) = 
  1047.2998  1166.5581  1143.9178
  1310.2434  1410.2120  1357.7017
  1424.8459  1478.0839  1385.0303

(5,.,.) = 
   745.1656   736.1990   657.2188
   731.5071   684.2137   577.6360
   748.1183   665.6530   556.7015

(6,.,.) = 
  1638.1992  1855.8641  1897.4263
  2011.9193  2318.6311  2361.3071
  2315.9619  2659.2483  2686.0166

(7,.,.) = 
 -2743.3394 -2913.3018 -2735.8701
 -2960.6387 -3110.2698 -2846.5764
 -2839.4150 -2914.6658 -2622.5090

(8,.,.) = 
  5740.9297  6148.6602  5904.3667
  6472.7661  6896.9614  6572.4731
  6737.9946  7108.8877  6736.2231

(9,.,.) = 
  2521.0222  3030.9807  3229.8008
  2904.4119  3428.5549  3555.6733
  3175.6653  3707.6052  3792.2729

(10,.,.) = 
 -3397.4280 -3354.6882 -3104.9111
 -3638.5249 -3602.7737 -3332.6956
 -3601.3889 -3556.6978 -3309.6069

(11,.,.) = 
   476.8270   635.9377   727.1655
   748.9476   938.0798  1025.3704
   839.9105  1075.1917  1165.2012

(12,.,.) = 
   446.2391   717.1956   950.8372
   514.0447   830.4894  1053.3359
   271.7838   587.0841   782.1534

(13,.,.) = 
 -2925.4299 -3092.2327 -2989.0381
 -2947.7429 -3101.2871 -2985.3235
 -2881.1829 -3025.6404 -2883.3904

(14,.,.) = 
  5038.2998  5337.1582  5139.7974
  5310.8330  5600.2158  5359.6279
  5254.6753  5567.0063  5295.9961

(15,.,.) = 
  3425.5103  3713.4712  3686.3831
  3992.4956  4377.1318  4326.5044
  4325.5640  4730.8140  4658.7695

(16,.,.) = 
 -2912.5488 -2991.6321 -2979.2246
 -3040.4106 -3153.6428 -3129.4478
 -3172.6021 -3313.7502 -3276.2297

(17,.,.) = 
 -7545.8594 -7939.1802 -7836.1465
 -8660.9043 -9163.9580 -9058.5684
 -9360.6260 -9926.1768 -9800.2012

(18,.,.) = 
  1635.5889  1583.8204  1487.1709
  1823.1377  1743.4512  1636.4070
  1818.4202  1725.0319  1621.5905
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3664.9150390625	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #108: time = 0.660523	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1790e+04   4.2445e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #109	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00028000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 288
 384
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 384
 384
[torch.LongStorage of size 3]

x_start = 1 / y_start = 49	
img_means:size() vs img:size():	
   3
 288
 384
[torch.LongStorage of size 3]

   3
 288
 384
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 2.0833333333333	
(orep_img_for_blob) img size after scaling:	
   3
 600
 800
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x97
  2 : CudaTensor - size: 18x72x97
  3 : CudaTensor - size: 18x70x95
  4 : CudaTensor - size: 18x68x93
  5 : CudaTensor - size: 256x74x99
}
proposal_im_deteect: img_blob size:    3
 600
 800
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 288
 384
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 2.0833333333333	
proposal_im_detect: scaled_img_size:	
   6
 600
 800
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1920.6624  -2163.1423  -2087.6826
  -2050.9072  -2285.7476  -2178.2800
  -2012.0814  -2204.0520  -2080.3579

(2,.,.) = 
   2876.0339   3041.6660   2931.9634
   3086.1167   3269.7358   3116.2769
   2981.3875   3133.1052   2965.2175

(3,.,.) = 
   3734.1267   4068.6458   4068.5344
   4578.5356   5000.2935   4992.8340
   5006.4375   5492.9370   5468.7036

(4,.,.) = 
   1073.4454   1196.9622   1174.7363
   1341.2180   1444.8906   1392.3944
   1456.9158   1513.2988   1419.1317

(5,.,.) = 
    761.5357    753.0894    672.6571
    748.5292    702.2078    594.2102
    764.7416    682.9960    573.9321

(6,.,.) = 
   1677.6641   1901.5386   1944.1292
   2057.2134   2370.9395   2414.7886
   2363.9741   2714.8240   2742.3323

(7,.,.) = 
  -2783.6033  -2957.8816  -2781.5469
  -3005.3896  -3159.7805  -2895.7244
  -2883.2832  -2962.6560  -2669.8350

(8,.,.) = 
   5836.1724   6253.0986   6008.9653
   6580.5234   7014.6558   6688.5981
   6847.9873   7228.3418   6852.8252

(9,.,.) = 
   2570.5369   3089.7812   3293.7529
   2963.5010   3497.1934   3628.1003
   3236.0068   3776.7795   3864.0596

(10,.,.) = 
  -3434.5452  -3394.0317  -3145.5835
  -3680.6431  -3647.6221  -3377.5332
  -3646.1748  -3604.4050  -3357.6636

(11,.,.) = 
    490.3347    652.0519    742.7620
    763.4644    955.1578   1042.6169
    853.9033   1092.7275   1183.4210

(12,.,.) = 
    447.6124    722.5416    958.3484
    516.8424    838.1785   1063.6052
    275.9256    596.3793    794.2571

(13,.,.) = 
  -2954.2759  -3123.6760  -3021.9846
  -2980.1152  -3137.2988  -3023.4082
  -2915.2966  -3063.0479  -2921.4788

(14,.,.) = 
   5098.0498   5402.7378   5206.3022
   5377.5137   5672.2983   5432.8569
   5324.6230   5642.8589   5372.0703

(15,.,.) = 
   3494.5508   3791.1877   3765.0264
   4071.2246   4465.5469   4415.3838
   4407.7720   4822.5967   4749.8276

(16,.,.) = 
  -2955.0852  -3038.0464  -3027.5793
  -3091.3867  -3208.2754  -3184.9670
  -3227.2312  -3372.9072  -3335.7375

(17,.,.) = 
  -7679.3521  -8084.1782  -7983.2305
  -8814.9951  -9331.6123  -9228.6758
  -9524.4033 -10103.9434  -9978.4990

(18,.,.) = 
   1653.8536   1602.4275   1506.5991
   1845.3400   1765.5468   1659.5930
   1843.2770   1749.8596   1647.4844
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 95
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 19950
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 95
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 95
[torch.LongStorage of size 2]

shift_y size:	
 70
 95
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6650
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 19950
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  19950
[torch.LongStorage of size 1]
	
  first line: 3734.1267089844	
(fast bbox transform) src_w size:  19950
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 19950
     4
[torch.LongStorage of size 2]

scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 19950
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 53200
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13300
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13300
[torch.LongStorage of size 1]

test img #109: time = 0.35542799999999	
(proposal_test:boxes_filter) boxes & scores size:	
 13300
     4
[torch.LongStorage of size 2]

 13300
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 953
   3
[torch.LongTensor of size 2]

mask size:	
 13300
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   3.8400e+02   3.8400e+02
        -inf         -inf   2.9167e+04   1.7197e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #110	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00062000/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 480
 640
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 640
 640
[torch.LongStorage of size 3]

x_start = 1 / y_start = 81	
img_means:size() vs img:size():	
   3
 480
 640
[torch.LongStorage of size 3]

   3
 480
 640
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.25	
(orep_img_for_blob) img size after scaling:	
   3
 600
 800
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x97
  2 : CudaTensor - size: 18x72x97
  3 : CudaTensor - size: 18x70x95
  4 : CudaTensor - size: 18x68x93
  5 : CudaTensor - size: 256x74x99
}
proposal_im_deteect: img_blob size:    3
 600
 800
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 480
 640
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.25	
proposal_im_detect: scaled_img_size:	
   4
 600
 800
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1920.7550  -2162.9553  -2087.0479
  -2050.4177  -2284.9685  -2177.0632
  -2010.7206  -2202.2935  -2078.1995

(2,.,.) = 
   2876.1765   3041.4517   2930.9907
   3085.7285   3268.9199   3114.8411
   2980.2568   3131.4119   2962.9385

(3,.,.) = 
   3730.5403   4064.0000   4062.8469
   4574.3257   4995.0029   4986.6577
   5001.2920   5486.8687   5462.0029

(4,.,.) = 
   1072.0712   1195.0247   1172.3591
   1339.2715   1442.4658   1389.6464
   1454.4930   1510.4109   1416.0360

(5,.,.) = 
    760.6581    752.0807    671.6841
    747.2265    700.7532    592.8087
    762.9064    681.0256    571.9005

(6,.,.) = 
   1675.3855   1898.5785   1940.6124
   2054.7585   2367.7607   2410.9902
   2361.2095   2711.1257   2737.9321

(7,.,.) = 
  -2782.2803  -2956.1892  -2779.2610
  -3003.6589  -3157.5344  -2892.9795
  -2880.6721  -2959.2830  -2665.7349

(8,.,.) = 
   5832.1396   6248.1616   6002.8940
   6575.4849   7008.6577   6681.7861
   6841.3662   7220.6113   6844.3174

(9,.,.) = 
   2567.8984   3086.6084   3289.9675
   2960.3374   3493.5081   3623.9216
   3232.4272   3772.6008   3859.3193

(10,.,.) = 
  -3433.0620  -3392.1619  -3143.0579
  -3678.7488  -3645.3193  -3374.6531
  -3643.6648  -3601.2742  -3353.8914

(11,.,.) = 
    489.5203    651.0317    741.6672
    762.7560    954.2266   1041.6320
    853.4178   1092.0208   1182.6639

(12,.,.) = 
    448.0218    722.6688    958.1934
    517.2119    838.1473   1063.2162
    275.8604    595.8412    793.3552

(13,.,.) = 
  -2953.9214  -3123.3225  -3021.3743
  -2979.4619  -3136.4863  -3022.3342
  -2914.0410  -3061.5388  -2919.7764

(14,.,.) = 
   5096.5146   5400.8311   5203.7471
   5375.1948   5669.6260   5429.6011
   5321.0166   5638.7222   5367.4048

(15,.,.) = 
   3490.9392   3786.5496   3759.4771
   4066.9363   4460.2163   4409.2393
   4402.4736   4816.0806   4742.5605

(16,.,.) = 
  -2952.8433  -3035.2695  -3024.1787
  -3088.1694  -3204.6562  -3180.9980
  -3223.2817  -3368.5527  -3331.1836

(17,.,.) = 
  -7673.0356  -8076.1704  -7973.4404
  -8806.8848  -9322.0342  -9217.5625
  -9514.1963 -10092.2998  -9965.7578

(18,.,.) = 
   1653.2865   1601.7117   1505.4689
   1844.4910   1764.6195   1658.2511
   1841.9744   1748.4814   1645.6954
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 95
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 19950
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 95
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 95
[torch.LongStorage of size 2]

shift_y size:	
 70
 95
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6650
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 19950
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  19950
[torch.LongStorage of size 1]
	
  first line: 3730.5402832031	
(fast bbox transform) src_w size:  19950
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 19950
     4
[torch.LongStorage of size 2]

scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 19950
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 53200
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13300
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13300
[torch.LongStorage of size 1]

test img #110: time = 0.36402899999999	
(proposal_test:boxes_filter) boxes & scores size:	
 13300
     4
[torch.LongStorage of size 2]

 13300
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 953
   3
[torch.LongTensor of size 2]

mask size:	
 13300
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   6.4000e+02   6.4000e+02
        -inf         -inf   4.8566e+04   2.8647e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #111	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00100000/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 480
 480
[torch.LongStorage of size 3]

x_start = 1 / y_start = 61	
img_means:size() vs img:size():	
   3
 360
 480
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6666666666667	
(orep_img_for_blob) img size after scaling:	
   3
 600
 800
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x97
  2 : CudaTensor - size: 18x72x97
  3 : CudaTensor - size: 18x70x95
  4 : CudaTensor - size: 18x68x93
  5 : CudaTensor - size: 256x74x99
}
proposal_im_deteect: img_blob size:    3
 600
 800
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 360
 480
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6666666666667	
proposal_im_detect: scaled_img_size:	
   5
 600
 800
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1914.2736  -2155.4641  -2079.8030
  -2043.0023  -2276.6223  -2168.7092
  -2004.4020  -2195.1248  -2071.1748

(2,.,.) = 
   2867.8740   3032.6904   2922.4514
   3076.3318   3258.5759   3104.8904
   2972.2974   3122.5901   2954.3840

(3,.,.) = 
   3711.6323   4043.5789   4042.3835
   4555.6851   4975.1978   4966.9136
   4987.0547   5472.2344   5447.8843

(4,.,.) = 
   1065.7177   1187.8350   1164.9740
   1331.8468   1434.7119   1381.8301
   1448.5115   1504.3083   1409.9419

(5,.,.) = 
    755.5219    746.4862    666.5463
    742.9492    696.0630    588.5222
    760.1750    678.2953    569.3846

(6,.,.) = 
   1667.4371   1889.8757   1931.7650
   2048.2812   2360.3430   2403.3259
   2356.2368   2705.4944   2732.6572

(7,.,.) = 
  -2772.6536  -2946.0352  -2769.3652
  -2994.6526  -3147.8770  -2883.8123
  -2874.3508  -2952.7061  -2659.6130

(8,.,.) = 
   5807.2764   6221.3208   5976.1885
   6552.3945   6983.8726   6657.6621
   6825.1943   7203.6646   6828.3115

(9,.,.) = 
   2553.7734   3071.4141   3274.1863
   2946.7317   3478.8389   3608.7986
   3223.0850   3762.5825   3849.0232

(10,.,.) = 
  -3419.5774  -3378.9536  -3130.5315
  -3666.8872  -3633.6470  -3363.7915
  -3635.4543  -3593.2922  -3346.4355

(11,.,.) = 
    489.1814    650.4140    740.7413
    762.0587    953.3453   1040.4807
    853.4963   1091.8658   1182.4517

(12,.,.) = 
    449.5934    724.4697    959.8339
    517.2532    837.9216   1062.7341
    275.0221    594.3875    791.3802

(13,.,.) = 
  -2944.4165  -3113.4556  -3012.0430
  -2971.1621  -3127.5200  -3013.6003
  -2907.8752  -3054.8359  -2913.1965

(14,.,.) = 
   5078.5312   5381.7993   5185.6387
   5359.2329   5652.7646   5413.3008
   5309.9956   5626.8945   5355.9121

(15,.,.) = 
   3473.5837   3767.6670   3740.6211
   4051.4355   4443.3428   4392.3828
   4391.5854   4804.6079   4731.3706

(16,.,.) = 
  -2938.5652  -3020.0928  -3009.1453
  -3074.3650  -3190.3132  -3166.8601
  -3213.6038  -3358.6804  -3321.5659

(17,.,.) = 
  -7636.1084  -8037.2788  -7934.9653
  -8772.5996  -9286.1768  -9181.9365
  -9488.5967 -10066.1221  -9940.4971

(18,.,.) = 
   1647.1710   1595.6694   1499.7765
   1838.4821   1758.9019   1652.7650
   1837.2783   1744.1622   1641.3386
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 95
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 19950
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 95
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 95
[torch.LongStorage of size 2]

shift_y size:	
 70
 95
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6650
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 19950
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  19950
[torch.LongStorage of size 1]
	
  first line: 3711.6323242188	
(fast bbox transform) src_w size:  19950
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 19950
     4
[torch.LongStorage of size 2]

scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 19950
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 53200
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13300
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13300
[torch.LongStorage of size 1]

test img #111: time = 0.3334	
(proposal_test:boxes_filter) boxes & scores size:	
 13300
     4
[torch.LongStorage of size 2]

 13300
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 953
   3
[torch.LongTensor of size 2]

mask size:	
 13300
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   4.8000e+02   4.8000e+02
        -inf         -inf   3.6421e+04   2.1481e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #112	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00018001/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1915.8507 -2156.3135 -2080.3149
 -2042.5042 -2275.4478 -2167.4097
 -2000.8235 -2190.7849 -2067.0398

(2,.,.) = 
  2868.2954  3032.2046  2920.8499
  3074.5972  3255.7805  3101.4824
  2966.7305  3116.0288  2947.4233

(3,.,.) = 
  3693.2146  4022.9314  4022.4175
  4528.6064  4944.1084  4936.1943
  4952.2344  5431.9849  5408.1519

(4,.,.) = 
  1056.0286  1176.5719  1154.1909
  1321.5507  1422.4435  1369.9479
  1436.9858  1490.7975  1397.5333

(5,.,.) = 
   751.3153   742.7542   663.7705
   737.6822   690.7709   584.0837
   754.1631   671.7169   562.7438

(6,.,.) = 
  1651.4554  1871.5258  1913.8146
  2026.8258  2336.5930  2380.3508
  2331.4370  2677.8035  2705.6067

(7,.,.) = 
 -2760.1577 -2932.2019 -2754.9907
 -2978.1479 -3130.0676 -2866.2949
 -2854.4619 -2931.8755 -2639.7803

(8,.,.) = 
  5779.9531  6192.0186  5948.3291
  6515.3882  6944.1572  6619.5786
  6779.0596  7153.9854  6781.0781

(9,.,.) = 
  2539.7231  3053.5530  3254.7095
  2925.1958  3453.2820  3582.5671
  3195.9114  3731.6455  3818.3032

(10,.,.) = 
 -3419.1716 -3377.2493 -3127.1382
 -3661.2991 -3626.6667 -3356.0762
 -3622.3005 -3578.9346 -3331.8040

(11,.,.) = 
   480.1398   640.2101   731.7642
   753.8829   944.1010  1031.6307
   844.9067  1081.5677  1171.7775

(12,.,.) = 
   448.2068   720.5438   955.4726
   517.3643   835.6058  1059.7247
   275.0252   592.2719   788.5591

(13,.,.) = 
 -2942.0081 -3110.5586 -3007.5603
 -2963.3115 -3119.1211 -3003.8450
 -2894.9028 -3041.8008 -2900.3479

(14,.,.) = 
  5068.9614  5370.8975  5173.7441
  5342.0776  5634.7739  5394.5386
  5283.4609  5599.6016  5329.0386

(15,.,.) = 
  3451.4404  3742.6528  3716.4573
  4021.4246  4409.8379  4359.9995
  4354.8638  4763.6147  4692.0229

(16,.,.) = 
 -2933.7454 -3014.4841 -3002.8137
 -3063.1255 -3178.1880 -3154.4209
 -3194.9563 -3338.1582 -3300.8853

(17,.,.) = 
 -7601.7539 -8000.0435 -7898.4365
 -8724.0547 -9232.4619 -9128.3936
 -9426.0449 -9996.7344 -9871.2988

(18,.,.) = 
  1646.2250  1594.6587  1498.1799
  1834.8782  1755.2128  1648.2802
  1829.6539  1736.2870  1633.0184
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3693.2145996094	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #112: time = 0.539435	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2069e+04   4.2600e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #113	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00067002/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1909.7805 -2149.2136 -2072.8362
 -2037.1707 -2269.0217 -2160.3879
 -1997.4716 -2186.4778 -2062.1091

(2,.,.) = 
  2859.5750  3022.0186  2909.8958
  3066.4666  3245.9783  3091.0383
  2961.8210  3109.5613  2940.1299

(3,.,.) = 
  3681.3276  4009.9434  4008.8684
  4516.8193  4931.0400  4922.2334
  4943.0527  5421.6250  5396.8013

(4,.,.) = 
  1052.8619  1173.4006  1150.9994
  1317.6880  1418.9282  1366.4937
  1433.4635  1487.6906  1394.3468

(5,.,.) = 
   749.3412   740.7520   661.4890
   736.3832   689.4280   582.3738
   753.3678   671.0605   561.7179

(6,.,.) = 
  1646.6981  1865.6678  1907.4362
  2021.9547  2330.0823  2372.8228
  2327.4387  2672.3918  2699.0054

(7,.,.) = 
 -2755.1274 -2925.7832 -2748.0005
 -2973.8965 -3124.3157 -2859.9224
 -2853.2888 -2929.2485 -2636.1716

(8,.,.) = 
  5766.8892  6177.1729  5932.6333
  6503.7466  6930.5991  6605.0669
  6772.0039  7145.0688  6770.5244

(9,.,.) = 
  2533.3894  3045.6602  3245.9834
  2920.0884  3446.8938  3575.1208
  3193.0535  3727.5120  3812.9153

(10,.,.) = 
 -3410.2952 -3367.2695 -3116.7375
 -3653.6335 -3617.4912 -3346.2329
 -3617.9031 -3572.7483 -3324.3765

(11,.,.) = 
   479.7435   639.4774   730.7720
   752.0270   941.8687  1029.3739
   843.1268  1079.2921  1169.5365

(12,.,.) = 
   445.7437   717.1574   951.2863
   513.4979   830.8668  1054.4835
   271.5506   588.0585   784.1022

(13,.,.) = 
 -2934.9949 -3102.0198 -2998.4993
 -2958.9734 -3113.0303 -2996.8076
 -2893.6338 -3038.6982 -2895.9089

(14,.,.) = 
  5056.8843  5356.7773  5158.8794
  5332.6904  5623.0938  5381.8276
  5278.7939  5592.2354  5320.1143

(15,.,.) = 
  3442.6460  3732.9065  3706.2031
  4013.1030  4400.2573  4349.6685
  4348.5181  4756.1240  4683.5151

(16,.,.) = 
 -2924.0786 -3004.0278 -2992.0220
 -3055.1355 -3169.3110 -3145.2881
 -3189.4924 -3331.5708 -3293.8052

(17,.,.) = 
 -7578.5635 -7974.8989 -7872.3101
 -8702.0576 -9208.1670 -9102.6152
 -9407.9551 -9976.2012 -9848.8682

(18,.,.) = 
  1641.6771  1589.5968  1492.5999
  1830.5374  1750.3606  1642.8905
  1826.7982  1732.8064  1628.9662
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3681.3276367188	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #113: time = 0.553923	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2171e+04   4.2674e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #114	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00037000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 360
 636
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 636
 636
[torch.LongStorage of size 3]

x_start = 1 / y_start = 139	
img_means:size() vs img:size():	
   3
 360
 636
[torch.LongStorage of size 3]

   3
 360
 636
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6666666666667	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1060
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1060
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 360
 636
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6666666666667	
proposal_im_detect: scaled_img_size:	
    5
  600
 1060
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1905.8442 -2146.8271 -2074.3552
 -2031.5895 -2265.2568 -2161.2029
 -1990.9717 -2182.0559 -2062.4016

(2,.,.) = 
  2854.2373  3020.1506  2913.4561
  3059.2339  3242.3245  3093.1650
  2952.9221  3104.0493  2940.6448

(3,.,.) = 
  3677.4260  4012.0356  4019.1289
  4510.1562  4931.6660  4932.5566
  4933.2603  5419.1030  5404.5225

(4,.,.) = 
  1051.8983  1174.0745  1154.2614
  1316.8585  1419.9121  1370.4265
  1431.9875  1488.6584  1398.4749

(5,.,.) = 
   745.9888   739.1071   662.5198
   732.5559   687.4001   582.8828
   749.2147   668.5386   561.7203

(6,.,.) = 
  1644.8132  1866.7053  1912.1917
  2019.2017  2330.4321  2377.5715
  2324.0625  2671.9248  2703.2708

(7,.,.) = 
 -2745.7334 -2919.8538 -2747.5444
 -2963.3335 -3117.0813 -2858.4001
 -2841.5061 -2920.7961 -2633.3730

(8,.,.) = 
  5752.3472  6170.5156  5938.3828
  6486.3218  6921.7407  6609.6284
  6751.8652  7133.7681  6773.1011

(9,.,.) = 
  2527.8496  3042.9778  3247.7637
  2912.0837  3441.8413  3575.5002
  3183.2493  3720.8518  3812.1907

(10,.,.) = 
 -3404.9500 -3367.8030 -3124.1509
 -3646.5674 -3616.4683 -3352.4895
 -3609.0505 -3569.6541 -3328.4841

(11,.,.) = 
   479.6538   640.1103   732.2177
   752.4185   942.9713  1031.2358
   842.7830  1079.3976  1170.4919

(12,.,.) = 
   448.1942   719.4121   953.3047
   516.1963   833.0566  1056.6118
   274.4442   590.2932   786.3668

(13,.,.) = 
 -2925.1682 -3095.5034 -2997.2400
 -2946.1201 -3103.2310 -2992.7329
 -2879.5706 -3027.5613 -2890.7007

(14,.,.) = 
  5043.7539  5350.1396  5162.0049
  5316.4961  5613.2935  5382.1855
  5260.7856  5580.5396  5319.0532

(15,.,.) = 
  3436.2495  3731.9326  3713.0459
  4004.9824  4397.8115  4355.9263
  4339.2246  4752.5913  4689.0049

(16,.,.) = 
 -2921.1089 -3006.3142 -3000.2761
 -3049.7981 -3169.2302 -3151.1665
 -3181.4814 -3328.9272 -3297.6655

(17,.,.) = 
 -7568.7124 -7977.9478 -7892.0586
 -8687.8047 -9208.2119 -9121.5947
 -9389.6084 -9972.9717 -9865.4844

(18,.,.) = 
  1640.2593  1591.6478  1498.0521
  1828.6713  1752.2919  1648.2595
  1823.8109  1733.4952  1632.8168
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3677.4260253906	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #114: time = 0.436037	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1150
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   6.3600e+02   6.3600e+02
        -inf         -inf   3.5625e+04   2.1434e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #115	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00016002/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 360
 640
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 640
 640
[torch.LongStorage of size 3]

x_start = 1 / y_start = 141	
img_means:size() vs img:size():	
   3
 360
 640
[torch.LongStorage of size 3]

   3
 360
 640
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6666666666667	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 360
 640
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6666666666667	
proposal_im_detect: scaled_img_size:	
    5
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1914.9094 -2155.2043 -2079.4231
 -2041.3502 -2274.0854 -2166.0964
 -2000.3361 -2189.9692 -2066.1047

(2,.,.) = 
  2867.0107  3030.7537  2919.4634
  3073.2568  3253.9326  3099.7063
  2966.7214  3115.2126  2946.3977

(3,.,.) = 
  3688.2156  4018.3438  4018.7529
  4523.2095  4939.1660  4932.2271
  4947.4897  5427.8389  5405.0454

(4,.,.) = 
  1054.0665  1174.7418  1152.6855
  1318.7448  1420.0255  1367.9366
  1433.7936  1488.0951  1395.2469

(5,.,.) = 
   749.6534   741.3141   662.6325
   735.8944   689.0857   582.5775
   752.6171   670.2215   561.1475

(6,.,.) = 
  1648.7177  1868.5298  1911.2059
  2024.1577  2333.3796  2377.1841
  2329.5928  2675.3657  2703.1143

(7,.,.) = 
 -2758.5645 -2930.5583 -2753.5386
 -2977.0137 -3128.4609 -2864.7007
 -2855.1135 -2931.7551 -2639.1633

(8,.,.) = 
  5774.5195  6186.9663  5944.3813
  6510.1421  6939.1011  6615.5625
  6776.3193  7151.1592  6778.7310

(9,.,.) = 
  2536.7827  3050.6812  3252.2217
  2921.9688  3450.1113  3579.5837
  3194.0881  3729.8096  3816.4453

(10,.,.) = 
 -3417.5632 -3375.9482 -3126.3745
 -3660.0955 -3625.3813 -3355.2341
 -3622.6750 -3578.7605 -3331.4854

(11,.,.) = 
   479.6537   639.6297   731.4185
   753.2316   943.3821  1031.2654
   844.2845  1080.7720  1171.3433

(12,.,.) = 
   448.5729   720.6858   955.5399
   516.9507   834.9354  1059.0839
   273.7361   590.6450   787.0046

(13,.,.) = 
 -2940.6279 -3109.0747 -3006.3804
 -2962.7502 -3117.8674 -3002.3438
 -2896.0864 -3041.9619 -2899.8857

(14,.,.) = 
  5065.8623  5367.9268  5171.5615
  5339.8633  5632.2002  5392.3354
  5283.6592  5598.9028  5328.1885

(15,.,.) = 
  3446.7639  3738.1501  3712.8259
  4016.5217  4404.9624  4355.9199
  4351.1094  4759.8838  4688.9814

(16,.,.) = 
 -2930.4175 -3011.4478 -3000.5386
 -3059.1301 -3174.3608 -3151.3777
 -3191.6401 -3334.6868 -3298.0500

(17,.,.) = 
 -7591.8760 -7991.1987 -7891.5151
 -8712.9746 -9222.3174 -9120.1855
 -9416.0059 -9987.5156 -9863.9531

(18,.,.) = 
  1645.3270  1594.0520  1497.6713
  1834.0607  1754.6497  1647.7134
  1829.2026  1735.8453  1632.4326
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3688.2155761719	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #115: time = 0.48218700000001	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   6.4000e+02   6.4000e+02
        -inf         -inf   3.6078e+04   2.1317e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #116	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00006001/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1911.1027  -2152.2742  -2078.2256
  -2037.9844  -2271.8608  -2165.9666
  -1997.7478  -2188.9343  -2066.9966

(2,.,.) = 
   2861.9319   3027.3313   2918.4863
   3068.3550   3251.0989   3099.2029
   2962.0662   3112.8447   2946.6135

(3,.,.) = 
   3695.4341   4027.6375   4029.3074
   4530.3687   4949.0547   4943.7012
   4953.6016   5436.4722   5415.1641

(4,.,.) = 
   1057.6177   1179.2772   1157.7286
   1323.2551   1425.3163   1373.7013
   1438.1697   1493.6335   1401.2795

(5,.,.) = 
    751.5854    744.0738    665.8641
    737.9403    692.2877    586.2482
    754.5012    673.2387    565.0652

(6,.,.) = 
   1654.4017   1875.5818   1918.7950
   2029.7271   2340.3164   2385.0154
   2334.6038   2681.6633   2710.2539

(7,.,.) = 
  -2757.5803  -2931.6741  -2757.3076
  -2976.2725  -3130.0964  -2868.9626
  -2854.3279  -2933.5625  -2643.8132

(8,.,.) = 
   5777.4731   6192.9072   5953.8340
   6513.2949   6945.7383   6625.6128
   6778.6333   7157.2690   6788.3618

(9,.,.) = 
   2541.1565   3056.2007   3258.7651
   2927.0095   3456.4849   3587.2161
   3198.2327   3735.2998   3823.3264

(10,.,.) = 
  -3415.4844  -3376.3206  -3129.2971
  -3658.0747  -3625.8342  -3358.1899
  -3620.5620  -3579.2500  -3334.4919

(11,.,.) = 
    481.5886    641.4656    732.6232
    754.8037    944.8170   1032.2256
    844.8361   1081.2795   1171.6252

(12,.,.) = 
    448.2693    720.3706    954.5599
    517.2429    835.2490   1059.0151
    275.5191    592.5338    788.8590

(13,.,.) = 
  -2935.1882  -3105.2693  -3004.5422
  -2956.7781  -3114.1492  -3001.0940
  -2890.8052  -3038.8416  -2899.0339

(14,.,.) = 
   5061.1045   5365.6392   5172.1470
   5335.0601   5629.9707   5393.4282
   5279.6279   5597.5952   5330.3491

(15,.,.) = 
   3453.2209   3747.2214   3723.5024
   4023.3298   4414.4624   4367.3091
   4357.6270   4769.1270   4699.9619

(16,.,.) = 
  -2933.0601  -3015.7690  -3005.7883
  -3063.1292  -3179.9490  -3157.5056
  -3195.3884  -3340.3254  -3304.3701

(17,.,.) = 
  -7602.6826  -8006.2778  -7909.4434
  -8724.9170  -9238.9014  -9140.1611
  -9426.9092 -10003.2588  -9882.8145

(18,.,.) = 
   1645.1431   1594.8657   1499.5553
   1834.1233   1755.6261   1649.7502
   1829.4414   1737.0511   1634.7603
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3695.4340820312	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #116: time = 0.609398	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2317e+04   4.2821e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #117	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00010000/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1920
 1920
[torch.LongStorage of size 3]

x_start = 1 / y_start = 421	
img_means:size() vs img:size():	
    3
 1080
 1920
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.55555555555556	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
 1080
 1920
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.55555555555556	
proposal_im_detect: scaled_img_size:	
    2
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1906.5626 -2145.3657 -2069.4771
 -2032.3633 -2263.8684 -2155.6943
 -1992.2220 -2181.0000 -2057.0911

(2,.,.) = 
  2855.6121  3017.9907  2906.3696
  3061.0613  3240.3821  3086.0681
  2955.4490  3103.1433  2934.3484

(3,.,.) = 
  3672.1243  3998.7800  3996.9294
  4505.8906  4918.2725  4908.7065
  4931.4268  5408.2769  5382.7764

(4,.,.) = 
  1049.0487  1168.5024  1145.4125
  1313.3656  1413.4987  1360.4087
  1429.3644  1482.7794  1389.1530

(5,.,.) = 
   746.4151   737.3046   658.3710
   733.2919   685.9821   579.2687
   750.6999   668.2744   559.1813

(6,.,.) = 
  1642.1000  1860.4312  1901.7161
  2017.6744  2325.0920  2367.3279
  2323.0234  2667.0642  2693.4395

(7,.,.) = 
 -2748.4883 -2918.7188 -2741.1506
 -2966.4717 -3116.3354 -2852.3384
 -2846.0525 -2921.8513 -2629.4431

(8,.,.) = 
  5750.9712  6159.1416  5914.4248
  6485.9468  6910.7710  6585.1074
  6754.5513  7126.0137  6751.7183

(9,.,.) = 
  2525.9307  3037.1616  3236.4773
  2910.9421  3436.3853  3563.5801
  3184.4731  3717.5034  3801.9209

(10,.,.) = 
 -3404.1340 -3361.7239 -3111.3945
 -3646.5308 -3610.8889 -3340.2803
 -3609.8210 -3565.2986 -3317.4883

(11,.,.) = 
   478.5654   637.9633   728.9745
   751.3899   940.7570  1027.7515
   842.1747  1077.8092  1167.5869

(12,.,.) = 
   447.4685   718.8910   952.6914
   515.3309   832.3645  1055.5420
   273.0537   589.2257   784.6789

(13,.,.) = 
 -2929.8259 -3097.0940 -2994.0867
 -2952.1599 -3106.3013 -2990.5435
 -2886.5691 -3031.6265 -2889.4402

(14,.,.) = 
  5046.5391  5345.9180  5148.5132
  5320.5176  5610.5869  5369.7515
  5266.1904  5579.2583  5307.7480

(15,.,.) = 
  3432.2698  3720.7495  3693.3506
  4002.1558  4387.5684  4336.1133
  4338.0269  4744.1138  4670.8965

(16,.,.) = 
 -2918.0342 -2997.4661 -2985.1108
 -3047.3582 -3160.9126 -3136.3696
 -3181.5415 -3322.8677 -3284.6233

(17,.,.) = 
 -7559.4536 -7953.5947 -7849.6934
 -8680.9668 -9184.7471 -9077.8799
 -9386.6475 -9952.6143 -9824.2188

(18,.,.) = 
  1639.0693  1587.0856  1490.4055
  1827.1809  1747.1260  1639.9363
  1822.6385  1728.9419  1625.3228
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3672.1242675781	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #117: time = 0.795142	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.9200e+03   1.9200e+03
        -inf         -inf   1.0803e+05   6.3910e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #118	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0001/ILSVRC2015_train_00196000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1912.1884 -2152.0898 -2076.1716
 -2038.6327 -2271.0354 -2163.0542
 -1997.4799 -2186.9397 -2063.0552

(2,.,.) = 
  2862.6235  3026.1748  2914.9287
  3068.8401  3249.5332  3095.3611
  2962.2664  3110.9739  2942.3918

(3,.,.) = 
  3686.6865  4015.4417  4014.4102
  4521.5278  4935.9873  4927.2881
  4945.6353  5424.4883  5399.7427

(4,.,.) = 
  1054.5610  1174.8514  1152.3478
  1319.0956  1419.7814  1367.2108
  1433.8168  1487.5571  1394.2156

(5,.,.) = 
   750.6609   742.0864   663.0690
   737.0496   690.2315   583.5551
   753.5095   671.2765   562.3614

(6,.,.) = 
  1649.4127  1869.1045  1911.1512
  2025.1814  2334.2354  2377.3513
  2330.8518  2676.4077  2703.4495

(7,.,.) = 
 -2756.6157 -2928.4692 -2751.6501
 -2975.1992 -3126.7749 -2863.3933
 -2853.3967 -2930.3740 -2638.4458

(8,.,.) = 
  5770.7920  6181.7397  5937.9839
  6505.9404  6933.3745  6608.5996
  6771.1660  7144.6992  6771.1953

(9,.,.) = 
  2535.6045  3048.6621  3249.4456
  2921.1997  3448.3374  3577.0037
  3192.8254  3727.4260  3813.1438

(10,.,.) = 
 -3411.8325 -3370.0747 -3120.6382
 -3653.8359 -3619.1699 -3349.1257
 -3616.4163 -3572.7551 -3325.7192

(11,.,.) = 
   479.8215   639.5362   730.7018
   752.8503   942.5139  1029.7826
   843.6063  1079.6630  1169.6930

(12,.,.) = 
   447.8125   719.9760   954.4262
   516.5418   834.5723  1058.3184
   274.3601   591.3674   787.3587

(13,.,.) = 
 -2936.5479 -3104.7749 -3002.1626
 -2958.6990 -3113.9426 -2998.7312
 -2891.9768 -3037.9666 -2896.1653

(14,.,.) = 
  5059.6294  5360.8428  5164.0615
  5332.9893  5624.5347  5384.4614
  5276.4658  5590.9014  5320.0273

(15,.,.) = 
  3445.9446  3736.4666  3709.9211
  4015.5955  4403.0190  4352.5698
  4349.8486  4757.5273  4685.1289

(16,.,.) = 
 -2927.5874 -3007.9368 -2996.1804
 -3056.9895 -3171.4282 -3147.3945
 -3189.3682 -3331.6909 -3293.9451

(17,.,.) = 
 -7588.0132 -7984.9653 -7882.8345
 -8708.6182 -9215.2568 -9110.3594
 -9410.7002 -9979.4873 -9852.8906

(18,.,.) = 
  1642.7695  1591.2422  1494.9504
  1831.5253  1751.8890  1645.2111
  1826.9382  1733.5182  1630.4319
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3686.6865234375	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #118: time = 0.60292699999999	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2120e+04   4.2668e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #119	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00005000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  576
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 353	
img_means:size() vs img:size():	
    3
  576
 1280
[torch.LongStorage of size 3]

    3
  576
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.0416666666667	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1333
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x164
  2 : CudaTensor - size: 18x72x164
  3 : CudaTensor - size: 18x70x162
  4 : CudaTensor - size: 18x68x160
  5 : CudaTensor - size: 256x74x166
}
proposal_im_deteect: img_blob size:     3
  600
 1333
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  576
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.0416666666667	
proposal_im_detect: scaled_img_size:	
    3
  600
 1333
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1906.0814 -2144.3230 -2068.5220
 -2029.8837 -2260.8521 -2153.0737
 -1987.7914 -2176.0920 -2052.7297

(2,.,.) = 
  2853.4817  3016.0176  2904.3345
  3057.2053  3236.2598  3082.1619
  2949.6689  3096.8679  2928.6250

(3,.,.) = 
  3658.1899  3983.6528  3982.6177
  4487.9419  4898.6978  4890.0415
  4910.7515  5386.0718  5361.8901

(4,.,.) = 
  1042.8397  1161.1940  1138.6351
  1305.8118  1404.8127  1352.3385
  1420.9353  1473.4930  1380.9359

(5,.,.) = 
   744.0558   735.4695   657.3873
   730.2725   683.2559   577.5142
   747.2191   664.8238   556.1675

(6,.,.) = 
  1632.6379  1850.0599  1891.8660
  2006.6892  2313.3013  2356.3064
  2312.2495  2655.1797  2682.4165

(7,.,.) = 
 -2739.5845 -2910.2021 -2733.5032
 -2956.4241 -3106.6055 -2844.1611
 -2835.1572 -2911.2344 -2620.6716

(8,.,.) = 
  5729.8794  6137.3096  5894.6475
  6460.4053  6884.4482  6561.5952
  6726.1792  7096.8716  6726.0659

(9,.,.) = 
  2514.2688  3023.4075  3222.0312
  2895.6794  3418.7268  3545.9578
  3167.6338  3698.8213  3783.8840

(10,.,.) = 
 -3397.6924 -3355.7756 -3106.1838
 -3637.9717 -3603.0605 -3333.7085
 -3599.7029 -3555.7185 -3309.2803

(11,.,.) = 
   473.6490   632.3522   723.8680
   747.0497   935.7333  1022.9334
   837.9524  1072.5859  1162.2040

(12,.,.) = 
   448.6130   719.1705   952.6257
   516.6458   832.4891  1055.1376
   273.4470   588.1956   782.9785

(13,.,.) = 
 -2923.9329 -3091.4932 -2988.4321
 -2943.6392 -3097.9089 -2982.1584
 -2876.5349 -3021.8535 -2880.2859

(14,.,.) = 
  5034.1699  5333.5356  5136.9888
  5304.4727  5594.4048  5354.6138
  5247.2642  5560.0581  5290.1177

(15,.,.) = 
  3416.3403  3703.4675  3677.1147
  3982.9348  4366.7500  4316.8672
  4317.4868  4721.8950  4650.6304

(16,.,.) = 
 -2911.1396 -2990.0864 -2977.5630
 -3036.7791 -3149.8899 -3125.4683
 -3168.2014 -3308.7153 -3270.8425

(17,.,.) = 
 -7532.1499 -7924.9048 -7822.8359
 -8645.8848 -9147.6357 -9042.5957
 -9346.7061 -9910.8516 -9784.9023

(18,.,.) = 
  1636.2418  1584.8855  1488.6060
  1823.5448  1744.2708  1637.4984
  1817.6602  1724.3857  1621.2352
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 162
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 34020
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 162
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 162
[torch.LongStorage of size 2]

shift_y size:	
  70
 162
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
     3
 11340
     4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 34020
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 34020
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 34020
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  34020
[torch.LongStorage of size 1]
	
  first line: 3658.1899414062	
(fast bbox transform) src_w size:  34020
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 34020
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 34020
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 34020
     4
[torch.LongStorage of size 2]

scores size:	
 34020
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 34020
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 34020
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 34020
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 90720
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 22680
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 22680
[torch.LongStorage of size 1]

test img #119: time = 0.66215799999999	
(proposal_test:boxes_filter) boxes & scores size:	
 22680
     4
[torch.LongStorage of size 2]

 22680
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 3
[torch.LongStorage of size 1]

 1947
    3
    4
[torch.LongTensor of size 3]

mask size:	
 22680
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 12
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
  1.0000e+00   1.0000e+00   5.7600e+02   5.7600e+02
        -inf         -inf   5.7433e+04   3.3825e+04
[torch.CudaTensor of size 3x4]

(proposal_test:boxes_filter) boxes size returned:	
 3
 4
[torch.LongStorage of size 2]

img #120	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00100000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 480
 480
[torch.LongStorage of size 3]

x_start = 1 / y_start = 61	
img_means:size() vs img:size():	
   3
 360
 480
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6666666666667	
(orep_img_for_blob) img size after scaling:	
   3
 600
 800
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x97
  2 : CudaTensor - size: 18x72x97
  3 : CudaTensor - size: 18x70x95
  4 : CudaTensor - size: 18x68x93
  5 : CudaTensor - size: 256x74x99
}
proposal_im_deteect: img_blob size:    3
 600
 800
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 360
 480
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6666666666667	
proposal_im_detect: scaled_img_size:	
   5
 600
 800
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1915.9087  -2157.3147  -2081.4097
  -2044.9347  -2278.8198  -2170.8792
  -2005.9452  -2196.9375  -2072.9521

(2,.,.) = 
   2869.8823   3034.7629   2924.3838
   3078.9241   3261.4392   3107.6042
   2974.1995   3124.6875   2956.5210

(3,.,.) = 
   3718.3218   4050.7141   4049.6375
   4561.5063   4981.4043   4973.5415
   4990.4224   5475.8677   5452.0249

(4,.,.) = 
   1067.7047   1189.9507   1167.1975
   1333.7931   1436.7185   1383.9269
   1449.9789   1506.0221   1411.9078

(5,.,.) = 
    756.6649    747.8048    667.8924
    743.7811    697.0969    589.6074
    760.6793    678.8897    569.9763

(6,.,.) = 
   1670.9863   1893.6357   1935.6578
   2051.2822   2363.5247   2406.8716
   2357.9387   2707.0850   2734.4033

(7,.,.) = 
  -2775.8579  -2949.5806  -2772.9438
  -2997.6687  -3151.2874  -2887.2932
  -2876.3555  -2954.9080  -2662.0806

(8,.,.) = 
   5814.9883   6229.8174   5985.0337
   6559.1836   6991.4565   6665.6445
   6829.5674   7208.6230   6833.8179

(9,.,.) = 
   2559.9919   3078.0710   3280.9023
   2951.5352   3483.9949   3614.1611
   3225.6694   3765.4902   3852.2749

(10,.,.) = 
  -3423.3735  -3383.0381  -3134.5969
  -3670.5432  -3637.5745  -3367.6812
  -3638.4944  -3596.5928  -3349.8174

(11,.,.) = 
    488.9976    650.0410    740.4462
    762.6572    953.7822   1040.9554
    853.7852   1092.0834   1182.7728

(12,.,.) = 
    449.2888    723.6621    958.5622
    517.9077    838.3152   1062.6865
    275.5828    594.9377    791.8158

(13,.,.) = 
  -2947.3691  -3116.5652  -3014.9109
  -2973.7783  -3130.4021  -3016.4192
  -2910.0679  -3057.1604  -2915.4485

(14,.,.) = 
   5083.7324   5387.4004   5190.8740
   5364.0815   5657.8921   5418.4302
   5313.5029   5630.8936   5360.0513

(15,.,.) = 
   3479.6807   3774.1960   3747.1365
   4056.4795   4448.7949   4398.1479
   4394.7397   4808.0806   4735.2451

(16,.,.) = 
  -2942.6245  -3024.4514  -3013.5303
  -3077.9792  -3194.0791  -3170.7656
  -3215.9841  -3361.2578  -3324.3970

(17,.,.) = 
  -7648.8682  -8050.6641  -7948.2725
  -8782.7012  -9297.0693  -9193.2529
  -9495.2949 -10073.4463  -9948.4316

(18,.,.) = 
   1648.5447   1597.3077   1501.4281
   1840.1439   1760.6962   1654.5386
   1838.6852   1745.6683   1642.9927
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 95
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 19950
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 95
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 95
[torch.LongStorage of size 2]

shift_y size:	
 70
 95
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6650
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 19950
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  19950
[torch.LongStorage of size 1]
	
  first line: 3718.3217773438	
(fast bbox transform) src_w size:  19950
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 19950
     4
[torch.LongStorage of size 2]

scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 19950
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 53200
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13300
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13300
[torch.LongStorage of size 1]

test img #120: time = 0.36855799999999	
(proposal_test:boxes_filter) boxes & scores size:	
 13300
     4
[torch.LongStorage of size 2]

 13300
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 953
   3
[torch.LongTensor of size 2]

mask size:	
 13300
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   4.8000e+02   4.8000e+02
        -inf         -inf   3.6425e+04   2.1484e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #121	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00034005/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1909.4418 -2148.8359 -2072.8938
 -2035.2665 -2267.0510 -2158.9373
 -1994.1538 -2182.8948 -2059.0398

(2,.,.) = 
  2858.8679  3021.7407  2910.1450
  3064.2822  3243.9583  3089.6406
  2957.8782  3105.4592  2936.6074

(3,.,.) = 
  3673.9290  4002.2571  4002.1655
  4506.3618  4920.1587  4912.7163
  4929.6250  5407.8208  5384.7773

(4,.,.) = 
  1049.6427  1169.5898  1147.4485
  1313.3121  1414.0208  1361.9344
  1428.2026  1482.0132  1389.3262

(5,.,.) = 
   746.6729   738.1018   659.4343
   732.8825   685.8454   579.4531
   749.4590   667.0141   558.0524

(6,.,.) = 
  1641.7930  1860.4379  1902.7229
  2016.0803  2323.9290  2367.3196
  2320.6648  2665.0657  2692.4912

(7,.,.) = 
 -2749.6509 -2920.5012 -2743.2515
 -2967.2512 -3117.6218 -2853.9468
 -2845.4497 -2921.2166 -2628.7805

(8,.,.) = 
  5754.6724  6164.9414  5921.9946
  6487.9854  6914.7002  6591.2290
  6753.2964  7126.1733  6754.0591

(9,.,.) = 
  2527.0171  3038.8552  3239.2634
  2911.0181  3437.0681  3565.5662
  3182.6194  3716.2751  3802.1140

(10,.,.) = 
 -3406.6375 -3364.4536 -3114.7966
 -3648.2844 -3613.0364 -3342.9248
 -3610.7769 -3566.3904 -3319.2151

(11,.,.) = 
   477.7474   637.2213   728.8553
   750.5390   940.1863  1027.8623
   841.5773  1077.4331  1167.8088

(12,.,.) = 
   447.2459   718.5009   952.6991
   515.2692   832.2123  1055.6477
   272.4493   588.2432   783.8400

(13,.,.) = 
 -2932.3062 -3099.9197 -2997.0007
 -2954.4805 -3108.7266 -2992.9907
 -2887.7295 -3032.8457 -2890.7769

(14,.,.) = 
  5050.5483  5351.0894  5154.4810
  5323.6108  5614.5581  5374.5439
  5267.1040  5580.8975  5310.2607

(15,.,.) = 
  3433.6443  3723.3152  3697.4802
  4001.6318  4388.1162  4338.6514
  4335.1602  4742.0537  4670.9346

(16,.,.) = 
 -2919.9561 -3000.1680 -2988.8455
 -3047.9155 -3162.3569 -3139.1184
 -3180.0413 -3322.2754 -3285.5469

(17,.,.) = 
 -7564.0088 -7960.6543 -7860.1968
 -8681.4365 -9187.8242 -9084.8291
 -9382.5039 -9951.1406 -9827.0957

(18,.,.) = 
  1639.9633  1588.5038  1492.0433
  1828.0162  1748.5730  1641.5941
  1823.0110  1729.7101  1626.2460
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3673.9289550781	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #121: time = 0.63370400000001	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1947e+04   4.2521e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #122	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00010002/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1920
 1920
[torch.LongStorage of size 3]

x_start = 1 / y_start = 421	
img_means:size() vs img:size():	
    3
 1080
 1920
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.55555555555556	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
 1080
 1920
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.55555555555556	
proposal_im_detect: scaled_img_size:	
    2
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1909.1322 -2148.1960 -2072.2065
 -2034.7013 -2266.2024 -2158.0198
 -1993.5049 -2181.9382 -2058.0261

(2,.,.) = 
  2857.9861  3020.7151  2909.0618
  3063.0728  3242.5515  3088.2100
  2956.5134  3103.8335  2934.9836

(3,.,.) = 
  3670.5029  3998.5918  3998.6807
  4501.9336  4915.2983  4907.9897
  4924.6499  5402.2681  5379.2935

(4,.,.) = 
  1047.9805  1167.7739  1145.5981
  1311.5380  1412.0396  1359.9366
  1426.4110  1480.0854  1387.4725

(5,.,.) = 
   745.8198   737.4297   659.0923
   732.0306   685.1528   579.0643
   748.7562   666.4089   557.5532

(6,.,.) = 
  1639.7081  1858.2725  1900.6349
  2013.6249  2321.3643  2364.8005
  2317.9165  2662.1799  2689.6606

(7,.,.) = 
 -2747.6035 -2918.3660 -2741.2512
 -2964.9619 -3115.1763 -2851.7778
 -2843.3381 -2919.0129 -2626.9192

(8,.,.) = 
  5749.1826  6159.1548  5916.6187
  6481.6460  6907.9893  6584.8882
  6746.9170  7119.3403  6747.5825

(9,.,.) = 
  2524.5837  3035.7576  3235.8550
  2907.7363  3433.0381  3561.3616
  3179.1145  3712.0830  3797.8313

(10,.,.) = 
 -3404.9146 -3362.8420 -3113.4578
 -3646.0901 -3610.9363 -3341.2537
 -3608.2412 -3563.8877 -3317.0483

(11,.,.) = 
   476.3983   635.6081   727.2761
   749.3613   938.6789  1026.3020
   840.2896  1075.7114  1165.9880

(12,.,.) = 
   447.0823   717.9864   951.9777
   515.0760   831.6472  1054.9393
   272.0930   587.5438   783.1213

(13,.,.) = 
 -2930.8623 -3098.1926 -2995.1365
 -2952.4561 -3106.3401 -2990.4417
 -2885.5994 -3030.3816 -2888.2378

(14,.,.) = 
  5047.0654  5347.1235  5150.6792
  5319.4756  5609.8730  5370.0181
  5262.7900  5575.9346  5305.5054

(15,.,.) = 
  3429.7432  3719.1541  3693.5256
  3997.0874  4383.2173  4333.9087
  4330.5054  4736.9595  4665.9604

(16,.,.) = 
 -2917.9644 -2998.0142 -2986.7969
 -3045.2771 -3159.4761 -3136.3303
 -3177.0332 -3318.7932 -3282.0593

(17,.,.) = 
 -7556.2490 -7952.6772 -7852.7075
 -8672.2031 -9178.0293 -9075.4268
 -9372.5166 -9940.2822 -9816.4912

(18,.,.) = 
  1639.0815  1587.7885  1491.5624
  1826.8634  1747.5745  1640.8058
  1821.5790  1728.3479  1625.0598
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3670.5029296875	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #122: time = 0.77623	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.9200e+03   1.9200e+03
        -inf         -inf   1.0784e+05   6.3746e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #123	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00014000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1920
 1920
[torch.LongStorage of size 3]

x_start = 1 / y_start = 421	
img_means:size() vs img:size():	
    3
 1080
 1920
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.55555555555556	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
 1080
 1920
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.55555555555556	
proposal_im_detect: scaled_img_size:	
    2
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1911.1523 -2150.8179 -2074.7292
 -2037.5280 -2269.6299 -2161.3718
 -1996.8307 -2185.9116 -2061.8499

(2,.,.) = 
  2861.5925  3024.6013  2912.9246
  3067.6978  3247.6287  3093.1169
  2961.5820  3109.5132  2940.4541

(3,.,.) = 
  3679.9431  4008.6204  4008.1653
  4513.6724  4927.8726  4919.9868
  4937.8945  5416.5449  5392.8711

(4,.,.) = 
  1051.4801  1171.6514  1149.3761
  1315.7257  1416.5582  1364.2396
  1431.1467  1485.0989  1392.0482

(5,.,.) = 
   747.9688   739.3193   660.4478
   734.3765   687.2569   580.6441
   751.1700   668.6765   559.6121

(6,.,.) = 
  1645.0679  1863.9451  1906.0526
  2020.1073  2328.2490  2371.4368
  2325.1775  2670.0466  2697.2085

(7,.,.) = 
 -2753.7056 -2924.7852 -2747.3569
 -2972.0566 -3122.7109 -2858.6299
 -2850.5215 -2926.5444 -2633.7634

(8,.,.) = 
  5763.3218  6173.8887  5930.3154
  6498.2964  6925.2900  6600.8379
  6764.7944  7137.9966  6764.7246

(9,.,.) = 
  2531.6372  3044.1140  3244.5813
  2916.7808  3443.4602  3571.8086
  3189.1216  3723.4993  3809.0610

(10,.,.) = 
 -3410.8540 -3368.5024 -3118.4424
 -3653.2847 -3617.8389 -3347.1604
 -3616.1958 -3571.6768 -3323.9653

(11,.,.) = 
   478.7439   638.3775   729.9136
   751.7821   941.5497  1029.1068
   842.9529  1079.0490  1169.2883

(12,.,.) = 
   447.4158   719.0184   953.3635
   515.7220   833.0952  1056.6792
   273.0945   589.3817   785.1296

(13,.,.) = 
 -2935.6821 -3103.3262 -3000.1611
 -2958.3518 -3112.7217 -2996.7764
 -2891.9517 -3037.2219 -2894.8450

(14,.,.) = 
  5056.7612  5357.3906  5160.2817
  5330.9316  5621.9497  5381.3564
  5275.2280  5589.1934  5317.8467

(15,.,.) = 
  3439.5745  3729.6006  3703.3889
  4008.8347  4395.6846  4345.6675
  4343.4009  4750.7554  4678.9014

(16,.,.) = 
 -2924.1077 -3004.3198 -2992.7070
 -3053.0422 -3167.4568 -3143.8098
 -3186.0239 -3328.2979 -3291.0896

(17,.,.) = 
 -7575.5356 -7972.3027 -7870.9634
 -8695.4268 -9201.8965 -9097.7988
 -9398.6660 -9967.4268 -9841.9834

(18,.,.) = 
  1641.9198  1590.3243  1493.7489
  1830.3583  1750.7294  1643.6125
  1825.6188  1732.0956  1628.5774
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3679.9431152344	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #123: time = 0.75398299999999	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.9200e+03   1.9200e+03
        -inf         -inf   1.0822e+05   6.3984e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #124	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00017004/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1916.3002  -2156.6233  -2080.5176
  -2042.9513  -2275.7778  -2167.5193
  -2001.9888  -2191.8669  -2067.6780

(2,.,.) = 
   2869.0586   3032.6536   2920.9563
   3075.5894   3256.3083   3101.5901
   2968.8323   3117.5374   2948.4395

(3,.,.) = 
   3694.5234   4024.3574   4023.7549
   4530.3315   4946.2148   4938.2139
   4954.4971   5434.9214   5411.1987

(4,.,.) = 
   1055.9584   1176.7538   1154.4830
   1321.1089   1422.3021   1369.9463
   1436.2999   1490.4720   1397.3529

(5,.,.) = 
    751.4735    743.0177    663.9662
    737.6255    690.7800    583.9749
    754.1085    671.7872    562.5988

(6,.,.) = 
   1652.2305   1872.2441   1914.4910
   2028.0665   2337.6272   2381.0249
   2333.2410   2679.3767   2706.8826

(7,.,.) = 
  -2761.4653  -2933.5576  -2756.2341
  -2979.9844  -3131.6741  -2867.5432
  -2857.3413  -2934.3083  -2641.6257

(8,.,.) = 
   5782.1909   6194.4961   5950.8140
   6518.4106   6947.4478   6622.6982
   6783.8540   7159.0078   6785.6816

(9,.,.) = 
   2540.8613   3054.9844   3256.1824
   2926.5798   3454.9248   3584.0532
   3198.3362   3734.2007   3820.5271

(10,.,.) = 
  -3420.9734  -3378.9463  -3128.6328
  -3663.6865  -3628.6536  -3357.7661
  -3625.8774  -3581.9370  -3334.1316

(11,.,.) = 
    480.3051    640.4075    732.1805
    754.1523    944.3716   1032.1379
    844.9367   1081.6420   1172.2437

(12,.,.) = 
    447.8111    720.1691    955.1696
    516.6472    834.8512   1059.0515
    273.6030    590.6937    787.2025

(13,.,.) = 
  -2943.1111  -3111.4387  -3008.1721
  -2965.0864  -3120.4104  -3004.5828
  -2898.1277  -3044.3445  -2902.0496

(14,.,.) = 
   5070.8330   5372.5459   5175.2261
   5344.9019   5637.1250   5396.5186
   5288.2217   5603.7334   5332.4395

(15,.,.) = 
   3452.5525   3743.9973   3717.9375
   4022.9419   4411.5967   4361.8159
   4357.3809   4766.4756   4694.8604

(16,.,.) = 
  -2934.6321  -3015.1804  -3003.4375
  -3063.8867  -3178.7415  -3154.9019
  -3196.4883  -3339.4062  -3301.9578

(17,.,.) = 
  -7603.9473  -8002.5674  -7900.9238
  -8726.4697  -9235.2080  -9131.1514
  -9429.5156 -10000.7246  -9875.3379

(18,.,.) = 
   1646.8234   1595.2229   1498.5918
   1835.8073   1756.0503   1648.8629
   1830.9135   1737.3801   1633.8051
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3694.5234375	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #124: time = 0.5547	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2250e+04   4.2731e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #125	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00025030/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1911.8303 -2151.4163 -2075.1497
 -2037.5413 -2269.5925 -2161.1877
 -1996.0220 -2184.9946 -2060.7805

(2,.,.) = 
  2862.1794  3025.1609  2913.1663
  3067.5005  3247.3657  3092.5806
  2960.4368  3108.2000  2938.9653

(3,.,.) = 
  3681.7234  4009.8403  4008.6892
  4514.2188  4927.9507  4919.4287
  4936.0967  5414.3511  5390.2744

(4,.,.) = 
  1052.3035  1172.2428  1149.7296
  1316.0248  1416.5503  1364.1179
  1430.2689  1483.8994  1391.0038

(5,.,.) = 
   748.7388   740.0103   661.1920
   734.3728   687.3399   580.9273
   750.5103   668.0030   559.1001

(6,.,.) = 
  1645.6962  1864.7617  1906.6123
  2020.1355  2328.3748  2371.3101
  2324.4670  2669.0466  2696.0171

(7,.,.) = 
 -2753.5322 -2924.9373 -2747.7737
 -2971.2395 -3122.0774 -2858.3347
 -2848.6978 -2924.8230 -2632.4055

(8,.,.) = 
  5763.5991  6174.1323  5930.3179
  6496.3569  6923.3491  6598.9756
  6760.0688  7133.1221  6760.3896

(9,.,.) = 
  2531.8464  3044.2646  3244.7192
  2916.0312  3442.5798  3570.9600
  3187.0139  3721.0459  3806.5537

(10,.,.) = 
 -3410.5066 -3368.4946 -3118.6301
 -3651.9329 -3616.9199 -3346.5039
 -3613.8845 -3569.7454 -3322.4043

(11,.,.) = 
   478.2626   637.7220   729.1594
   751.3622   940.9166  1028.5035
   842.1558  1078.0175  1168.3256

(12,.,.) = 
   447.9118   719.3456   953.6498
   516.4515   833.6423  1057.1062
   273.3688   589.3375   784.9254

(13,.,.) = 
 -2935.4480 -3103.3987 -3000.2341
 -2957.0378 -3111.7341 -2995.8672
 -2890.0002 -3035.3879 -2893.1541

(14,.,.) = 
  5056.1919  5357.0005  5159.7583
  5328.6211  5619.7568  5379.3584
  5271.3984  5585.4116  5314.4028

(15,.,.) = 
  3440.1897  3730.1526  3703.5896
  4007.9890  4394.7827  4344.5259
  4340.7627  4747.8179  4675.9912

(16,.,.) = 
 -2924.8594 -3004.6328 -2992.5837
 -3052.4500 -3166.5166 -3142.6323
 -3183.9456 -3325.9695 -3288.6436

(17,.,.) = 
 -7577.9839 -7974.3633 -7871.8477
 -8694.8584 -9201.0771 -9096.2422
 -9393.8359 -9962.3643 -9836.7568

(18,.,.) = 
  1641.9567  1590.3101  1493.7858
  1830.0107  1750.3092  1643.2847
  1824.6816  1731.2087  1627.7405
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3681.7233886719	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #125: time = 0.53194499999999	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2005e+04   4.2568e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #126	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00019000/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 480
 480
[torch.LongStorage of size 3]

x_start = 1 / y_start = 61	
img_means:size() vs img:size():	
   3
 360
 480
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6666666666667	
(orep_img_for_blob) img size after scaling:	
   3
 600
 800
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x97
  2 : CudaTensor - size: 18x72x97
  3 : CudaTensor - size: 18x70x95
  4 : CudaTensor - size: 18x68x93
  5 : CudaTensor - size: 256x74x99
}
proposal_im_deteect: img_blob size:    3
 600
 800
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 360
 480
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6666666666667	
proposal_im_detect: scaled_img_size:	
   5
 600
 800
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1924.0579  -2167.0205  -2091.6311
  -2053.9309  -2289.4216  -2182.1055
  -2014.5897  -2207.1589  -2083.4355

(2,.,.) = 
   2880.9456   3047.2795   2937.7839
   3091.0315   3275.5288   3122.2278
   2985.4871   3138.0071   2970.3796

(3,.,.) = 
   3742.9817   4077.3975   4076.1650
   4589.2759   5011.3579   5002.7744
   5017.7139   5505.0220   5479.7100

(4,.,.) = 
   1076.5712   1199.9586   1177.2666
   1344.6080   1448.0524   1395.1477
   1459.9960   1516.1000   1421.4862

(5,.,.) = 
    763.9680    755.4541    675.1259
    750.7487    704.4996    596.5770
    766.8903    685.1677    576.0857

(6,.,.) = 
   1682.6184   1907.1304   1949.0520
   2063.8818   2378.3623   2421.4524
   2371.8684   2723.4653   2750.3875

(7,.,.) = 
  -2788.4456  -2963.4875  -2787.3979
  -3010.8728  -3166.1121  -2902.2112
  -2888.4351  -2968.5532  -2676.0205

(8,.,.) = 
   5846.6787   6263.7236   6018.8340
   6592.2759   7026.7666   6699.6455
   6859.9727   7240.8081   6864.2783

(9,.,.) = 
   2575.2903   3095.3425   3299.2751
   2969.0583   3503.3669   3634.1707
   3241.8909   3783.2998   3870.3398

(10,.,.) = 
  -3439.0769  -3399.1160  -3150.7107
  -3685.6042  -3653.0559  -3382.7144
  -3651.3491  -3609.9883  -3362.9712

(11,.,.) = 
    491.5120    653.3326    743.6729
    765.5766    957.2682   1044.3372
    855.9661   1094.9249   1185.3281

(12,.,.) = 
    449.5055    725.3494    961.4133
    519.2532    841.4262   1067.2140
    277.5144    598.8516    797.2979

(13,.,.) = 
  -2957.9028  -3128.1538  -3027.0452
  -2983.4307  -3141.3816  -3028.0083
  -2918.5273  -3066.9636  -2925.6526

(14,.,.) = 
   5105.2476   5410.7788   5214.5718
   5384.7256   5679.9922   5440.6284
   5331.6763   5650.4683   5379.4507

(15,.,.) = 
   3502.1692   3798.8730   3771.7751
   4080.2061   4474.6689   4423.3789
   4417.7993   4832.8335   4758.7441

(16,.,.) = 
  -2960.9363  -3043.6707  -3032.6086
  -3097.4231  -3214.0171  -3189.8364
  -3233.4473  -3378.9128  -3340.7405

(17,.,.) = 
  -7696.2598  -8100.8188  -7998.1909
  -8833.6768  -9350.2139  -9245.3848
  -9544.2207 -10124.0137  -9996.4092

(18,.,.) = 
   1656.4814   1605.2383   1509.6954
   1848.4310   1768.7258   1662.9717
   1846.3169   1752.9617   1650.7118
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 95
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 19950
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 95
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 95
[torch.LongStorage of size 2]

shift_y size:	
 70
 95
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6650
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 19950
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  19950
[torch.LongStorage of size 1]
	
  first line: 3742.9816894531	
(fast bbox transform) src_w size:  19950
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 19950
     4
[torch.LongStorage of size 2]

scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 19950
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 53200
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13300
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13300
[torch.LongStorage of size 1]

test img #126: time = 0.344155	
(proposal_test:boxes_filter) boxes & scores size:	
 13300
     4
[torch.LongStorage of size 2]

 13300
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 953
   3
[torch.LongTensor of size 2]

mask size:	
 13300
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   4.8000e+02   4.8000e+02
        -inf         -inf   3.6553e+04   2.1562e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #127	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00044002/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1901.6204 -2140.8296 -2066.3875
 -2026.5087 -2258.3167 -2152.0227
 -1985.3372 -2174.3210 -2052.5281

(2,.,.) = 
  2848.1013  3011.6504  2902.0891
  3052.3945  3232.7168  3080.8137
  2945.9763  3094.5076  2928.2029

(3,.,.) = 
  3657.0737  3986.9482  3990.7615
  4487.1113  4902.8296  4899.9482
  4909.8647  5390.0254  5371.5698

(4,.,.) = 
  1045.3761  1165.7278  1144.6322
  1307.9514  1409.6731  1359.2158
  1423.2081  1478.0454  1387.0502

(5,.,.) = 
   742.1866   733.5455   656.2883
   728.4987   681.4042   576.3530
   744.6310   662.5408   555.2363

(6,.,.) = 
  1635.1749  1854.8474  1898.4189
  2008.4373  2317.0559  2362.2900
  2312.3440  2657.4399  2686.9473

(7,.,.) = 
 -2739.8713 -2911.5945 -2736.3250
 -2956.0596 -3107.7095 -2846.9546
 -2833.9885 -2911.4810 -2622.2075

(8,.,.) = 
  5731.1987  6143.1270  5905.1816
  6462.0967  6890.7666  6573.5947
  6726.7139  7101.9614  6736.5205

(9,.,.) = 
  2515.9802  3028.7424  3230.5068
  2898.4473  3425.8677  3556.4707
  3170.1733  3705.0239  3792.9624

(10,.,.) = 
 -3391.7410 -3352.2529 -3105.8782
 -3632.2856 -3599.8992 -3333.2173
 -3594.6694 -3553.2324 -3309.6772

(11,.,.) = 
   476.9441   636.6430   728.0737
   748.7928   938.7864  1026.4866
   839.9369  1075.7406  1166.1742

(12,.,.) = 
   449.0078   720.2518   953.7257
   516.8189   833.5170  1056.4906
   274.9196   590.2518   785.2586

(13,.,.) = 
 -2921.2500 -3089.9004 -2988.6521
 -2943.2148 -3098.5881 -2984.6909
 -2876.2378 -3022.4751 -2882.5269

(14,.,.) = 
  5031.4717  5333.7002  5140.5581
  5303.3896  5596.2832  5360.0010
  5246.5923  5562.6299  5296.0000

(15,.,.) = 
  3419.0413  3710.0818  3687.0154
  3985.5320  4373.3735  4327.3613
  4318.5874  4726.9741  4659.5732

(16,.,.) = 
 -2906.4443 -2988.0242 -2979.0793
 -3034.2080 -3150.1003 -3129.2566
 -3166.5012 -3310.3289 -3276.0991

(17,.,.) = 
 -7532.4863 -7932.3096 -7838.2031
 -8646.9795 -9157.1787 -9061.2832
 -9347.6777 -9920.4492 -9803.9912

(18,.,.) = 
  1633.6854  1583.1343  1488.4066
  1821.0222  1742.7893  1637.5828
  1815.6666  1723.7976  1622.2576
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3657.0737304688	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #127: time = 0.54610899999999	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1737e+04   4.2429e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #128	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0001/ILSVRC2015_train_00296000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1909.5619 -2148.7900 -2072.8601
 -2034.9564 -2266.5857 -2158.4351
 -1993.2438 -2181.6953 -2057.8037

(2,.,.) = 
  2859.7891  3022.3833  2910.3103
  3064.7529  3244.1392  3089.1865
  2957.6106  3105.0269  2935.4602

(3,.,.) = 
  3671.3442  3999.2292  3998.6550
  4503.1455  4916.2710  4908.1489
  4925.7290  5403.2241  5379.4863

(4,.,.) = 
  1048.5697  1168.3195  1146.0323
  1312.0386  1412.3909  1360.0845
  1426.9652  1480.2872  1387.2947

(5,.,.) = 
   746.0645   737.4138   658.6627
   732.0392   684.8278   578.3527
   748.2955   665.8399   556.8018

(6,.,.) = 
  1640.6444  1858.9087  1900.9338
  2014.5729  2322.0632  2365.1787
  2318.6582  2662.8574  2690.1697

(7,.,.) = 
 -2751.4741 -2922.0107 -2743.8086
 -2968.2830 -3118.3445 -2853.6836
 -2845.2896 -2920.9060 -2627.6748

(8,.,.) = 
  5753.6187  6163.0645  5918.8159
  6485.7310  6911.1694  6586.0933
  6749.6348  7121.2642  6747.6626

(9,.,.) = 
  2527.3342  3039.1965  3238.8286
  2910.6243  3436.7231  3564.3101
  3181.9607  3715.6848  3800.4541

(10,.,.) = 
 -3406.3672 -3363.8308 -3113.2034
 -3646.9138 -3611.1628 -3339.8567
 -3608.1689 -3563.2944 -3315.1030

(11,.,.) = 
   477.3855   636.6259   728.1233
   750.2297   939.6718  1027.2463
   841.5452  1077.4210  1167.5951

(12,.,.) = 
   449.6333   721.1337   955.2418
   517.9711   835.0452  1058.5730
   274.7941   590.7470   786.2390

(13,.,.) = 
 -2934.4324 -3101.9062 -2998.2036
 -2956.0364 -3110.2822 -2993.7390
 -2888.2209 -3033.2634 -2890.5308

(14,.,.) = 
  5052.2407  5352.0728  5154.2949
  5324.0542  5614.4102  5373.1279
  5265.8564  5579.1235  5307.1948

(15,.,.) = 
  3431.5034  3720.3333  3693.8818
  3998.9399  4384.3286  4333.9854
  4331.8198  4737.4614  4665.4565

(16,.,.) = 
 -2918.4749 -2998.1841 -2986.3630
 -3045.5337 -3159.5322 -3135.7200
 -3177.4583 -3319.1069 -3281.5635

(17,.,.) = 
 -7559.8755 -7955.3691 -7854.1113
 -8675.9912 -9180.5986 -9076.1162
 -9375.8564 -9942.4668 -9816.7324

(18,.,.) = 
  1640.0099  1588.4298  1491.6591
  1827.5272  1747.9519  1640.5870
  1821.8043  1728.5339  1624.6986
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3671.3442382812	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #128: time = 0.53059500000001	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1934e+04   4.2496e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #129	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00102005/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 360
 640
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 640
 640
[torch.LongStorage of size 3]

x_start = 1 / y_start = 141	
img_means:size() vs img:size():	
   3
 360
 640
[torch.LongStorage of size 3]

   3
 360
 640
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6666666666667	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 360
 640
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6666666666667	
proposal_im_detect: scaled_img_size:	
    5
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1900.9987 -2139.7673 -2063.9036
 -2027.5829 -2258.7339 -2150.9065
 -1987.4105 -2175.7383 -2052.1384

(2,.,.) = 
  2846.5410  3008.9841  2898.0647
  3052.2825  3231.8745  3078.2075
  2947.2080  3094.9260  2926.8904

(3,.,.) = 
  3669.3167  3996.7974  3995.6191
  4501.3403  4914.2861  4905.6279
  4924.5610  5401.8354  5377.2676

(4,.,.) = 
  1050.8662  1171.0537  1148.6241
  1313.9976  1414.9558  1362.6831
  1428.6467  1482.8043  1389.5792

(5,.,.) = 
   746.7642   737.8976   658.8217
   733.4504   686.4866   579.9143
   749.7443   667.7335   559.3061

(6,.,.) = 
  1643.7988  1862.5497  1904.1792
  2018.0790  2325.6609  2368.3240
  2321.9216  2666.1279  2692.7991

(7,.,.) = 
 -2745.2517 -2915.8560 -2739.3584
 -2963.1772 -3113.6211 -2850.8174
 -2842.1860 -2918.2822 -2626.8535

(8,.,.) = 
  5746.4927  6155.5264  5911.9424
  6479.6431  6905.1499  6581.1323
  6744.6826  7116.7798  6744.0923

(9,.,.) = 
  2525.7021  3036.8938  3237.0122
  2911.0647  3436.4180  3564.4763
  3181.9280  3714.5774  3799.7161

(10,.,.) = 
 -3392.4399 -3350.4470 -3102.0464
 -3634.2896 -3599.4651 -3330.2681
 -3598.7588 -3554.9651 -3308.7913

(11,.,.) = 
   479.6378   638.8679   729.3083
   750.6888   939.8503  1026.7318
   841.3827  1076.8308  1166.6399

(12,.,.) = 
   445.0861   716.2062   949.3431
   513.0371   829.8685  1052.4303
   272.2474   587.9356   782.8486

(13,.,.) = 
 -2922.2559 -3089.1665 -2986.9875
 -2946.3245 -3100.2852 -2985.6475
 -2880.6345 -3025.4392 -2884.1609

(14,.,.) = 
  5035.4067  5334.8706  5138.5845
  5309.4492  5599.2739  5360.0337
  5254.8115  5567.5229  5297.5249

(15,.,.) = 
  3432.1294  3721.7053  3694.8728
  4000.0693  4386.1436  4335.5425
  4333.0532  4739.4951  4666.9941

(16,.,.) = 
 -2911.0422 -2991.0166 -2979.5754
 -3041.4585 -3155.4329 -3131.9446
 -3174.7808 -3316.8726 -3279.9211

(17,.,.) = 
 -7552.6689 -7947.8408 -7845.7671
 -8670.0137 -9175.1006 -9070.5625
 -9370.8555 -9938.1738 -9812.3262

(18,.,.) = 
  1633.3824  1581.7893  1485.7292
  1821.5369  1742.0625  1635.8165
  1817.9546  1724.8723  1622.1764
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3669.3166503906	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #129: time = 0.427029	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   6.4000e+02   6.4000e+02
        -inf         -inf   3.5908e+04   2.1234e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #130	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00005003/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  576
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 353	
img_means:size() vs img:size():	
    3
  576
 1280
[torch.LongStorage of size 3]

    3
  576
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.0416666666667	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1333
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x164
  2 : CudaTensor - size: 18x72x164
  3 : CudaTensor - size: 18x70x162
  4 : CudaTensor - size: 18x68x160
  5 : CudaTensor - size: 256x74x166
}
proposal_im_deteect: img_blob size:     3
  600
 1333
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  576
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.0416666666667	
proposal_im_detect: scaled_img_size:	
    3
  600
 1333
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1903.4469 -2142.0740 -2066.8940
 -2028.2520 -2259.6526 -2152.6182
 -1987.1973 -2176.0046 -2053.1411

(2,.,.) = 
  2849.6868  3012.4263  2901.8530
  3053.8674  3233.3738  3080.0801
  2947.1279  3094.7722  2927.1877

(3,.,.) = 
  3665.9021  3993.0320  3992.4531
  4494.0366  4906.6172  4898.7725
  4914.2876  5390.8579  5367.4429

(4,.,.) = 
  1046.2705  1165.8219  1143.7295
  1309.7419  1409.7709  1357.8109
  1424.0844  1477.7695  1385.7391

(5,.,.) = 
   745.7314   737.5827   659.4495
   731.7465   685.3939   579.6109
   748.4910   666.6531   558.0682

(6,.,.) = 
  1637.9156  1856.1072  1898.1237
  2010.5891  2317.6462  2360.7783
  2313.7388  2656.8528  2684.0798

(7,.,.) = 
 -2739.6694 -2910.9961 -2735.7534
 -2956.4019 -3107.2900 -2845.8037
 -2835.1682 -2911.8274 -2622.0374

(8,.,.) = 
  5735.1548  6144.4785  5903.7437
  6464.8643  6890.8940  6569.5815
  6729.1172  7101.4912  6732.0225

(9,.,.) = 
  2520.1885  3029.8540  3229.2708
  2901.7029  3425.4734  3553.4058
  3171.7405  3703.3821  3789.0308

(10,.,.) = 
 -3397.9500 -3356.5562 -3108.2419
 -3638.4941 -3603.8376 -3335.3596
 -3600.4241 -3556.7080 -3310.8589

(11,.,.) = 
   474.3366   632.8657   724.2803
   747.2877   935.8264  1023.0562
   837.3837  1071.9756  1161.8704

(12,.,.) = 
   445.3652   715.2228   948.6169
   513.8453   829.3091  1052.0125
   271.8064   586.3862   781.6987

(13,.,.) = 
 -2921.3354 -3088.8105 -2986.4961
 -2941.4236 -3095.8459 -2980.8457
 -2875.1812 -3020.4912 -2879.1760

(14,.,.) = 
  5032.1680  5331.8604  5136.5659
  5303.2295  5593.3608  5354.9614
  5247.2334  5560.3271  5291.4741

(15,.,.) = 
  3423.4551  3712.5649  3687.2766
  3989.0256  4374.5986  4325.8418
  4321.5776  4727.5396  4657.1611

(16,.,.) = 
 -2914.4216 -2994.0696 -2982.1326
 -3041.2708 -3154.9648 -3130.8940
 -3172.1487 -3313.4812 -3275.9133

(17,.,.) = 
 -7543.5405 -7939.2139 -7838.5391
 -8656.1670 -9160.8906 -9057.8574
 -9353.5713 -9920.1709 -9795.8936

(18,.,.) = 
  1635.8889  1584.8810  1489.2054
  1823.1686  1744.0856  1637.7463
  1817.6436  1724.6205  1621.7999
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 162
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 34020
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 162
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 162
[torch.LongStorage of size 2]

shift_y size:	
  70
 162
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
     3
 11340
     4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 34020
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 34020
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 34020
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  34020
[torch.LongStorage of size 1]
	
  first line: 3665.9020996094	
(fast bbox transform) src_w size:  34020
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 34020
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 34020
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 34020
     4
[torch.LongStorage of size 2]

scores size:	
 34020
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 34020
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 34020
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 34020
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 90720
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 22680
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 22680
[torch.LongStorage of size 1]

test img #130: time = 0.636815	
(proposal_test:boxes_filter) boxes & scores size:	
 22680
     4
[torch.LongStorage of size 2]

 22680
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 3
[torch.LongStorage of size 1]

 1947
    3
    4
[torch.LongTensor of size 3]

mask size:	
 22680
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 12
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
  1.0000e+00   1.0000e+00   5.7600e+02   5.7600e+02
        -inf         -inf   5.7495e+04   3.3875e+04
[torch.CudaTensor of size 3x4]

(proposal_test:boxes_filter) boxes size returned:	
 3
 4
[torch.LongStorage of size 2]

img #131	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00118009/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1902.2013 -2140.4993 -2064.5217
 -2027.5074 -2258.2324 -2150.1555
 -1986.5341 -2174.3860 -2050.6924

(2,.,.) = 
  2848.1362  3010.1660  2898.6028
  3052.8528  3231.5801  3077.3967
  2946.9727  3093.7517  2925.1755

(3,.,.) = 
  3659.3801  3985.6406  3984.7173
  4489.3066  4900.9268  4892.8613
  4911.8701  5388.0464  5364.6865

(4,.,.) = 
  1045.6456  1164.8966  1142.5107
  1308.2515  1408.3170  1356.2142
  1422.8829  1476.3053  1383.7159

(5,.,.) = 
   744.0376   735.1969   656.4919
   730.3983   683.2856   576.9925
   746.8988   664.6332   555.9639

(6,.,.) = 
  1635.4880  1853.1492  1895.0614
  2008.7791  2315.3647  2358.4580
  2312.7690  2655.9177  2683.1150

(7,.,.) = 
 -2739.9700 -2909.8582 -2732.8052
 -2957.0156 -3106.6226 -2843.5034
 -2835.9919 -2911.2961 -2619.7253

(8,.,.) = 
  5733.3394  6141.1919  5897.8823
  6464.4541  6888.8359  6565.6138
  6729.7280  7100.8486  6729.5918

(9,.,.) = 
  2517.3936  3026.9810  3226.0002
  2900.3540  3424.1672  3551.6897
  3171.5093  3703.1016  3788.2383

(10,.,.) = 
 -3393.2009 -3350.6760 -3101.4717
 -3633.9895 -3598.5771 -3329.1228
 -3597.1077 -3552.8196 -3306.3987

(11,.,.) = 
   476.1791   635.1970   726.3636
   747.8857   936.9524  1024.2739
   838.8945  1074.0421  1164.0793

(12,.,.) = 
   445.8662   716.4254   949.7228
   513.4223   829.4504  1052.0319
   271.3710   586.2114   780.9915

(13,.,.) = 
 -2921.9753 -3088.6409 -2985.6638
 -2944.2117 -3097.5872 -2981.9082
 -2877.5989 -3021.9290 -2880.0613

(14,.,.) = 
  5032.2124  5330.9775  5134.2456
  5304.3110  5593.6733  5353.8652
  5248.2222  5560.5508  5290.4561

(15,.,.) = 
  3420.5559  3708.5576  3682.1228
  3986.9441  4371.5615  4321.7300
  4320.0049  4725.2510  4654.0693

(16,.,.) = 
 -2908.5481 -2987.8096 -2975.8347
 -3036.2285 -3149.7053 -3126.0095
 -3168.2358 -3309.6177 -3272.7092

(17,.,.) = 
 -7534.9771 -7928.5781 -7826.9238
 -8648.9004 -9152.2988 -9048.4707
 -9348.5117 -9914.5361 -9790.2266

(18,.,.) = 
  1633.5789  1581.9701  1485.5720
  1821.0538  1741.6675  1634.8942
  1816.4210  1723.3582  1620.2148
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3659.3801269531	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #131: time = 0.548562	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1724e+04   4.2417e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #132	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00044002/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1901.8009 -2141.0781 -2066.6479
 -2026.8604 -2258.6836 -2152.3491
 -1985.7401 -2174.7402 -2052.8494

(2,.,.) = 
  2848.3826  3011.9841  2902.3911
  3052.8879  3233.2341  3081.2102
  2946.5613  3095.0120  2928.5745

(3,.,.) = 
  3657.7004  3987.6299  3991.4807
  4488.0146  4903.8062  4900.8350
  4910.8140  5391.0610  5372.4756

(4,.,.) = 
  1045.5959  1165.9594  1144.9065
  1308.3195  1410.0211  1359.5784
  1423.6206  1478.4584  1387.4679

(5,.,.) = 
   742.4123   733.8528   656.5270
   728.8091   681.7870   576.6209
   744.9532   662.9268   555.5525

(6,.,.) = 
  1635.5505  1855.1881  1898.7677
  2008.9089  2317.5251  2362.7776
  2312.8333  2657.9270  2687.4229

(7,.,.) = 
 -2740.1128 -2911.7380 -2736.3994
 -2956.5808 -3108.1387 -2847.1831
 -2834.6179 -2912.0400 -2622.5227

(8,.,.) = 
  5731.9985  6143.8496  5905.8271
  6463.2485  6891.8633  6574.4590
  6727.9546  7103.1846  6737.4536

(9,.,.) = 
  2516.3879  3029.0356  3230.7686
  2899.0691  3426.3921  3556.8926
  3170.7246  3705.5776  3793.4243

(10,.,.) = 
 -3392.1382 -3352.5576 -3106.1367
 -3632.9199 -3600.4673 -3333.6230
 -3595.3738 -3553.8955 -3310.1421

(11,.,.) = 
   477.0525   636.7278   728.1169
   748.9147   938.8952  1026.5758
   839.9647  1075.7959  1166.2589

(12,.,.) = 
   449.1189   720.2576   953.6782
   516.8981   833.5360  1056.4370
   274.9478   590.2333   785.2410

(13,.,.) = 
 -2921.4399 -3090.0916 -2988.7700
 -2943.4919 -3098.8486 -2984.8503
 -2876.5962 -3022.8315 -2882.7542

(14,.,.) = 
  5032.0605  5334.2632  5140.9688
  5304.1460  5597.0122  5360.5015
  5247.4702  5563.4658  5296.5415

(15,.,.) = 
  3419.6465  3710.6982  3687.6370
  3986.3311  4374.2104  4328.1411
  4319.4868  4727.8843  4660.3530

(16,.,.) = 
 -2907.0959 -2988.7864 -2979.6753
 -3034.9695 -3150.9377 -3129.9463
 -3167.2358 -3311.1074 -3276.7500

(17,.,.) = 
 -7533.7339 -7933.6812 -7839.6328
 -8648.6719 -9159.0176 -9062.9990
 -9349.5088 -9922.4219 -9805.7070

(18,.,.) = 
  1633.9886  1583.4061  1488.5377
  1821.4471  1743.1333  1637.7738
  1816.1422  1724.1774  1622.4797
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3657.7004394531	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #132: time = 0.57735500000001	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1732e+04   4.2428e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #133	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00038000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1907.1859 -2146.0955 -2069.8369
 -2032.7975 -2264.2390 -2155.9487
 -1991.3427 -2179.8506 -2055.9026

(2,.,.) = 
  2855.6230  3017.9785  2906.0110
  3060.7405  3239.9888  3085.2952
  2954.0300  3101.2922  2932.2734

(3,.,.) = 
  3670.6794  3997.7080  3996.6165
  4501.9741  4914.2876  4905.8989
  4924.2222  5401.0293  5377.0508

(4,.,.) = 
  1048.9932  1168.5950  1146.2498
  1312.1656  1412.5203  1360.3593
  1426.7644  1480.2844  1387.5216

(5,.,.) = 
   746.7947   737.7936   658.7156
   732.8694   685.5027   578.8910
   749.0964   666.4930   557.5482

(6,.,.) = 
  1641.1158  1859.5647  1901.4199
  2015.0776  2322.4707  2365.4668
  2318.9734  2662.9026  2689.9739

(7,.,.) = 
 -2748.4065 -2918.8665 -2741.4949
 -2965.5288 -3115.7480 -2852.1345
 -2843.2747 -2919.0996 -2627.0037

(8,.,.) = 
  5750.0356  6158.7822  5914.6289
  6481.8867  6907.1919  6582.8218
  6745.8643  7117.5942  6744.9702

(9,.,.) = 
  2525.7642  3036.7661  3236.6580
  2909.3628  3434.5901  3562.5352
  3180.0625  3712.9460  3798.1299

(10,.,.) = 
 -3401.7368 -3359.2236 -3109.3767
 -3642.7932 -3607.3718 -3337.0686
 -3605.1309 -3560.7612 -3313.5713

(11,.,.) = 
   477.1335   636.3715   727.6799
   749.5131   938.8435  1026.3359
   840.5018  1076.1036  1166.2881

(12,.,.) = 
   447.0412   718.0836   952.2301
   515.2734   831.9807  1055.3567
   272.8419   588.5117   783.9579

(13,.,.) = 
 -2929.7097 -3096.8118 -2993.5129
 -2951.8887 -3105.9763 -2989.9580
 -2884.7402 -3029.7263 -2887.5098

(14,.,.) = 
  5045.2681  5344.7969  5147.3252
  5317.6924  5607.8716  5367.2397
  5260.5742  5573.7886  5302.7158

(15,.,.) = 
  3430.9517  3719.8525  3693.1782
  3998.1665  4383.7466  4333.4526
  4330.7197  4736.7344  4664.9238

(16,.,.) = 
 -2916.4084 -2995.7383 -2983.6462
 -3044.3521 -3157.9099 -3133.9534
 -3176.1870 -3317.6714 -3280.2566

(17,.,.) = 
 -7556.8208 -7951.3242 -7848.8691
 -8672.4668 -9176.7656 -9071.8242
 -9371.7529 -9938.4170 -9812.5615

(18,.,.) = 
  1637.9260  1586.0347  1489.4109
  1825.6467  1745.7942  1638.7981
  1820.6288  1727.1060  1623.7162
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3670.6794433594	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #133: time = 0.589862	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1832e+04   4.2470e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #134	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00033002/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 358
 640
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 640
 640
[torch.LongStorage of size 3]

x_start = 1 / y_start = 142	
img_means:size() vs img:size():	
   3
 358
 640
[torch.LongStorage of size 3]

   3
 358
 640
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6759776536313	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1072
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x131
  2 : CudaTensor - size: 18x72x131
  3 : CudaTensor - size: 18x70x129
  4 : CudaTensor - size: 18x68x127
  5 : CudaTensor - size: 256x74x133
}
proposal_im_deteect: img_blob size:     3
  600
 1072
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 358
 640
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6759776536313	
proposal_im_detect: scaled_img_size:	
    5
  600
 1073
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1897.3411 -2135.1545 -2059.6804
 -2022.0735 -2252.3254 -2144.9343
 -1981.1002 -2168.6445 -2046.0096

(2,.,.) = 
  2841.3608  3003.0393  2891.9790
  3045.0522  3223.3379  3070.0388
  2939.1018  3085.5789  2918.1960

(3,.,.) = 
  3647.6997  3974.5818  3975.5583
  4475.8955  4888.0161  4881.9360
  4898.0283  5374.5957  5353.2495

(4,.,.) = 
  1041.5251  1160.9575  1139.3483
  1303.9086  1404.5096  1353.1790
  1419.1594  1473.2723  1381.4053

(5,.,.) = 
   740.5978   732.1215   654.2682
   726.8806   680.2028   574.8771
   743.5244   661.6802   553.8246

(6,.,.) = 
  1629.7992  1846.9277  1889.3771
  2002.1321  2307.8091  2351.3201
  2305.2075  2647.3030  2674.8796

(7,.,.) = 
 -2732.1238 -2901.7842 -2725.4453
 -2948.1704 -3097.4897 -2835.4072
 -2826.7573 -2902.1335 -2611.5886

(8,.,.) = 
  5716.7910  6125.3823  5884.8872
  6446.7778  6872.0386  6552.0708
  6712.0288  7084.2324  6716.2241

(9,.,.) = 
  2509.4829  3018.6128  3218.3152
  2891.5481  3415.0964  3543.3811
  3162.6409  3694.3601  3780.5562

(10,.,.) = 
 -3385.2937 -3343.6460 -3095.6226
 -3626.2126 -3591.6162 -3323.3762
 -3589.8325 -3546.1243 -3300.8164

(11,.,.) = 
   474.8722   633.7673   725.3136
   746.4433   935.4377  1023.0855
   837.6163  1072.6125  1162.9104

(12,.,.) = 
   444.9823   714.3690   946.7705
   512.0811   826.8116  1048.5511
   270.1965   583.7263   777.9227

(13,.,.) = 
 -2914.0325 -3080.5322 -2978.1621
 -2936.0884 -3089.3083 -2974.4426
 -2869.6536 -3014.2031 -2873.5447

(14,.,.) = 
  5018.7754  5317.9160  5122.9839
  5290.8457  5580.8350  5343.0928
  5235.5825  5548.7036  5281.0010

(15,.,.) = 
  3409.6230  3697.9805  3673.4031
  3975.1143  4359.9800  4312.1187
  4308.0376  4713.4087  4644.1465

(16,.,.) = 
 -2899.5400 -2979.8518 -2969.6045
 -3026.8247 -3141.4392 -3119.7561
 -3159.4712 -3301.8174 -3266.9832

(17,.,.) = 
 -7511.4468 -7906.8711 -7808.9941
 -8624.0771 -9129.4141 -9029.4746
 -9324.4287 -9892.3369 -9772.0781

(18,.,.) = 
  1629.7827  1578.8123  1483.0035
  1816.8076  1738.2999  1632.0797
  1812.0912  1719.7960  1617.0302
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 129
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 27090
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 129
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 129
[torch.LongStorage of size 2]

shift_y size:	
  70
 129
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 9030
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 27090
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 27090
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 27090
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  27090
[torch.LongStorage of size 1]
	
  first line: 3647.6997070312	
(fast bbox transform) src_w size:  27090
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 27090
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 27090
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 27090
     4
[torch.LongStorage of size 2]

scores size:	
 27090
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 27090
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 27090
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 27090
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 72240
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 18060
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 18060
[torch.LongStorage of size 1]

test img #134: time = 0.466025	
(proposal_test:boxes_filter) boxes & scores size:	
 18060
     4
[torch.LongStorage of size 2]

 18060
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1809
    3
[torch.LongTensor of size 2]

mask size:	
 18060
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   6.4000e+02   6.4000e+02
        -inf         -inf   3.5562e+04   2.0941e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #135	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00030002/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1914.9242 -2155.1814 -2079.1313
 -2041.6460 -2274.3267 -2166.0957
 -2000.8368 -2190.4758 -2066.3445

(2,.,.) = 
  2866.9993  3030.5747  2919.0200
  3073.5220  3254.1279  3099.5664
  2967.1045  3115.6245  2946.5142

(3,.,.) = 
  3691.6479  4021.3567  4020.8237
  4527.1714  4942.7661  4934.7993
  4951.5674  5431.6250  5407.7642

(4,.,.) = 
  1055.4462  1176.0798  1153.7642
  1320.3966  1421.5300  1369.1443
  1435.5267  1489.7189  1396.5513

(5,.,.) = 
   750.8373   742.3638   663.3547
   737.0969   690.2305   583.4371
   753.6959   671.2788   562.0587

(6,.,.) = 
  1650.9601  1870.7841  1912.9993
  2026.6646  2335.9343  2379.2358
  2332.0630  2677.9067  2705.1233

(7,.,.) = 
 -2759.8865 -2931.7371 -2754.4592
 -2978.6079 -3130.0120 -2865.8882
 -2856.6687 -2933.2798 -2640.4155

(8,.,.) = 
  5778.4980  6190.4209  5946.7583
  6514.7026  6943.2144  6618.4653
  6780.8091  7155.3169  6781.7183

(9,.,.) = 
  2539.1375  3052.8567  3253.8984
  2924.9736  3452.9290  3581.7930
  3197.0483  3732.5789  3818.5791

(10,.,.) = 
 -3418.2996 -3376.3044 -3126.2830
 -3661.0913 -3626.0410 -3355.3596
 -3623.8445 -3579.7031 -3331.9658

(11,.,.) = 
   480.2291   640.1837   731.7927
   753.7714   943.8542  1031.5597
   844.7084  1081.2343  1171.7051

(12,.,.) = 
   447.8186   719.9532   954.7521
   516.3374   834.3693  1058.4535
   273.4308   590.4379   786.7825

(13,.,.) = 
 -2941.0122 -3109.2300 -3006.1899
 -2963.4202 -3118.5005 -3002.7290
 -2896.9946 -3042.8494 -2900.4734

(14,.,.) = 
  5067.2866  5368.8662  5171.7568
  5341.6572  5633.5649  5393.0449
  5285.7476  5600.6343  5329.2603

(15,.,.) = 
  3450.2441  3741.4302  3715.2866
  4020.5024  4408.7725  4358.8149
  4355.1182  4763.7661  4691.8921

(16,.,.) = 
 -2932.1912 -3012.8022 -3001.2014
 -3061.5769 -3176.3591 -3152.6179
 -3194.2981 -3337.0227 -3299.6411

(17,.,.) = 
 -7598.1221 -7996.4668 -7894.9951
 -8720.1836 -9228.5518 -9124.5371
 -9423.4600 -9994.1230 -9868.6016

(18,.,.) = 
  1645.6011  1594.0597  1497.5159
  1834.5250  1754.8080  1647.7352
  1829.8317  1736.2175  1632.6831
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3691.6479492188	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #135: time = 0.57888199999999	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2247e+04   4.2721e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #136	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00018003/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1915.8477 -2156.2742 -2080.2537
 -2042.4944 -2275.3479 -2167.2368
 -2001.1101 -2190.9158 -2067.0969

(2,.,.) = 
  2868.2595  3032.1504  2920.7769
  3074.5054  3255.6606  3101.2874
  2966.8914  3116.1421  2947.4702

(3,.,.) = 
  3692.8132  4022.6028  4022.2759
  4527.7007  4943.2485  4935.5884
  4950.9253  5430.7271  5407.1611

(4,.,.) = 
  1055.9117  1176.4677  1154.1486
  1321.2892  1422.1724  1369.6606
  1436.6061  1490.4740  1397.1652

(5,.,.) = 
   751.3018   742.7856   663.8133
   737.4890   690.5947   583.9182
   753.8602   671.4258   562.4871

(6,.,.) = 
  1651.1134  1871.2560  1913.6212
  2026.1842  2336.0918  2379.9377
  2330.7129  2677.2795  2705.2622

(7,.,.) = 
 -2760.0486 -2932.1169 -2754.9380
 -2977.8789 -3129.7822 -2866.0251
 -2854.4524 -2931.8577 -2639.7866

(8,.,.) = 
  5779.5244  6191.7505  5948.2778
  6514.2949  6943.1699  6618.8271
  6777.8184  7152.8203  6780.0586

(9,.,.) = 
  2539.4292  3053.2844  3254.4854
  2924.5452  3452.5754  3581.7944
  3195.1440  3730.8123  3817.4368

(10,.,.) = 
 -3418.9722 -3377.1514 -3127.1819
 -3660.7166 -3626.2549 -3355.8955
 -3621.5430 -3578.3057 -3331.5132

(11,.,.) = 
   480.0019   640.0840   731.7049
   753.4703   943.6708  1031.2994
   844.3907  1080.9751  1171.2870

(12,.,.) = 
   448.2444   720.5054   955.4099
   517.2894   835.4219  1059.4635
   274.9205   592.1485   788.3734

(13,.,.) = 
 -2942.0291 -3110.5901 -3007.5840
 -2963.4680 -3119.1963 -3003.8352
 -2895.1897 -3041.8684 -2900.3779

(14,.,.) = 
  5068.8447  5370.8193  5173.7417
  5341.7046  5634.3770  5394.2065
  5283.0483  5598.9971  5328.5518

(15,.,.) = 
  3450.9907  3742.2788  3716.2676
  4020.5005  4408.9775  4359.2759
  4353.7192  4762.5342  4691.1157

(16,.,.) = 
 -2933.5984 -3014.3745 -3002.7617
 -3062.5386 -3177.5762 -3153.8796
 -3193.9529 -3337.0554 -3299.9382

(17,.,.) = 
 -7601.1685 -7999.6455 -7898.3276
 -8722.4385 -9231.0596 -9127.3105
 -9423.4023 -9994.3594 -9869.3828

(18,.,.) = 
  1646.1799  1594.6439  1498.1913
  1834.6776  1755.0798  1648.2438
  1829.2843  1735.9894  1632.8416
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3692.8132324219	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #136: time = 0.591639	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2035e+04   4.2578e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #137	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00033003/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 358
 640
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 640
 640
[torch.LongStorage of size 3]

x_start = 1 / y_start = 142	
img_means:size() vs img:size():	
   3
 358
 640
[torch.LongStorage of size 3]

   3
 358
 640
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6759776536313	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1072
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x131
  2 : CudaTensor - size: 18x72x131
  3 : CudaTensor - size: 18x70x129
  4 : CudaTensor - size: 18x68x127
  5 : CudaTensor - size: 256x74x133
}
proposal_im_deteect: img_blob size:     3
  600
 1072
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 358
 640
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6759776536313	
proposal_im_detect: scaled_img_size:	
    5
  600
 1073
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1908.1577 -2147.5198 -2071.7104
 -2034.1637 -2265.9480 -2158.0288
 -1993.2725 -2182.0615 -2058.3171

(2,.,.) = 
  2856.9788  3019.9294  2908.6238
  3062.4907  3242.3235  3088.2268
  2956.2815  3104.0540  2935.4395

(3,.,.) = 
  3674.4209  4002.7488  4002.5127
  4506.5273  4920.3540  4912.7695
  4929.3774  5407.4878  5384.1997

(4,.,.) = 
  1050.0381  1170.1356  1148.0026
  1313.6544  1414.4304  1362.3665
  1428.3877  1482.3096  1389.6252

(5,.,.) = 
   747.1364   738.6508   659.9904
   733.4027   686.5366   580.1746
   749.9435   667.6682   558.8213

(6,.,.) = 
  1642.7336  1861.5166  1903.8098
  2016.9124  2324.8628  2368.2947
  2321.2234  2665.7014  2693.1904

(7,.,.) = 
 -2749.1511 -2920.3564 -2743.6377
 -2966.8813 -3117.6499 -2854.5103
 -2845.3115 -2921.5090 -2629.6765

(8,.,.) = 
  5754.0996  6164.5063  5921.8604
  6487.1865  6914.0386  6590.7690
  6752.2305  7125.2192  6753.3369

(9,.,.) = 
  2527.5503  3039.3569  3239.7920
  2911.5793  3437.5500  3566.1125
  3182.8489  3716.3608  3802.2668

(10,.,.) = 
 -3404.9497 -3362.9255 -3113.6492
 -3646.5151 -3611.4268 -3341.6501
 -3609.1230 -3564.9482 -3318.1143

(11,.,.) = 
   477.8950   637.2477   728.6639
   750.4079   939.8749  1027.3824
   841.2065  1076.9161  1167.1772

(12,.,.) = 
   446.8528   718.1000   952.1637
   515.0316   832.0004  1055.3955
   272.6806   588.5502   784.2027

(13,.,.) = 
 -2930.7847 -3098.4075 -2995.6262
 -2953.0366 -3107.4150 -2991.8926
 -2886.5383 -3031.7378 -2889.8123

(14,.,.) = 
  5048.4136  5348.8599  5152.4370
  5321.4473  5612.2646  5372.5195
  5265.2222  5578.8804  5308.4570

(15,.,.) = 
  3434.1548  3724.0610  3698.2808
  4001.9561  4388.5923  4339.1914
  4335.2329  4742.2173  4671.1016

(16,.,.) = 
 -2919.5308 -2999.7014 -2988.2168
 -3047.7905 -3162.0940 -3138.6455
 -3179.8457 -3321.9460 -3284.9963

(17,.,.) = 
 -7564.0376 -7960.7065 -7860.0645
 -8681.0986 -9187.4189 -9084.3047
 -9381.5273 -9949.9355 -9825.6348

(18,.,.) = 
  1639.2589  1587.8739  1491.5618
  1827.3224  1747.9321  1641.1302
  1822.4408  1729.1764  1625.9327
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 129
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 27090
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 129
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 129
[torch.LongStorage of size 2]

shift_y size:	
  70
 129
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 9030
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 27090
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 27090
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 27090
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  27090
[torch.LongStorage of size 1]
	
  first line: 3674.4208984375	
(fast bbox transform) src_w size:  27090
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 27090
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 27090
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 27090
     4
[torch.LongStorage of size 2]

scores size:	
 27090
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 27090
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 27090
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 27090
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 72240
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 18060
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 18060
[torch.LongStorage of size 1]

test img #137: time = 0.492688	
(proposal_test:boxes_filter) boxes & scores size:	
 18060
     4
[torch.LongStorage of size 2]

 18060
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1809
    3
[torch.LongTensor of size 2]

mask size:	
 18060
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   6.4000e+02   6.4000e+02
        -inf         -inf   3.5717e+04   2.1042e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #138	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00054000/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 240
 320
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 320
 320
[torch.LongStorage of size 3]

x_start = 1 / y_start = 41	
img_means:size() vs img:size():	
   3
 240
 320
[torch.LongStorage of size 3]

   3
 240
 320
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 2.5	
(orep_img_for_blob) img size after scaling:	
   3
 600
 800
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x97
  2 : CudaTensor - size: 18x72x97
  3 : CudaTensor - size: 18x70x95
  4 : CudaTensor - size: 18x68x93
  5 : CudaTensor - size: 256x74x99
}
proposal_im_deteect: img_blob size:    3
 600
 800
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 240
 320
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 2.5	
proposal_im_detect: scaled_img_size:	
   8
 600
 800
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1921.3555  -2163.7068  -2087.8604
  -2051.2532  -2285.9839  -2178.1360
  -2011.8689  -2203.6250  -2079.5769

(2,.,.) = 
   2876.9717   3042.4387   2932.1057
   3086.7368   3270.1848   3116.1777
   2981.5063   3132.9541   2964.5674

(3,.,.) = 
   3732.9451   4066.6663   4065.6521
   4577.1260   4997.9902   4989.5386
   5004.6021   5490.3179   5465.2017

(4,.,.) = 
   1073.0157   1196.1094   1173.5480
   1340.4160   1443.6558   1390.8627
   1455.8081   1511.7477   1417.2687

(5,.,.) = 
    761.3754    752.9154    672.5389
    748.1031    701.7247    593.7910
    764.0502    682.2389    573.1743

(6,.,.) = 
   1676.8519   1900.3351   1942.4457
   2056.3989   2369.6672   2412.9448
   2363.2141   2713.5122   2740.4607

(7,.,.) = 
  -2783.7622  -2957.9421  -2781.2092
  -3005.3464  -3159.5256  -2895.1304
  -2882.8601  -2961.9490  -2668.7275

(8,.,.) = 
   5835.3457   6251.6343   6006.4688
   6579.0464   7012.3804   6685.3560
   6845.7690   7225.2349   6848.7852

(9,.,.) = 
   2569.6709   3088.6953   3292.2676
   2962.3267   3495.7073   3626.1946
   3234.6526   3775.1025   3861.8521

(10,.,.) = 
  -3434.0977  -3393.2244  -3144.1487
  -3679.8611  -3646.4392  -3375.7375
  -3645.1401  -3602.8806  -3355.5913

(11,.,.) = 
    489.9162    651.4120    741.9541
    763.1192    954.5453   1041.8486
    853.7621   1092.3462   1182.8989

(12,.,.) = 
    448.1599    722.9905    958.6373
    517.5032    838.6959   1063.9053
    276.2191    596.5477    794.2058

(13,.,.) = 
  -2954.8989  -3124.4060  -3022.5164
  -2980.5786  -3137.8069  -3023.7434
  -2915.4663  -3063.1785  -2921.4485

(14,.,.) = 
   5098.4058   5402.8853   5205.7969
   5377.3228   5671.8667   5431.7808
   5323.7715   5641.6514   5370.2065

(15,.,.) = 
   3493.3076   3789.2017   3762.2219
   4069.5701   4463.0469   4412.0171
   4405.6841   4819.5850   4745.9419

(16,.,.) = 
  -2954.3176  -3036.7673  -3025.6807
  -3090.0017  -3206.4333  -3182.6069
  -3225.4670  -3370.7310  -3333.0723

(17,.,.) = 
  -7677.4927  -8080.9185  -7978.3701
  -8812.0752  -9327.2197  -9222.5693
  -9520.4160 -10098.4688  -9971.4482

(18,.,.) = 
   1653.8438   1602.2341   1506.0479
   1845.1478   1765.1843   1658.8574
   1842.8193   1749.2427   1646.5220
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 95
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 19950
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 95
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 95
[torch.LongStorage of size 2]

shift_y size:	
 70
 95
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6650
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 19950
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  19950
[torch.LongStorage of size 1]
	
  first line: 3732.9450683594	
(fast bbox transform) src_w size:  19950
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 19950
     4
[torch.LongStorage of size 2]

scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 19950
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 53200
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13300
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13300
[torch.LongStorage of size 1]

test img #138: time = 0.359351	
(proposal_test:boxes_filter) boxes & scores size:	
 13300
     4
[torch.LongStorage of size 2]

 13300
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 953
   3
[torch.LongTensor of size 2]

mask size:	
 13300
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   3.2000e+02   3.2000e+02
        -inf         -inf   2.4272e+04   1.4302e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #139	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00046003/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1900.8535 -2138.9480 -2062.8650
 -2025.8944 -2256.3662 -2148.2598
 -1985.1260 -2172.8364 -2049.2112

(2,.,.) = 
  2846.5071  3008.3040  2896.5808
  3050.9810  3229.4136  3075.1350
  2945.2466  3091.8301  2923.2683

(3,.,.) = 
  3655.7939  3981.4419  3980.2368
  4485.5493  4896.6694  4888.4268
  4908.3589  5384.2900  5360.9702

(4,.,.) = 
  1044.4133  1163.3435  1140.7295
  1306.9147  1406.7212  1354.3784
  1421.7164  1475.0045  1382.2872

(5,.,.) = 
   742.9900   733.9017   655.2175
   729.3585   681.9305   575.6164
   746.0869   663.6070   554.8719

(6,.,.) = 
  1633.6445  1850.9192  1892.6138
  2007.0164  2313.2056  2355.9929
  2310.9880  2653.7292  2680.7224

(7,.,.) = 
 -2737.5723 -2907.1199 -2729.8325
 -2954.5837 -3103.8582 -2840.5037
 -2833.7612 -2908.8911 -2617.2881

(8,.,.) = 
  5728.2231  6135.2661  5891.6699
  6459.4077  6883.1328  6559.7339
  6725.3086  7096.1465  6724.9678

(9,.,.) = 
  2514.4614  3023.4688  3221.7952
  2897.3904  3420.7026  3547.7161
  3169.0244  3700.4607  3785.4836

(10,.,.) = 
 -3391.2837 -3348.7192 -3099.3684
 -3632.0740 -3596.6230 -3327.2148
 -3595.2146 -3550.9326 -3304.5471

(11,.,.) = 
   475.9087   634.9597   726.2194
   747.8294   936.8737  1024.1404
   838.8112  1073.9252  1163.8833

(12,.,.) = 
   445.8211   716.3408   949.5002
   513.2727   829.1381  1051.5348
   271.1957   585.9301   780.5460

(13,.,.) = 
 -2920.1082 -3086.6504 -2983.6396
 -2942.3093 -3095.6143 -2979.8953
 -2875.9111 -3020.2966 -2878.5093

(14,.,.) = 
  5028.8159  5327.3130  5130.4932
  5301.0825  5590.3081  5350.4648
  5245.4180  5557.8096  5287.8564

(15,.,.) = 
  3416.9861  3704.4211  3677.6909
  3983.5461  4367.6978  4317.6274
  4316.9404  4721.9268  4650.7197

(16,.,.) = 
 -2906.3093 -2985.2124 -2972.9878
 -3033.8142 -3147.0288 -3123.1748
 -3166.1616 -3307.4382 -3270.5439

(17,.,.) = 
 -7528.5762 -7921.2280 -7818.9810
 -8642.3535 -9145.1318 -9040.8965
 -9342.5273 -9908.3545 -9784.0195

(18,.,.) = 
  1632.6666  1581.0090  1484.5223
  1819.9907  1740.5620  1633.6721
  1815.3717  1722.2802  1618.9945
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3655.7939453125	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #139: time = 0.550556	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1693e+04   4.2404e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #140	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00109004/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1912.5376 -2152.2234 -2076.2563
 -2038.9871 -2271.1926 -2163.0627
 -1997.9852 -2187.1729 -2063.2100

(2,.,.) = 
  2863.6140  3026.9070  2915.1860
  3069.7576  3250.1301  3095.4746
  2963.2888  3111.6384  2942.4995

(3,.,.) = 
  3683.7283  4012.6616  4011.8955
  4518.0029  4932.6958  4924.5176
  4941.8481  5421.1479  5397.1528

(4,.,.) = 
  1052.7540  1173.2472  1150.9556
  1317.0991  1418.2308  1365.9708
  1432.4021  1486.4452  1393.3433

(5,.,.) = 
   749.1158   740.4300   661.5662
   735.3418   688.2621   581.6393
   751.7717   669.3907   560.5052

(6,.,.) = 
  1647.3112  1866.7346  1908.8679
  2022.3619  2331.1375  2374.3203
  2327.3345  2672.7727  2700.0454

(7,.,.) = 
 -2755.8936 -2927.6387 -2750.3469
 -2974.2070 -3125.7764 -2861.9287
 -2852.3357 -2929.2986 -2636.8516

(8,.,.) = 
  5768.4507  6179.5850  5935.6035
  6503.4351  6931.1938  6606.3662
  6769.0693  7143.0981  6769.6069

(9,.,.) = 
  2534.1855  3047.2649  3248.0723
  2919.1392  3446.5801  3575.3923
  3191.1177  3726.0664  3811.9182

(10,.,.) = 
 -3412.1455 -3369.9751 -3119.7749
 -3654.3228 -3619.1650 -3348.4143
 -3616.9504 -3572.7004 -3324.9973

(11,.,.) = 
   479.3399   639.0910   730.5363
   752.4144   942.2902  1029.8585
   843.4688  1079.7867  1170.1130

(12,.,.) = 
   447.9622   720.0941   955.0237
   516.4807   834.3489  1058.6110
   273.8427   590.5963   786.9666

(13,.,.) = 
 -2937.6929 -3105.8308 -3002.7153
 -2960.1707 -3115.2219 -2999.4038
 -2893.4661 -3039.2932 -2897.0068

(14,.,.) = 
  5060.4790  5361.5718  5164.2778
  5334.2632  5625.8809  5385.2212
  5277.8281  5592.4756  5321.0547

(15,.,.) = 
  3443.2407  3733.6343  3707.0662
  4012.5879  4399.9497  4349.6133
  4346.6587  4754.4131  4682.2812

(16,.,.) = 
 -2926.2844 -3006.4114 -2994.5854
 -3055.0554 -3169.4119 -3145.5625
 -3187.5400 -3329.8406 -3292.2375

(17,.,.) = 
 -7583.2344 -7980.3643 -7878.4297
 -8703.2910 -9210.3203 -9105.7373
 -9405.6797 -9974.9463 -9848.9736

(18,.,.) = 
  1642.9236  1591.2704  1494.6584
  1831.4950  1751.8079  1644.7449
  1826.6252  1733.2166  1629.7465
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3683.7282714844	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #140: time = 0.53089	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2040e+04   4.2596e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #141	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00005000/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  576
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 353	
img_means:size() vs img:size():	
    3
  576
 1280
[torch.LongStorage of size 3]

    3
  576
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.0416666666667	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1333
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x164
  2 : CudaTensor - size: 18x72x164
  3 : CudaTensor - size: 18x70x162
  4 : CudaTensor - size: 18x68x160
  5 : CudaTensor - size: 256x74x166
}
proposal_im_deteect: img_blob size:     3
  600
 1333
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  576
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.0416666666667	
proposal_im_detect: scaled_img_size:	
    3
  600
 1333
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1904.4303 -2143.0620 -2068.1770
 -2029.3752 -2260.8975 -2153.9746
 -1988.7386 -2177.6648 -2054.9451

(2,.,.) = 
  2851.4775  3014.2263  2903.7983
  3056.0066  3235.4878  3082.4480
  2949.8660  3097.5823  2930.1138

(3,.,.) = 
  3661.4875  3989.4907  3990.9907
  4491.9263  4905.3379  4899.0459
  4915.3604  5392.5396  5370.1172

(4,.,.) = 
  1044.3472  1164.1771  1142.7032
  1308.1230  1408.7760  1357.4930
  1423.6710  1477.6864  1386.0214

(5,.,.) = 
   744.4835   736.4506   658.6660
   731.1005   684.5848   579.0352
   748.6584   666.6904   558.1973

(6,.,.) = 
  1635.2832  1853.7014  1896.5576
  2009.1047  2316.4749  2360.5181
  2313.8884  2657.3706  2685.2886

(7,.,.) = 
 -2740.7083 -2911.9182 -2736.5403
 -2957.4561 -3108.2471 -2846.8015
 -2836.6541 -2913.2996 -2623.4487

(8,.,.) = 
  5733.6182  6143.7568  5904.1963
  6465.3848  6892.0210  6571.7505
  6732.5518  7105.1465  6736.0161

(9,.,.) = 
  2517.4209  3027.7532  3228.2847
  2899.6016  3424.2585  3553.3198
  3171.8867  3704.2361  3790.5754

(10,.,.) = 
 -3399.1125 -3358.0730 -3109.9077
 -3640.2739 -3605.7966 -3337.3938
 -3602.4502 -3558.7834 -3312.8535

(11,.,.) = 
   474.6507   633.4943   725.1647
   747.4264   936.4702  1023.9139
   837.9072  1072.7979  1162.7798

(12,.,.) = 
   446.8672   717.2839   950.9114
   514.4980   830.6234  1053.7555
   272.0370   587.1052   782.7009

(13,.,.) = 
 -2923.3035 -3090.9524 -2988.7041
 -2943.8589 -3098.2681 -2983.1274
 -2877.7961 -3023.0845 -2881.7578

(14,.,.) = 
  5034.5815  5334.8096  5140.0503
  5306.4224  5597.1021  5358.8066
  5250.9849  5564.4639  5295.5190

(15,.,.) = 
  3420.3030  3709.6694  3685.6455
  3987.6230  4373.5435  4325.8623
  4322.5596  4728.7876  4658.9814

(16,.,.) = 
 -2912.5920 -2992.7769 -2982.0498
 -3040.0930 -3154.3418 -3131.3286
 -3172.7166 -3314.3152 -3277.2993

(17,.,.) = 
 -7537.4194 -7934.4780 -7837.0474
 -8654.0430 -9159.8311 -9059.0332
 -9356.6396 -9923.8750 -9800.7793

(18,.,.) = 
  1636.7227  1585.8445  1490.3606
  1824.1798  1745.1309  1638.8741
  1818.7012  1725.7239  1622.9965
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 162
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 34020
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 162
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 162
[torch.LongStorage of size 2]

shift_y size:	
  70
 162
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
     3
 11340
     4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 34020
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 34020
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 34020
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  34020
[torch.LongStorage of size 1]
	
  first line: 3661.4875488281	
(fast bbox transform) src_w size:  34020
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 34020
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 34020
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 34020
     4
[torch.LongStorage of size 2]

scores size:	
 34020
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 34020
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 34020
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 34020
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 90720
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 22680
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 22680
[torch.LongStorage of size 1]

test img #141: time = 0.804513	
(proposal_test:boxes_filter) boxes & scores size:	
 22680
     4
[torch.LongStorage of size 2]

 22680
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 3
[torch.LongStorage of size 1]

 1947
    3
    4
[torch.LongTensor of size 3]

mask size:	
 22680
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 12
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
  1.0000e+00   1.0000e+00   5.7600e+02   5.7600e+02
        -inf         -inf   5.7511e+04   3.3872e+04
[torch.CudaTensor of size 3x4]

(proposal_test:boxes_filter) boxes size returned:	
 3
 4
[torch.LongStorage of size 2]

img #142	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0001/ILSVRC2015_train_00200000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1908.0836 -2147.4829 -2071.5901
 -2034.1917 -2266.0261 -2158.0190
 -1993.4729 -2182.3005 -2058.5159

(2,.,.) = 
  2857.1152  3020.0195  2908.6206
  3062.8438  3242.6570  3088.4785
  2956.8259  3104.6917  2935.9739

(3,.,.) = 
  3673.7961  4002.1411  4002.0081
  4507.0034  4920.6338  4912.9663
  4931.1050  5409.0098  5385.3555

(4,.,.) = 
  1050.1536  1170.3835  1148.2386
  1314.0090  1414.9558  1362.8451
  1429.3053  1483.1012  1390.1040

(5,.,.) = 
   746.6564   737.8179   659.0682
   733.1046   685.7916   579.3580
   749.7968   667.2889   558.4945

(6,.,.) = 
  1642.6948  1861.6169  1903.7642
  2017.3925  2325.4485  2368.6675
  2322.1470  2666.7754  2693.8318

(7,.,.) = 
 -2750.1882 -2921.2539 -2744.2170
 -2967.7874 -3118.4915 -2854.9177
 -2845.9983 -2922.1521 -2629.8108

(8,.,.) = 
  5755.1851  6165.4111  5922.2559
  6489.1758  6915.7793  6591.8101
  6755.0054  7127.7090  6754.7969

(9,.,.) = 
  2527.6147  3039.6667  3240.3682
  2912.4429  3438.7937  3567.1816
  3184.6741  3718.5505  3803.8110

(10,.,.) = 
 -3405.0063 -3362.9885 -3113.4229
 -3646.7917 -3611.6814 -3341.4658
 -3609.5913 -3565.3560 -3318.0791

(11,.,.) = 
   478.7943   638.3359   729.5170
   751.3790   941.0416  1028.3401
   842.3029  1078.1232  1168.1539

(12,.,.) = 
   447.3921   719.0559   953.3204
   515.5156   832.9067  1056.3636
   273.1183   589.3733   784.8207

(13,.,.) = 
 -2931.7312 -3099.2900 -2996.4646
 -2954.4851 -3108.8994 -2993.1943
 -2887.9011 -3033.2173 -2891.0947

(14,.,.) = 
  5049.7749  5350.2896  5153.5835
  5323.5005  5614.3730  5374.1216
  5267.4346  5581.2817  5310.1836

(15,.,.) = 
  3434.4526  3724.3420  3698.2695
  4003.2048  4389.7690  4339.7847
  4337.2979  4744.1152  4672.0938

(16,.,.) = 
 -2918.8628 -2998.9497 -2987.5083
 -3047.9187 -3162.2468 -3138.7581
 -3180.9775 -3323.1575 -3285.9727

(17,.,.) = 
 -7563.9756 -7960.4297 -7859.6362
 -8682.9932 -9189.0420 -9085.2725
 -9385.6963 -9953.7236 -9828.2236

(18,.,.) = 
  1639.3376  1587.7225  1491.2904
  1827.3914  1747.7091  1640.8246
  1822.5947  1729.1919  1625.8496
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3673.7961425781	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #142: time = 0.555848	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1951e+04   4.2536e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #143	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00031000/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1912.9126 -2153.1001 -2077.4893
 -2039.4093 -2272.1780 -2164.5029
 -1998.9421 -2188.9229 -2065.1982

(2,.,.) = 
  2864.1013  3027.9856  2916.8745
  3070.4006  3251.3411  3097.1389
  2964.1919  3113.0874  2944.4099

(3,.,.) = 
  3691.3843  4020.7710  4019.3298
  4526.1621  4941.6973  4932.7793
  4950.0029  5430.0718  5405.3701

(4,.,.) = 
  1055.5085  1176.1138  1153.5088
  1320.5732  1421.5964  1368.9744
  1435.4819  1489.8585  1396.6896

(5,.,.) = 
   750.9529   742.6901   663.8950
   737.3329   690.7535   584.1313
   754.2178   672.1744   563.0186

(6,.,.) = 
  1651.3833  1871.2743  1912.9523
  2026.9352  2336.2168  2379.0303
  2332.1121  2677.8577  2704.6724

(7,.,.) = 
 -2757.5759 -2929.8865 -2753.1292
 -2976.4321 -3128.2334 -2864.6199
 -2855.0723 -2932.1833 -2639.9263

(8,.,.) = 
  5774.5171  6186.4336  5942.8477
  6510.3359  6938.9912  6614.2573
  6776.9302  7151.7876  6778.3267

(9,.,.) = 
  2538.5515  3051.6880  3251.8120
  2923.9829  3451.4468  3579.6609
  3195.7422  3730.9250  3816.5488

(10,.,.) = 
 -3415.9617 -3374.4773 -3124.8752
 -3658.6990 -3624.0310 -3353.7710
 -3621.8074 -3578.0837 -3330.4480

(11,.,.) = 
   479.8691   639.5520   730.7637
   753.5549   943.3414  1030.6631
   844.0950  1080.3444  1170.4940

(12,.,.) = 
   447.8776   719.7390   954.0881
   516.6104   834.3060  1058.0292
   274.1539   590.8219   786.8680

(13,.,.) = 
 -2937.5908 -3106.1128 -3003.3687
 -2959.4111 -3114.9993 -2999.6204
 -2893.5310 -3039.7515 -2897.6523

(14,.,.) = 
  5062.2100  5363.8887  5167.1089
  5336.3604  5628.2866  5388.2378
  5281.3320  5596.2422  5325.2144

(15,.,.) = 
  3449.3308  3740.5752  3713.9390
  4019.4019  4407.6753  4357.3232
  4354.2002  4762.9766  4690.7231

(16,.,.) = 
 -2931.8208 -3012.3345 -3000.0835
 -3061.1865 -3175.7566 -3151.2449
 -3193.7168 -3336.3352 -3298.2417

(17,.,.) = 
 -7595.7896 -7993.9966 -7891.3823
 -8717.3672 -9225.6523 -9120.5645
 -9420.2637 -9990.9932 -9864.3350

(18,.,.) = 
  1644.6432  1593.2716  1496.8940
  1833.5704  1753.8199  1646.7073
  1828.9716  1735.3152  1631.6444
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3691.3842773438	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #143: time = 0.55838000000001	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2264e+04   4.2764e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #144	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00033000/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 358
 640
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 640
 640
[torch.LongStorage of size 3]

x_start = 1 / y_start = 142	
img_means:size() vs img:size():	
   3
 358
 640
[torch.LongStorage of size 3]

   3
 358
 640
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6759776536313	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1072
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x131
  2 : CudaTensor - size: 18x72x131
  3 : CudaTensor - size: 18x70x129
  4 : CudaTensor - size: 18x68x127
  5 : CudaTensor - size: 256x74x133
}
proposal_im_deteect: img_blob size:     3
  600
 1072
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 358
 640
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6759776536313	
proposal_im_detect: scaled_img_size:	
    5
  600
 1073
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1903.2480 -2140.6243 -2063.1846
 -2028.4457 -2258.3459 -2148.5750
 -1987.3170 -2174.1819 -2048.9209

(2,.,.) = 
  2850.1077  3010.4275  2896.6509
  3054.5522  3231.4666  3075.0481
  2948.3599  3093.5911  2922.8196

(3,.,.) = 
  3656.7495  3981.6064  3979.3926
  4487.4263  4897.0845  4886.9922
  4910.5576  5384.7295  5358.8184

(4,.,.) = 
  1044.5050  1163.4513  1140.8734
  1306.7518  1406.8356  1354.6935
  1421.7902  1474.7483  1382.1223

(5,.,.) = 
   744.6248   735.0914   655.9693
   730.7959   682.9816   576.2997
   747.4655   664.6370   555.4083

(6,.,.) = 
  1633.9866  1851.3593  1892.6855
  2007.9362  2313.8020  2355.7209
  2312.0620  2654.2754  2679.8589

(7,.,.) = 
 -2743.8560 -2912.5784 -2733.9060
 -2961.1111 -3109.1235 -2844.0686
 -2839.7659 -2913.5154 -2619.9072

(8,.,.) = 
  5734.4609  6140.2295  5894.1929
  6465.9771  6887.9424  6561.4434
  6731.8296  7100.2202  6725.1548

(9,.,.) = 
  2516.7246  3025.7910  3224.7656
  2900.1880  3423.4089  3550.3572
  3172.7039  3703.2129  3787.1077

(10,.,.) = 
 -3393.4932 -3349.6541 -3098.5815
 -3634.7764 -3597.8467 -3326.1155
 -3598.2588 -3552.4993 -3303.5513

(11,.,.) = 
   475.4227   634.3524   725.6252
   747.1984   936.1831  1023.6658
   838.4744  1073.5256  1163.5522

(12,.,.) = 
   447.1567   717.6989   951.0231
   514.5811   830.3598  1052.8801
   271.9697   586.2321   780.9490

(13,.,.) = 
 -2924.6282 -3089.8860 -2985.1228
 -2947.4395 -3099.3010 -2981.4780
 -2880.8638 -3023.8787 -2879.9895

(14,.,.) = 
  5034.3843  5330.8462  5131.3955
  5307.0361  5594.0625  5351.1987
  5251.3979  5561.5327  5288.2178

(15,.,.) = 
  3418.7156  3705.4961  3677.7822
  3985.9270  4369.0396  4317.2886
  4319.6768  4723.0918  4649.3101

(16,.,.) = 
 -2906.0710 -2983.5459 -2970.3472
 -3033.9836 -3145.8125 -3120.9268
 -3167.3474 -3307.0024 -3268.6111

(17,.,.) = 
 -7529.7812 -7920.5723 -7815.6167
 -8644.5352 -9144.7676 -9036.7480
 -9345.5430 -9907.7256 -9778.5361

(18,.,.) = 
  1633.9757  1581.4230  1484.2659
  1821.4526  1740.8733  1633.2067
  1816.6295  1722.5164  1618.4373
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 129
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 27090
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 129
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 129
[torch.LongStorage of size 2]

shift_y size:	
  70
 129
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 9030
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 27090
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 27090
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 27090
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  27090
[torch.LongStorage of size 1]
	
  first line: 3656.7495117188	
(fast bbox transform) src_w size:  27090
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 27090
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 27090
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 27090
     4
[torch.LongStorage of size 2]

scores size:	
 27090
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 27090
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 27090
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 27090
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 72240
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 18060
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 18060
[torch.LongStorage of size 1]

test img #144: time = 0.45179899999999	
(proposal_test:boxes_filter) boxes & scores size:	
 18060
     4
[torch.LongStorage of size 2]

 18060
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1809
    3
[torch.LongTensor of size 2]

mask size:	
 18060
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   6.4000e+02   6.4000e+02
        -inf         -inf   3.5606e+04   2.0967e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #145	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00062000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 480
 640
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 640
 640
[torch.LongStorage of size 3]

x_start = 1 / y_start = 81	
img_means:size() vs img:size():	
   3
 480
 640
[torch.LongStorage of size 3]

   3
 480
 640
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.25	
(orep_img_for_blob) img size after scaling:	
   3
 600
 800
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x97
  2 : CudaTensor - size: 18x72x97
  3 : CudaTensor - size: 18x70x95
  4 : CudaTensor - size: 18x68x93
  5 : CudaTensor - size: 256x74x99
}
proposal_im_deteect: img_blob size:    3
 600
 800
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 480
 640
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.25	
proposal_im_detect: scaled_img_size:	
   4
 600
 800
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1921.2283  -2163.4922  -2087.6082
  -2050.9209  -2285.5115  -2177.5627
  -2011.3718  -2202.9558  -2078.8140

(2,.,.) = 
   2876.8372   3042.2769   2931.8872
   3086.3860   3269.7539   3115.6562
   2980.9570   3132.2463   2963.7021

(3,.,.) = 
   3731.2708   4064.9797   4063.8357
   4575.0103   4995.7842   4987.1611
   5002.1626   5487.7588   5462.5327

(4,.,.) = 
   1072.4619   1195.4554   1172.7495
   1339.7036   1442.8273   1389.8517
   1454.8785   1510.7435   1416.1824

(5,.,.) = 
    760.7793    752.4272    672.2249
    747.4523    701.1416    593.2843
    763.3867    681.6180    572.5734

(6,.,.) = 
   1675.7056   1899.0813   1941.0656
   2055.1121   2368.2559   2411.3640
   2361.9058   2712.0193   2738.7634

(7,.,.) = 
  -2783.0356  -2957.2532  -2780.6042
  -3004.3899  -3158.4778  -2894.1040
  -2881.6589  -2960.6008  -2667.2786

(8,.,.) = 
   5833.1152   6249.4385   6004.2700
   6576.3110   7009.5488   6682.4326
   6842.7334   7222.0352   6845.5132

(9,.,.) = 
   2568.5720   3087.5103   3290.9731
   2960.8015   3494.0417   3624.4468
   3232.8621   3773.1619   3859.9556

(10,.,.) = 
  -3433.5439  -3392.6992  -3143.4868
  -3678.9268  -3645.5093  -3374.7283
  -3643.8918  -3601.5869  -3354.2346

(11,.,.) = 
    489.6871    651.1778    741.7136
    762.9016    954.3151   1041.6334
    853.5200   1092.0632   1182.6102

(12,.,.) = 
    448.7926    723.6143    959.3339
    518.0142    839.1121   1064.3776
    276.4250    596.5533    794.1503

(13,.,.) = 
  -2954.5110  -3124.0647  -3022.3101
  -2979.8831  -3137.0632  -3023.1226
  -2914.4861  -3062.1406  -2920.5784

(14,.,.) = 
   5097.4502   5401.9805   5205.0322
   5375.8550   5670.4126   5430.4683
   5321.8213   5639.6440   5368.3667

(15,.,.) = 
   3491.5122   3787.2122   3760.0520
   4067.3516   4460.6333   4409.3706
   4403.2451   4816.8970   4743.1377

(16,.,.) = 
  -2953.4373  -3035.8804  -3024.6125
  -3088.5322  -3204.9507  -3180.9565
  -3223.5728  -3368.8035  -3331.1929

(17,.,.) = 
  -7674.2065  -8077.5391  -7974.7495
  -8807.8535  -9322.9062  -9218.0449
  -9515.6123 -10093.6035  -9966.4795

(18,.,.) = 
   1653.6802   1602.2141   1505.9924
   1844.7896   1764.9052   1658.4766
   1842.2235   1748.6748   1645.8232
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 95
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 19950
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 95
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 95
[torch.LongStorage of size 2]

shift_y size:	
 70
 95
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6650
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 19950
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  19950
[torch.LongStorage of size 1]
	
  first line: 3731.2707519531	
(fast bbox transform) src_w size:  19950
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 19950
     4
[torch.LongStorage of size 2]

scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 19950
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 53200
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13300
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13300
[torch.LongStorage of size 1]

test img #145: time = 0.33819000000001	
(proposal_test:boxes_filter) boxes & scores size:	
 13300
     4
[torch.LongStorage of size 2]

 13300
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 953
   3
[torch.LongTensor of size 2]

mask size:	
 13300
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   6.4000e+02   6.4000e+02
        -inf         -inf   4.8603e+04   2.8650e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #146	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00013001/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1920
 1920
[torch.LongStorage of size 3]

x_start = 1 / y_start = 421	
img_means:size() vs img:size():	
    3
 1080
 1920
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.55555555555556	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
 1080
 1920
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.55555555555556	
proposal_im_detect: scaled_img_size:	
    2
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1916.0254 -2156.4385 -2080.3596
 -2042.7274 -2275.5637 -2167.3086
 -2001.7844 -2191.5586 -2067.3616

(2,.,.) = 
  2868.6802  3032.3694  2920.7554
  3075.1831  3255.9346  3101.3037
  2968.4927  3117.1357  2947.9971

(3,.,.) = 
  3694.2297  4024.1685  4023.6099
  4529.7539  4945.5874  4937.5874
  4953.4585  5433.6240  5409.7305

(4,.,.) = 
  1056.2109  1176.9366  1154.6074
  1321.1375  1422.3102  1369.8992
  1436.0754  1490.1847  1396.9626

(5,.,.) = 
   751.3268   742.8756   663.8079
   737.4603   690.5867   583.7501
   753.9289   671.4943   562.2666

(6,.,.) = 
  1652.0865  1872.0519  1914.2574
  2027.6024  2337.0078  2380.3083
  2332.5007  2678.5298  2705.7290

(7,.,.) = 
 -2761.4854 -2933.4460 -2756.0837
 -2979.7781 -3131.2319 -2866.9275
 -2856.9255 -2933.4719 -2640.3777

(8,.,.) = 
  5782.1616  6194.3589  5950.5532
  6517.8794  6946.6387  6621.6582
  6782.5278  7157.0767  6783.1973

(9,.,.) = 
  2540.8184  3054.8372  3256.0049
  2926.4600  3454.5925  3583.5085
  3197.8464  3733.3926  3819.3030

(10,.,.) = 
 -3420.5225 -3378.5186 -3128.3521
 -3663.1514 -3628.0652 -3357.2078
 -3625.0061 -3580.7905 -3332.8481

(11,.,.) = 
   480.5089   640.5751   732.2289
   754.0328   944.2192  1031.9755
   844.6562  1081.2677  1171.7643

(12,.,.) = 
   447.9888   720.2609   955.2150
   516.5234   834.7366  1058.9750
   273.5783   590.7025   787.1687

(13,.,.) = 
 -2942.7429 -3111.0547 -3007.9500
 -2964.9739 -3120.1208 -3004.2661
 -2898.0898 -3044.0266 -2901.5369

(14,.,.) = 
  5070.3833  5372.1362  5174.8965
  5344.4463  5636.4961  5395.8320
  5287.5132  5602.5562  5331.0186

(15,.,.) = 
  3452.5955  3743.9875  3717.8062
  4022.5559  4410.9956  4360.9932
  4356.3374  4765.0215  4693.0537

(16,.,.) = 
 -2934.1887 -3014.8528 -3003.2258
 -3063.5176 -3178.3289 -3154.5312
 -3195.9128 -3338.6714 -3301.1643

(17,.,.) = 
 -7603.3374 -8001.9688 -7900.4146
 -8725.2100 -9233.8965 -9129.8457
 -9427.3057 -9998.0898 -9872.4678

(18,.,.) = 
  1646.6537  1595.0890  1498.5031
  1835.5811  1755.8275  1648.6998
  1830.6215  1736.9321  1633.3441
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3694.2297363281	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #146: time = 0.69354899999999	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.9200e+03   1.9200e+03
        -inf         -inf   1.0827e+05   6.4029e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #147	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00018003/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1915.9749 -2156.3860 -2080.3315
 -2042.7184 -2275.5378 -2167.3516
 -2001.5111 -2191.2991 -2067.3237

(2,.,.) = 
  2868.4712  3032.2886  2920.8296
  3074.8647  3255.8938  3101.4048
  2967.5996  3116.6660  2947.8176

(3,.,.) = 
  3693.4209  4023.2273  4022.7910
  4528.6855  4944.2842  4936.4482
  4952.3110  5432.1680  5408.4048

(4,.,.) = 
  1056.0574  1176.6571  1154.3156
  1321.3778  1422.3271  1369.8062
  1436.6589  1490.5745  1397.2546

(5,.,.) = 
   751.3890   742.8773   663.8624
   737.6235   690.7127   583.9596
   754.0789   671.6169   562.5538

(6,.,.) = 
  1651.5225  1871.6300  1913.9218
  2026.8750  2336.6558  2380.2922
  2331.6938  2678.1130  2705.8245

(7,.,.) = 
 -2760.6353 -2932.6716 -2755.4231
 -2978.8320 -3130.6184 -2866.6826
 -2855.8494 -2933.0408 -2640.6628

(8,.,.) = 
  5780.5918  6192.7729  5949.1479
  6515.9761  6944.7534  6620.1294
  6780.2837  7155.1079  6781.9058

(9,.,.) = 
  2539.9692  3053.8782  3255.0547
  2925.4111  3453.4949  3582.6060
  3196.4912  3732.1985  3818.6262

(10,.,.) = 
 -3419.5291 -3377.6462 -3127.6008
 -3661.6277 -3626.9758 -3356.4412
 -3622.9980 -3579.4541 -3332.3096

(11,.,.) = 
   480.1880   640.2570   731.8737
   753.7085   943.8807  1031.5244
   844.6271  1081.2007  1171.5522

(12,.,.) = 
   448.1802   720.4548   955.3732
   517.0974   835.2507  1059.3527
   274.5622   591.8018   788.0876

(13,.,.) = 
 -2942.3433 -3110.8269 -3007.7881
 -2964.0789 -3119.6587 -3004.1426
 -2896.3352 -3042.8167 -2901.0098

(14,.,.) = 
  5069.4834  5371.3745  5174.2153
  5342.8501  5635.3062  5394.9478
  5284.9624  5600.6108  5329.7705

(15,.,.) = 
  3451.6553  3742.9614  3716.8511
  4021.5183  4409.9692  4360.0933
  4355.1909  4763.9780  4692.2891

(16,.,.) = 
 -2933.8950 -3014.6138 -3002.9724
 -3062.9988 -3177.9363 -3154.1716
 -3194.7854 -3337.7505 -3300.4824

(17,.,.) = 
 -7602.1338 -8000.5972 -7899.1191
 -8723.8926 -9232.4023 -9128.3975
 -9425.5654 -9996.3428 -9870.9717

(18,.,.) = 
  1646.3707  1594.8053  1498.3021
  1835.0430  1755.3677  1648.4319
  1829.8398  1736.3948  1633.1119
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3693.4208984375	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #147: time = 0.566254	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2108e+04   4.2626e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #148	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00108003/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 240
 320
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 320
 320
[torch.LongStorage of size 3]

x_start = 1 / y_start = 41	
img_means:size() vs img:size():	
   3
 240
 320
[torch.LongStorage of size 3]

   3
 240
 320
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 2.5	
(orep_img_for_blob) img size after scaling:	
   3
 600
 800
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x97
  2 : CudaTensor - size: 18x72x97
  3 : CudaTensor - size: 18x70x95
  4 : CudaTensor - size: 18x68x93
  5 : CudaTensor - size: 256x74x99
}
proposal_im_deteect: img_blob size:    3
 600
 800
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 240
 320
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 2.5	
proposal_im_detect: scaled_img_size:	
   8
 600
 800
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1916.8894  -2157.6541  -2079.8989
  -2046.8278  -2279.8008  -2169.6926
  -2007.8229  -2197.8301  -2071.5835

(2,.,.) = 
   2870.6099   3033.6143   2920.6392
   3080.3801   3261.0698   3104.2654
   2976.1465   3124.9888   2953.6362

(3,.,.) = 
   3718.8123   4048.4509   4044.5188
   4560.7637   4976.5386   4964.7666
   4987.8193   5468.3535   5439.8843

(4,.,.) = 
   1068.1604   1190.1636   1167.1741
   1334.2218   1436.6815   1383.6982
   1449.6294   1504.6533   1410.1295

(5,.,.) = 
    760.0114    750.1689    668.4152
    747.0394    699.3840    590.1338
    763.4268    680.5374    570.2074

(6,.,.) = 
   1670.2252   1891.4451   1932.2581
   2048.8735   2359.2534   2400.8076
   2354.7219   2701.9783   2727.1304

(7,.,.) = 
  -2779.9810  -2951.7512  -2772.7053
  -3001.5906  -3153.2432  -2886.6450
  -2880.1924  -2957.0225  -2661.6812

(8,.,.) = 
   5820.5601   6231.4512   5981.5654
   6562.9932   6990.3970   6658.7456
   6830.4067   7204.2241   6823.3608

(9,.,.) = 
   2562.1558   3078.3584   3280.0120
   2953.9001   3484.3711   3612.7854
   3226.3643   3763.7334   3848.4099

(10,.,.) = 
  -3424.8606  -3381.0854  -3129.4780
  -3670.5879  -3634.1812  -3360.7937
  -3636.8025  -3591.8621  -3341.9722

(11,.,.) = 
    487.7343    648.4351    738.8232
    760.1473    950.7106   1037.9269
    850.8577   1088.4436   1178.9482

(12,.,.) = 
    446.8029    721.1655    956.4257
    515.8754    836.7435   1061.6224
    274.7898    594.6791    792.0835

(13,.,.) = 
  -2950.6511  -3117.6316  -3013.0769
  -2977.6208  -3132.2366  -3014.9475
  -2913.2847  -3058.4924  -2913.5032

(14,.,.) = 
   5087.5684   5387.5684   5186.2026
   5367.0312   5657.2524   5412.6411
   5314.6729   5628.4585   5352.5093

(15,.,.) = 
   3481.3328   3773.7100   3744.1418
   4056.2554   4445.8145   4391.9365
   4391.8945   4801.9424   4725.6387

(16,.,.) = 
  -2943.7754  -3023.0854  -3009.5986
  -3079.5669  -3192.8474  -3166.7437
  -3216.0767  -3358.0168  -3318.1582

(17,.,.) = 
  -7649.3315  -8045.3115  -7936.6509
  -8781.1250  -9288.1494  -9176.8145
  -9489.0068 -10058.7324  -9925.3477

(18,.,.) = 
   1649.2953   1596.1139   1498.4635
   1840.2881   1758.6217   1650.8816
   1838.3319   1743.1774   1639.1763
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 95
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 19950
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 95
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 95
[torch.LongStorage of size 2]

shift_y size:	
 70
 95
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6650
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 19950
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  19950
[torch.LongStorage of size 1]
	
  first line: 3718.8122558594	
(fast bbox transform) src_w size:  19950
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 19950
     4
[torch.LongStorage of size 2]

scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 19950
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 53200
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13300
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13300
[torch.LongStorage of size 1]

test img #148: time = 0.336303	
(proposal_test:boxes_filter) boxes & scores size:	
 13300
     4
[torch.LongStorage of size 2]

 13300
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 953
   3
[torch.LongTensor of size 2]

mask size:	
 13300
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   3.2000e+02   3.2000e+02
        -inf         -inf   2.4194e+04   1.4257e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #149	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00016011/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 360
 640
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 640
 640
[torch.LongStorage of size 3]

x_start = 1 / y_start = 141	
img_means:size() vs img:size():	
   3
 360
 640
[torch.LongStorage of size 3]

   3
 360
 640
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6666666666667	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 360
 640
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6666666666667	
proposal_im_detect: scaled_img_size:	
    5
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1918.4041  -2158.8784  -2082.5232
  -2045.4698  -2278.5391  -2170.0376
  -2004.6587  -2194.8064  -2070.3206

(2,.,.) = 
   2871.9319   3035.4937   2923.5120
   3078.8857   3259.6841   3104.5159
   2972.0618   3120.9614   2951.3684

(3,.,.) = 
   3702.3613   4031.7642   4029.7476
   4538.7988   4954.0762   4944.2280
   4962.7793   5442.2568   5416.1636

(4,.,.) = 
   1058.5000   1179.1896   1156.4818
   1324.4774   1425.2716   1372.3020
   1439.6230   1493.4309   1399.7307

(5,.,.) = 
    754.4310    746.0018    666.6088
    740.6734    693.9136    586.7371
    757.2410    674.7653    565.1986

(6,.,.) = 
   1655.8843   1876.0651   1917.6849
   2031.9850   2341.7212   2384.3525
   2337.5300   2683.7207   2710.1941

(7,.,.) = 
  -2765.8250  -2938.0239  -2760.5569
  -2984.8787  -3136.7385  -2872.2498
  -2862.3643  -2939.5664  -2646.6504

(8,.,.) = 
   5791.6479   6203.3022   5958.1494
   6528.4038   6956.7158   6629.8784
   6793.6709   7167.8306   6792.1333

(9,.,.) = 
   2546.0896   3059.9280   3260.3960
   2932.3450   3460.3682   3588.5508
   3203.9517   3739.5474   3824.8745

(10,.,.) = 
  -3426.0103  -3383.4600  -3132.3345
  -3668.9065  -3633.2798  -3361.4448
  -3630.7239  -3586.1868  -3337.2954

(11,.,.) = 
    480.2852    640.2435    731.7606
    754.3660    944.3453   1031.7802
    844.8521   1081.3812   1171.5621

(12,.,.) = 
    447.6529    719.9573    955.1273
    516.7628    835.1855   1059.6685
    274.1199    591.7390    788.6779

(13,.,.) = 
  -2945.8694  -3114.1589  -3010.4463
  -2967.6404  -3123.1775  -3006.8125
  -2901.1257  -3047.4673  -2904.4163

(14,.,.) = 
   5076.4937   5377.7075   5179.1826
   5350.7300   5642.3354   5400.4204
   5294.2134   5608.9873   5336.2163

(15,.,.) = 
   3459.4575   3750.6655   3723.4314
   4030.3374   4418.6514   4367.3809
   4364.8550   4773.4365   4700.0234

(16,.,.) = 
  -2940.5491  -3020.5166  -3007.6191
  -3070.4666  -3184.5107  -3159.1426
  -3202.8491  -3344.7764  -3305.5278

(17,.,.) = 
  -7617.9380  -8015.2222  -7910.6279
  -8741.7891  -9248.7207  -9141.1074
  -9444.5596 -10013.4531  -9883.6768

(18,.,.) = 
   1649.4617   1597.4958   1500.6296
   1838.6930   1758.2684   1650.7897
   1833.5927   1739.2753   1635.3939
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3702.361328125	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #149: time = 0.430661	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   6.4000e+02   6.4000e+02
        -inf         -inf   3.6121e+04   2.1350e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #150	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00074001/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1915.7572 -2156.0881 -2079.9873
 -2042.5616 -2275.3127 -2167.0071
 -2001.7606 -2191.4651 -2067.2285

(2,.,.) = 
  2868.2410  3031.8535  2920.1978
  3074.8816  3255.5210  3100.8271
  2968.4573  3116.9983  2947.7605

(3,.,.) = 
  3693.4160  4023.2148  4022.5979
  4529.3115  4945.0327  4936.9424
  4953.9077  5434.0859  5410.0728

(4,.,.) = 
  1055.9625  1176.6367  1154.2957
  1321.0344  1422.1948  1369.7631
  1436.2068  1490.3969  1397.1658

(5,.,.) = 
   751.2527   742.7714   663.6932
   737.5289   690.6378   583.7678
   754.1409   671.6913   562.3789

(6,.,.) = 
  1651.7461  1871.6414  1913.8201
  2027.6040  2336.9634  2380.2183
  2333.1392  2679.0776  2706.2336

(7,.,.) = 
 -2761.1294 -2933.0317 -2755.6335
 -2979.9802 -3131.3943 -2867.0959
 -2858.0422 -2934.6240 -2641.5647

(8,.,.) = 
  5781.1748  6193.1895  5949.3481
  6517.7139  6946.3135  6621.2856
  6783.9951  7158.5386  6784.6284

(9,.,.) = 
  2540.3518  3054.2561  3255.3320
  2926.3711  3454.4966  3583.3479
  3198.5457  3734.2495  3820.2056

(10,.,.) = 
 -3419.8679 -3377.8101 -3127.6323
 -3662.7800 -3627.6479 -3356.7827
 -3625.5383 -3581.3098 -3333.3899

(11,.,.) = 
   480.4376   640.4513   732.0862
   754.0911   944.2273  1031.9590
   845.0596  1081.6521  1172.1495

(12,.,.) = 
   447.9444   720.1736   955.0645
   516.5032   834.6454  1058.8130
   273.5052   590.6441   787.0533

(13,.,.) = 
 -2942.3096 -3110.5698 -3007.4348
 -2964.7302 -3119.8569 -3003.9651
 -2898.3235 -3044.2175 -2901.6919

(14,.,.) = 
  5069.5483  5371.1943  5173.9185
  5344.0718  5636.0220  5395.2939
  5288.1885  5603.1230  5331.5244

(15,.,.) = 
  3451.8860  3743.1519  3716.9392
  4022.3857  4410.7539  4360.6938
  4357.1733  4765.9121  4693.9048

(16,.,.) = 
 -2933.5847 -3014.1877 -3002.5225
 -3063.0498 -3177.8396 -3154.0154
 -3195.8442 -3338.5779 -3301.0854

(17,.,.) = 
 -7601.6802 -8000.0938 -7898.4468
 -8724.2744 -9232.7178 -9128.4834
 -9427.8809 -9998.5820 -9872.8027

(18,.,.) = 
  1646.3567  1594.7686  1498.1501
  1835.3824  1755.5894  1648.4392
  1830.7042  1737.0063  1633.3827
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3693.416015625	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #150: time = 0.58440599999999	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2279e+04   4.2739e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #151	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00010003/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1920
 1920
[torch.LongStorage of size 3]

x_start = 1 / y_start = 421	
img_means:size() vs img:size():	
    3
 1080
 1920
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.55555555555556	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
 1080
 1920
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.55555555555556	
proposal_im_detect: scaled_img_size:	
    2
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1908.8228 -2147.9890 -2071.4321
 -2035.8005 -2267.5945 -2159.0281
 -1995.9247 -2185.0408 -2060.6272

(2,.,.) = 
  2858.9189  3021.3506  2909.0645
  3065.5044  3245.1323  3089.9329
  2959.8279  3107.9143  2938.5007

(3,.,.) = 
  3685.8872  4012.8569  4009.6543
  4521.8638  4934.7607  4923.7300
  4948.0425  5425.5820  5398.5649

(4,.,.) = 
  1054.8054  1174.6973  1151.5380
  1320.0370  1420.5173  1367.3535
  1436.1600  1489.9009  1395.9924

(5,.,.) = 
   750.8216   741.7280   662.0752
   737.4394   690.0457   582.7299
   754.3668   671.7890   562.4528

(6,.,.) = 
  1650.3691  1869.4033  1910.1093
  2026.4237  2334.5298  2376.2234
  2332.3882  2677.1074  2702.5718

(7,.,.) = 
 -2756.2139 -2927.1606 -2749.5403
 -2974.5286 -3125.2756 -2860.9238
 -2852.7832 -2928.9351 -2636.3201

(8,.,.) = 
  5769.0405  6177.7778  5931.7012
  6505.5396  6931.0991  6603.8872
  6773.3027  7145.2207  6769.4468

(9,.,.) = 
  2535.9421  3047.8669  3247.1506
  2922.3767  3448.7141  3575.9155
  3195.1580  3729.2986  3813.6877

(10,.,.) = 
 -3409.2026 -3366.6235 -3115.9473
 -3652.3335 -3616.7014 -3345.5361
 -3616.0845 -3571.7371 -3323.7146

(11,.,.) = 
   480.6300   640.0427   730.5294
   753.5076   943.0502  1029.8680
   844.3411  1080.4749  1170.2411

(12,.,.) = 
   447.2556   719.1224   952.7422
   515.5623   833.3092  1056.4286
   273.4219   590.3640   785.9845

(13,.,.) = 
 -2934.4058 -3101.9570 -2998.3132
 -2957.3459 -3112.3462 -2996.4255
 -2891.4614 -3037.3044 -2894.7722

(14,.,.) = 
  5056.4248  5356.0039  5157.2031
  5331.3267  5621.5552  5379.8506
  5276.7461  5590.2661  5317.9087

(15,.,.) = 
  3446.0581  3735.3875  3706.9824
  4017.2559  4403.5635  4351.2070
  4353.4858  4760.3633  4685.8574

(16,.,.) = 
 -2925.9702 -3004.6182 -2990.9014
 -3057.4624 -3170.4089 -3144.5703
 -3192.3777 -3333.7913 -3294.4622

(17,.,.) = 
 -7586.2646 -7980.1021 -7873.6289
 -8710.7197 -9214.5361 -9105.2471
 -9417.3877 -9983.9463 -9853.1348

(18,.,.) = 
  1641.8649  1589.4941  1492.5459
  1830.5350  1749.9241  1642.5453
  1826.4054  1732.1891  1628.6041
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3685.8872070312	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #151: time = 0.833089	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.9200e+03   1.9200e+03
        -inf         -inf   1.0831e+05   6.4148e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #152	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00001004/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1913.8785 -2154.0444 -2078.0791
 -2040.5382 -2273.1519 -2165.0293
 -1999.7928 -2189.3745 -2065.3574

(2,.,.) = 
  2865.4797  3029.0264  2917.5747
  3071.8933  3252.4617  3098.0378
  2965.5601  3114.0535  2945.1040

(3,.,.) = 
  3689.6335  4019.2742  4018.8809
  4524.7388  4940.2637  4932.4756
  4949.0000  5428.9556  5405.2739

(4,.,.) = 
  1054.8806  1175.4847  1153.2245
  1319.7025  1420.8430  1368.5446
  1434.8013  1489.0376  1395.9840

(5,.,.) = 
   750.4552   742.0008   663.0422
   736.7452   689.9197   583.1923
   753.3625   671.0088   561.8554

(6,.,.) = 
  1650.1304  1869.8875  1912.1552
  2025.6621  2334.8123  2378.1914
  2330.9338  2676.6560  2703.9551

(7,.,.) = 
 -2758.5542 -2930.3914 -2753.2737
 -2977.1763 -3128.5642 -2864.6565
 -2855.3806 -2932.0151 -2639.3621

(8,.,.) = 
  5775.4927  6187.3594  5943.9907
  6511.3472  6939.8179  6615.4302
  6777.4478  7151.9268  6778.7104

(9,.,.) = 
  2537.8630  3051.3923  3252.4185
  2923.4961  3451.2861  3580.1936
  3195.4729  3730.8420  3816.9163

(10,.,.) = 
 -3416.4873 -3374.5779 -3124.7456
 -3659.1516 -3624.1914 -3353.7214
 -3621.9758 -3577.9185 -3330.3865

(11,.,.) = 
   479.9692   639.8696   731.4555
   753.3834   943.4019  1031.0903
   844.3178  1080.7386  1171.1725

(12,.,.) = 
   447.6731   719.6760   954.3517
   516.1818   834.0743  1058.0422
   273.4382   590.2914   786.5338

(13,.,.) = 
 -2939.4951 -3107.6775 -3004.7385
 -2961.8979 -3116.9524 -3001.2825
 -2895.5454 -3041.3735 -2899.1084

(14,.,.) = 
  5064.6694  5366.1855  5169.2729
  5338.9307  5630.7856  5390.4766
  5283.1284  5597.9419  5326.7974

(15,.,.) = 
  3448.4243  3739.5786  3713.5825
  4018.4077  4406.6055  4356.8511
  4352.9336  4761.5039  4689.8311

(16,.,.) = 
 -2930.6011 -3011.2151 -2999.7073
 -3059.9255 -3174.7319 -3151.0896
 -3192.6150 -3335.3547 -3298.0906

(17,.,.) = 
 -7594.0884 -7992.4126 -7891.1973
 -8715.6025 -9223.9570 -9120.2725
 -9418.6387 -9989.2363 -9864.0742

(18,.,.) = 
  1644.7616  1593.2655  1496.8024
  1833.6117  1753.9640  1646.9669
  1828.9620  1735.4222  1631.9487
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3689.6335449219	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #152: time = 0.611847	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2218e+04   4.2707e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #153	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00044001/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1907.8788 -2147.2771 -2071.3235
 -2034.7993 -2266.5676 -2158.3835
 -1995.2169 -2183.8391 -2059.7542

(2,.,.) = 
  2857.0259  3019.7412  2908.4634
  3063.7107  3243.2268  3088.9932
  2958.7949  3106.2786  2937.4326

(3,.,.) = 
  3677.6521  4007.3010  4007.2488
  4511.3818  4926.2578  4918.7939
  4935.9976  5414.7705  5391.1855

(4,.,.) = 
  1051.2303  1171.6132  1149.4646
  1315.1178  1416.4601  1364.1881
  1430.5814  1484.8624  1391.6154

(5,.,.) = 
   746.3790   737.7058   658.9075
   733.5273   686.4707   579.7802
   751.4672   668.9099   559.5321

(6,.,.) = 
  1645.4503  1864.4926  1906.6051
  2020.3289  2328.5828  2371.8423
  2323.6396  2668.3125  2695.4336

(7,.,.) = 
 -2751.8635 -2922.7778 -2745.5542
 -2969.8948 -3120.4358 -2856.7092
 -2848.7051 -2924.5879 -2632.0884

(8,.,.) = 
  5759.5225  6170.1343  5926.8945
  6495.3564  6922.5474  6598.4355
  6763.0972  7136.1660  6762.8921

(9,.,.) = 
  2531.6191  3044.1345  3244.6172
  2915.7656  3442.8149  3571.3416
  3188.1328  3722.6650  3808.2068

(10,.,.) = 
 -3407.8606 -3365.6812 -3116.0271
 -3651.9080 -3616.2539 -3345.6458
 -3616.2368 -3571.3865 -3323.3057

(11,.,.) = 
   479.7342   639.1952   730.4437
   752.6811   942.5404  1030.0421
   843.1504  1079.2723  1169.7001

(12,.,.) = 
   447.1254   718.8259   953.0012
   514.5840   832.1301  1055.8579
   271.5630   587.9553   784.3144

(13,.,.) = 
 -2932.4458 -3099.6023 -2996.7463
 -2955.9546 -3109.9929 -2994.2334
 -2891.1370 -3036.0576 -2893.5151

(14,.,.) = 
  5051.9492  5352.0723  5155.3589
  5327.8604  5618.2686  5377.8232
  5274.2573  5587.7549  5316.2563

(15,.,.) = 
  3438.2703  3728.8225  3702.8259
  4008.0010  4395.1187  4345.2222
  4342.3716  4749.7451  4677.7876

(16,.,.) = 
 -2920.4976 -3000.6431 -2989.3250
 -3051.0776 -3165.3330 -3141.9670
 -3186.1875 -3328.3181 -3291.0920

(17,.,.) = 
 -7571.1929 -7968.6987 -7867.9614
 -8691.5586 -9198.6475 -9094.6553
 -9396.2549 -9964.8232 -9838.9629

(18,.,.) = 
  1639.4896  1588.0878  1491.6769
  1828.4955  1748.6860  1641.4302
  1825.0952  1731.2235  1627.4602
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3677.6520996094	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #153: time = 0.62564500000001	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2166e+04   4.2674e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #154	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0001/ILSVRC2015_train_00257000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1916.0842  -2156.6841  -2080.8713
  -2043.1926  -2276.3213  -2168.3835
  -2002.6573  -2192.8965  -2068.9587

(2,.,.) = 
   2868.7012   3032.6938   2921.5593
   3075.6050   3256.7942   3102.5168
   2969.1924   3118.4053   2949.6646

(3,.,.) = 
   3699.7703   4030.1384   4029.4692
   4536.0820   4952.6206   4944.5171
   4960.3242   5441.2505   5417.1538

(4,.,.) = 
   1058.2593   1179.2728   1156.9268
   1323.9701   1425.2938   1372.8422
   1439.0981   1493.5546   1400.3622

(5,.,.) = 
    753.0356    744.7313    665.6349
    739.3250    692.7576    585.9053
    755.8932    673.6993    564.5574

(6,.,.) = 
   1655.3755   1875.8859   1918.0653
   2031.3890   2341.4270   2384.7480
   2336.7664   2683.3425   2710.5603

(7,.,.) = 
  -2763.1843  -2935.6626  -2758.8848
  -2982.2690  -3134.3857  -2870.6313
  -2860.2622  -2937.6252  -2645.2834

(8,.,.) = 
   5787.3833   6200.1284   5956.7070
   6524.3286   6953.8774   6629.1802
   6790.2822   7165.8784   6792.4258

(9,.,.) = 
   2544.4089   3058.7085   3259.9746
   2930.9316   3459.4753   3588.5098
   3202.7400   3738.8745   3825.0635

(10,.,.) = 
  -3422.2366  -3380.6624  -3130.9646
  -3665.3425  -3630.7114  -3360.3284
  -3628.0088  -3584.3877  -3336.9351

(11,.,.) = 
    481.0790    641.1434    732.6408
    754.8517    944.9979   1032.6306
    845.3801   1082.0536   1172.5156

(12,.,.) = 
    447.5310    719.8519    954.8092
    516.4372    834.7485   1059.0266
    273.9001    591.3012    787.9880

(13,.,.) = 
  -2942.7446  -3111.2659  -3008.4014
  -2964.9084  -3120.5312  -3005.0220
  -2898.7256  -3045.1062  -2902.8657

(14,.,.) = 
   5071.7974   5373.8335   5176.9033
   5346.4175   5638.8081   5398.5825
   5290.7905   5606.3115   5335.2427

(15,.,.) = 
   3457.5476   3749.6292   3723.5369
   4028.4812   4417.7637   4367.8594
   4363.2148   4772.9058   4701.0059

(16,.,.) = 
  -2937.5278  -3018.4114  -3006.7285
  -3067.6726  -3182.6672  -3158.6250
  -3200.3838  -3343.3809  -3305.6423

(17,.,.) = 
  -7612.5435  -8011.9185  -7910.2114
  -8736.2939  -9245.7842  -9141.6396
  -9439.6299 -10011.4580  -9885.6055

(18,.,.) = 
   1647.5800   1596.1272   1499.8280
   1836.8098   1757.0571   1650.2493
   1832.1877   1738.5754   1635.3175
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3699.7702636719	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #154: time = 0.59114799999999	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2352e+04   4.2808e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #155	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00017003/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1916.8868  -2157.3694  -2081.2708
  -2043.8768  -2276.8127  -2168.5012
  -2003.2346  -2193.1555  -2068.8665

(2,.,.) = 
   2869.8635   3033.6416   2922.0298
   3076.7505   3257.6121   3102.8904
   2970.3894   3119.1785   2949.9009

(3,.,.) = 
   3697.2871   4027.2407   4026.3704
   4533.9453   4949.9312   4941.5381
   4959.0532   5439.4907   5415.0542

(4,.,.) = 
   1057.1382   1177.8801   1155.4028
   1322.6385   1423.7716   1371.1715
   1437.9932   1492.1960   1398.8030

(5,.,.) = 
    752.2073    743.7575    664.6403
    738.5528    691.7251    584.7854
    755.3015    672.8527    563.4603

(6,.,.) = 
   1653.6318   1873.7311   1915.8057
   2029.8723   2339.5093   2382.6309
   2335.7490   2681.9524   2708.9241

(7,.,.) = 
  -2763.0408  -2935.1873  -2757.8281
  -2982.1838  -3133.8604  -2869.5203
  -2860.3787  -2937.2163  -2644.1296

(8,.,.) = 
   5785.9194   6198.1592   5954.0718
   6523.2769   6952.1626   6626.7598
   6790.1411   7164.9658   6790.5889

(9,.,.) = 
   2542.8269   3056.9905   3258.0212
   2929.2703   3457.6836   3586.4626
   3201.6738   3737.7048   3823.5928

(10,.,.) = 
  -3422.5110  -3380.5198  -3130.2231
  -3665.7649  -3630.6848  -3359.6938
  -3628.6975  -3584.5278  -3336.4165

(11,.,.) = 
    480.8568    640.9305    732.5170
    754.7966    944.9821   1032.6272
    845.7194   1082.4236   1172.8442

(12,.,.) = 
    448.0213    720.3953    955.3837
    516.6980    835.0311   1059.2885
    273.6923    591.0752    787.6481

(13,.,.) = 
  -2943.8430  -3112.2705  -3009.0947
  -2966.2083  -3121.5889  -3005.7085
  -2900.0251  -3046.1636  -2903.5903

(14,.,.) = 
   5072.7651   5374.5791   5177.1719
   5347.6304   5639.7739   5398.9067
   5292.1382   5607.3105   5335.5234

(15,.,.) = 
   3455.3643   3746.8589   3720.4302
   4026.5244   4415.2080   4364.8940
   4361.8696   4770.9404   4698.5854

(16,.,.) = 
  -2936.4651  -3017.0872  -3005.2278
  -3066.3826  -3181.1663  -3157.0391
  -3199.4714  -3342.2031  -3304.3516

(17,.,.) = 
  -7608.9434  -8007.4746  -7905.2651
  -8732.9131  -9241.5039  -9136.6641
  -9437.5664 -10008.4277  -9881.8311

(18,.,.) = 
   1647.6014   1596.0221   1499.4257
   1836.8594   1757.0012   1649.8237
   1832.2925   1738.4885   1634.8260
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3697.287109375	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #155: time = 0.573362	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2364e+04   4.2798e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #156	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00133001/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1915.8868  -2156.3032  -2080.2898
  -2042.7450  -2275.5979  -2167.3867
  -2002.0032  -2191.8152  -2067.6550

(2,.,.) = 
   2868.4636   3032.1836   2920.6440
   3075.1655   3255.9307   3101.3164
   2968.7642   3117.4453   2948.2866

(3,.,.) = 
   3694.8350   4024.7529   4024.1313
   4530.8862   4946.7749   4938.6982
   4955.4399   5435.8018   5411.7861

(4,.,.) = 
   1056.5040   1177.2938   1154.9490
   1321.6726   1422.9062   1370.4668
   1436.8019   1491.0684   1397.8109

(5,.,.) = 
    751.4672    742.9919    663.9517
    737.7025    690.8434    584.0198
    754.2795    671.8481    562.6193

(6,.,.) = 
   1652.5037   1872.4868   1914.6206
   2028.4095   2337.8806   2381.1047
   2333.9365   2679.9824   2707.1128

(7,.,.) = 
  -2761.4524  -2933.5305  -2756.2708
  -2980.3342  -3131.9700  -2867.7720
  -2858.3628  -2935.1592  -2642.2202

(8,.,.) = 
   5782.6221   6194.8882   5951.1133
   6519.3076   6948.1553   6623.2041
   6785.5215   7160.3550   6786.4932

(9,.,.) = 
   2541.1973   3055.2803   3256.4187
   2927.3784   3455.7056   3584.6052
   3199.5591   3735.4475   3821.4412

(10,.,.) = 
  -3420.4614  -3378.5374  -3128.4316
  -3663.4275  -3628.4165  -3357.6064
  -3626.1924  -3582.0774  -3334.2085

(11,.,.) = 
    480.7499    640.8074    732.4091
    754.4233    944.5848   1032.2908
    845.3138   1081.9680   1172.4467

(12,.,.) = 
    447.9032    720.2170    955.1571
    516.4906    834.7235   1058.9709
    273.5488    590.7781    787.2524

(13,.,.) = 
  -2942.5288  -3110.9199  -3007.8606
  -2964.9448  -3120.2271  -3004.4431
  -2898.5979  -3044.6362  -2902.1724

(14,.,.) = 
   5070.2935   5372.1362   5174.9604
   5344.8926   5637.0337   5396.4268
   5289.0728   5604.2124   5332.7036

(15,.,.) = 
   3453.1797   3744.6348   3718.4014
   4023.7891   4412.3599   4362.2710
   4358.5444   4767.4932   4695.4600

(16,.,.) = 
  -2934.5061  -3015.1965  -3003.5132
  -3064.0994  -3178.9500  -3155.0647
  -3196.9016  -3339.7119  -3302.1672

(17,.,.) = 
  -7604.3472  -8002.9917  -7901.3018
  -8727.2188  -9235.9326  -9131.6738
  -9430.7676 -10001.7842  -9875.9365

(18,.,.) = 
   1646.5923   1595.0524   1498.4965
   1835.6401   1755.8932   1648.7990
   1830.9751   1737.3309   1633.7714
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3694.8349609375	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #156: time = 0.605124	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2297e+04   4.2751e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #157	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00067001/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1903.7391 -2143.0457 -2067.7507
 -2030.8029 -2262.6206 -2155.3462
 -1991.4819 -2180.7107 -2057.9934

(2,.,.) = 
  2851.0659  3013.9087  2903.3416
  3057.4329  3237.2661  3084.3154
  2953.4519  3101.6470  2934.3728

(3,.,.) = 
  3669.3604  3999.3069  4001.5938
  4504.2690  4920.2993  4915.4810
  4931.4551  5412.1089  5391.4775

(4,.,.) = 
  1049.5782  1170.4617  1149.3086
  1313.9329  1416.0978  1365.2950
  1430.3356  1485.7113  1393.8732

(5,.,.) = 
   745.6587   737.2040   658.7247
   732.9967   686.3792   580.1504
   750.2663   668.5072   560.1264

(6,.,.) = 
  1642.0135  1861.1426  1904.1324
  2017.0271  2325.0686  2369.1584
  2322.4202  2667.4062  2695.5776

(7,.,.) = 
 -2747.0547 -2917.7952 -2741.4297
 -2965.5693 -3116.0251 -2853.2917
 -2845.5815 -2921.8010 -2630.2651

(8,.,.) = 
  5750.0244  6161.6890  5921.3760
  6486.9194  6915.5718  6595.0605
  6756.6938  7132.1265  6762.7441

(9,.,.) = 
  2525.2104  3037.5220  3239.3564
  2911.7446  3438.6733  3568.6340
  3185.3870  3720.1943  3807.3813

(10,.,.) = 
 -3399.3298 -3358.3428 -3110.7568
 -3643.3030 -3609.3103 -3340.8770
 -3609.5029 -3566.3772 -3320.7776

(11,.,.) = 
   479.6909   639.5252   731.0357
   751.4833   941.3336  1029.1915
   842.7451  1078.7677  1169.3113

(12,.,.) = 
   445.6060   716.3915   949.8031
   512.6173   828.9883  1051.8608
   270.8439   586.2653   781.5688

(13,.,.) = 
 -2925.3850 -3092.7712 -2990.9324
 -2950.1602 -3104.3328 -2989.7080
 -2885.5840 -3030.9148 -2889.7773

(14,.,.) = 
  5041.5781  5342.8042  5148.3701
  5318.1812  5609.9551  5372.2085
  5266.0786  5581.0254  5312.5288

(15,.,.) = 
  3432.5071  3723.8323  3699.9250
  4003.0142  4391.3379  4343.9263
  4339.3032  4748.3745  4679.0889

(16,.,.) = 
 -2913.5073 -2995.2156 -2986.0366
 -3045.1926 -3161.2156 -3140.2244
 -3180.9963 -3325.0098 -3290.3096

(17,.,.) = 
 -7554.9331 -7954.5791 -7858.7056
 -8678.2197 -9188.6104 -9090.6172
 -9386.5947 -9959.7754 -9840.4189

(18,.,.) = 
  1636.8052  1585.8601  1490.2122
  1825.7982  1747.0071  1640.8944
  1822.6730  1730.0057  1627.4010
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3669.3603515625	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #157: time = 0.535584	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2188e+04   4.2697e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #158	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00014003/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1920
 1920
[torch.LongStorage of size 3]

x_start = 1 / y_start = 421	
img_means:size() vs img:size():	
    3
 1080
 1920
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.55555555555556	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
 1080
 1920
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.55555555555556	
proposal_im_detect: scaled_img_size:	
    2
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1907.7766 -2147.0730 -2071.2310
 -2033.3969 -2265.0798 -2157.1218
 -1992.2147 -2180.7915 -2057.0073

(2,.,.) = 
  2856.3696  3019.2578  2907.8816
  3061.5786  3241.2134  3087.1208
  2955.1379  3102.6082  2933.9321

(3,.,.) = 
  3671.2925  3999.3047  3999.0894
  4503.0098  4916.4336  4908.8477
  4925.6567  5403.4004  5380.1479

(4,.,.) = 
  1048.9601  1168.8306  1146.6991
  1312.1902  1412.8125  1360.7867
  1426.7839  1480.5331  1387.8684

(5,.,.) = 
   746.3333   737.6796   659.0560
   732.4432   685.3865   579.0391
   748.8745   666.4444   557.5159

(6,.,.) = 
  1641.0370  1859.5696  1901.8435
  2015.2219  2322.8296  2366.1982
  2319.5815  2663.6702  2691.0996

(7,.,.) = 
 -2747.6497 -2918.5027 -2741.5798
 -2965.1875 -3115.5618 -2852.2471
 -2843.5190 -2919.2681 -2627.1465

(8,.,.) = 
  5750.1748  6160.0879  5917.3472
  6482.7700  6909.0479  6585.7500
  6747.6582  7120.0425  6748.0259

(9,.,.) = 
  2525.1968  3036.7104  3237.0295
  2908.8711  3434.5037  3562.9326
  3180.1885  3713.3303  3798.9673

(10,.,.) = 
 -3403.1038 -3361.0544 -3111.7949
 -3644.4470 -3609.3008 -3339.5256
 -3607.1409 -3562.7896 -3315.8318

(11,.,.) = 
   477.4418   636.7677   728.2292
   750.0743   939.4886  1026.9989
   841.0573  1076.6599  1166.8881

(12,.,.) = 
   447.1555   718.4290   952.4769
   515.2498   832.1893  1055.5070
   272.5977   588.3345   783.8328

(13,.,.) = 
 -2929.7737 -3097.3489 -2994.6704
 -2951.9851 -3106.1760 -2990.6250
 -2885.4058 -3030.3491 -2888.3384

(14,.,.) = 
  5046.0884  5346.4639  5150.1685
  5318.8364  5609.4663  5369.7349
  5262.4697  5575.7778  5305.2104

(15,.,.) = 
  3431.0896  3720.5554  3694.7192
  3998.5430  4384.6699  4335.1914
  4331.7280  4738.1392  4666.9175

(16,.,.) = 
 -2917.3049 -2997.3984 -2986.0967
 -3045.0410 -3159.2446 -3135.9478
 -3176.9949 -3318.8940 -3282.0347

(17,.,.) = 
 -7558.2026 -7954.4932 -7854.0557
 -8674.1826 -9180.0586 -9077.0312
 -9374.2910 -9942.1865 -9817.9521

(18,.,.) = 
  1638.3988  1587.0111  1490.7344
  1826.3119  1746.9543  1640.1368
  1821.2864  1728.0338  1624.7001
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3671.2924804688	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #158: time = 0.740065	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.9200e+03   1.9200e+03
        -inf         -inf   1.0783e+05   6.3755e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #159	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00015000/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 720
 960
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 960
 960
[torch.LongStorage of size 3]

x_start = 1 / y_start = 121	
img_means:size() vs img:size():	
   3
 720
 960
[torch.LongStorage of size 3]

   3
 720
 960
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
   3
 600
 800
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x97
  2 : CudaTensor - size: 18x72x97
  3 : CudaTensor - size: 18x70x95
  4 : CudaTensor - size: 18x68x93
  5 : CudaTensor - size: 256x74x99
}
proposal_im_deteect: img_blob size:    3
 600
 800
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 720
 960
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
   3
 600
 800
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1922.9482  -2165.5164  -2089.7327
  -2052.6619  -2287.6318  -2179.8770
  -2012.8799  -2204.8411  -2080.8508

(2,.,.) = 
   2879.1975   3044.9656   2934.7874
   3088.8113   3272.5835   3118.6924
   2983.0332   3134.7437   2966.4756

(3,.,.) = 
   3736.3704   4070.3430   4069.3313
   4580.7944   5002.0786   4993.7227
   5007.8315   5494.1138   5469.2290

(4,.,.) = 
   1074.1559   1197.2955   1174.6837
   1341.6244   1444.8933   1392.0428
   1456.7090   1512.7035   1418.2924

(5,.,.) = 
    762.1594    753.6974    673.3206
    748.6541    702.3121    594.4273
    764.3426    682.5202    573.5282

(6,.,.) = 
   1678.3292   1902.1619   1944.3783
   2058.1265   2371.8647   2415.2732
   2365.0222   2715.7617   2742.8735

(7,.,.) = 
  -2785.5234  -2959.9780  -2783.3298
  -3007.0435  -3161.4885  -2897.1587
  -2884.0315  -2963.3223  -2670.1816

(8,.,.) = 
   5839.4575   6256.1836   6011.1240
   6582.9546   7016.8149   6689.9214
   6848.7983   7228.7979   6852.6685

(9,.,.) = 
   2571.5024   3090.8948   3294.6621
   2964.1375   3497.8994   3628.6272
   3236.1260   3776.9709   3864.0286

(10,.,.) = 
  -3436.5352  -3396.0139  -3147.0972
  -3681.9417  -3648.9155  -3378.4358
  -3646.6240  -3604.7620  -3357.7258

(11,.,.) = 
    490.1668    651.8012    742.3957
    763.6647    955.1917   1042.5155
    854.2639   1093.0204   1183.6066

(12,.,.) = 
    448.7359    723.7746    959.5756
    518.2939    839.6907   1065.0236
    276.8574    597.3748    795.1155

(13,.,.) = 
  -2956.7097  -3126.5266  -3024.8125
  -2981.8457  -3139.3906  -3025.5190
  -2916.3081  -3064.2585  -2922.7561

(14,.,.) = 
   5101.6919   5406.6616   5209.8076
   5379.9580   5674.9819   5435.1855
   5325.6016   5643.9341   5372.8403

(15,.,.) = 
   3496.0798   3792.2715   3765.3550
   4072.3105   4466.2378   4415.3086
   4408.1011   4822.4502   4749.0557

(16,.,.) = 
  -2956.8794  -3039.5083  -3028.5291
  -3092.1184  -3208.7751  -3185.0603
  -3226.9695  -3372.4827  -3335.0405

(17,.,.) = 
  -7684.1416  -8088.1914  -7985.7578
  -8818.4375  -9334.4023  -9230.1211
  -9525.8115 -10104.8818  -9978.4814

(18,.,.) = 
   1655.1227   1603.6588   1507.6058
   1846.3962   1766.5442   1660.3737
   1843.7590   1750.3091   1647.7323
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 95
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 19950
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 95
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 95
[torch.LongStorage of size 2]

shift_y size:	
 70
 95
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6650
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 19950
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  19950
[torch.LongStorage of size 1]
	
  first line: 3736.3703613281	
(fast bbox transform) src_w size:  19950
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 19950
     4
[torch.LongStorage of size 2]

scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 19950
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 53200
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13300
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13300
[torch.LongStorage of size 1]

test img #159: time = 0.38942899999999	
(proposal_test:boxes_filter) boxes & scores size:	
 13300
     4
[torch.LongStorage of size 2]

 13300
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 953
   3
[torch.LongTensor of size 2]

mask size:	
 13300
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   9.6000e+02   9.6000e+02
        -inf         -inf   7.2988e+04   4.3044e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #160	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00046002/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1905.8453 -2144.3250 -2067.9683
 -2030.8779 -2261.8354 -2153.2678
 -1989.6744 -2177.7649 -2053.6316

(2,.,.) = 
  2853.5627  3015.6091  2903.4172
  3058.2695  3237.0391  3082.2280
  2951.9822  3098.8196  2929.6565

(3,.,.) = 
  3663.7224  3989.5530  3987.9670
  4494.7539  4906.1372  4897.3774
  4917.4614  5393.6416  5369.8052

(4,.,.) = 
  1046.3601  1165.3749  1142.6377
  1309.0106  1408.7344  1356.1877
  1423.5859  1476.6176  1383.6865

(5,.,.) = 
   744.8645   735.7015   656.8287
   730.9521   683.4106   576.9577
   747.4639   664.7341   555.7936

(6,.,.) = 
  1636.5099  1854.2461  1896.0061
  2010.5281  2317.3745  2360.3274
  2314.9849  2658.3481  2685.5349

(7,.,.) = 
 -2743.2478 -2913.1543 -2735.4695
 -2960.4006 -3109.9021 -2846.0854
 -2839.1404 -2914.3481 -2622.1260

(8,.,.) = 
  5739.9595  6147.4702  5902.9663
  6471.5264  6895.6177  6571.2124
  6737.0234  7107.9209  6735.6133

(9,.,.) = 
  2519.4446  3029.2651  3227.8103
  2902.6003  3426.6809  3553.7322
  3174.4668  3706.5828  3791.3450

(10,.,.) = 
 -3399.2346 -3356.4001 -3106.2781
 -3639.8267 -3604.0378 -3333.8479
 -3602.3386 -3557.6638 -3310.4668

(11,.,.) = 
   476.2688   635.5911   727.1107
   748.6537   937.9376  1025.4564
   839.7470  1075.1202  1165.2354

(12,.,.) = 
   446.9762   718.0684   951.9915
   514.7006   831.2606  1054.3987
   272.1569   587.4320   782.5878

(13,.,.) = 
 -2926.8022 -3093.7810 -2990.3416
 -2948.5374 -3102.1584 -2985.8594
 -2881.9148 -3026.4812 -2884.0422

(14,.,.) = 
  5039.8662  5338.8315  5141.2520
  5311.7212  5601.3042  5360.4844
  5255.3276  5567.8550  5296.7490

(15,.,.) = 
  3423.7229  3711.3347  3684.2773
  3990.7153  4375.1558  4324.6289
  4324.1201  4729.3643  4657.6753

(16,.,.) = 
 -2913.0513 -2991.8599 -2979.2629
 -3040.1001 -3153.1887 -3128.9155
 -3171.9705 -3313.0146 -3275.5269

(17,.,.) = 
 -7544.5244 -7937.3745 -7834.1655
 -8659.2764 -9161.9814 -9056.4033
 -9359.1455 -9924.7666 -9799.1602

(18,.,.) = 
  1636.5366  1584.5693  1487.7698
  1823.9194  1744.1335  1636.9716
  1818.7958  1725.3771  1621.7990
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3663.7224121094	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #160: time = 0.543581	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1775e+04   4.2437e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #161	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00026000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1908.0696 -2147.4500 -2071.5957
 -2033.8621 -2265.7195 -2158.0015
 -1992.0216 -2180.9192 -2057.4253

(2,.,.) = 
  2856.2644  3019.4976  2908.3513
  3061.2620  3241.6550  3087.7886
  2953.9482  3102.3599  2934.2185

(3,.,.) = 
  3677.3789  4005.1343  4004.0059
  4509.2720  4922.4990  4913.8735
  4930.7988  5408.3682  5383.9541

(4,.,.) = 
  1052.5436  1172.4000  1149.7572
  1316.5087  1416.8892  1364.3419
  1430.2671  1483.8046  1390.6355

(5,.,.) = 
   748.6089   739.9910   661.1494
   734.5205   687.7700   581.5751
   750.2617   668.2451   559.9648

(6,.,.) = 
  1644.5955  1863.8518  1905.8285
  2018.3717  2326.9314  2370.1326
  2322.3027  2667.2854  2694.4287

(7,.,.) = 
 -2749.5210 -2920.8689 -2744.1809
 -2966.2886 -3117.5310 -2854.7561
 -2843.1365 -2919.8875 -2628.8142

(8,.,.) = 
  5756.7334  6166.7485  5923.1665
  6488.1753  6914.8555  6590.9746
  6749.4248  7122.3286  6750.2686

(9,.,.) = 
  2529.1736  3040.8950  3241.0918
  2912.8804  3438.8716  3567.2634
  3182.1899  3715.5386  3801.0996

(10,.,.) = 
 -3403.4927 -3361.9619 -3113.0381
 -3643.7808 -3609.5195 -3340.3694
 -3604.5911 -3561.2822 -3315.2986

(11,.,.) = 
   478.4875   637.8868   728.8528
   750.7134   940.0731  1027.1722
   841.2017  1076.8727  1166.7667

(12,.,.) = 
   447.0198   718.5321   952.4890
   515.7007   832.9734  1056.2321
   273.9414   590.1970   785.8358

(13,.,.) = 
 -2930.0376 -3098.0425 -2995.6792
 -2951.1902 -3106.3618 -2991.7012
 -2883.0356 -3028.9219 -2887.9973

(14,.,.) = 
  5048.1665  5348.8892  5152.4028
  5319.2495  5610.6133  5371.3408
  5260.0034  5574.1680  5304.5918

(15,.,.) = 
  3437.4951  3727.2170  3700.4683
  4004.5029  4391.0498  4340.6748
  4335.5957  4742.3188  4670.3315

(16,.,.) = 
 -2920.6538 -3000.8499 -2989.2151
 -3048.7961 -3163.1685 -3139.4983
 -3179.2444 -3321.4736 -3284.2278

(17,.,.) = 
 -7570.5820 -7966.5557 -7864.1577
 -8686.6514 -9192.4404 -9087.8164
 -9382.7354 -9950.6172 -9824.9824

(18,.,.) = 
  1638.7775  1587.3745  1491.1990
  1826.4631  1747.1165  1640.7056
  1821.3212  1728.4286  1625.6301
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3677.37890625	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #161: time = 0.55458399999999	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1722e+04   4.2400e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #162	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00002000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 480
 480
[torch.LongStorage of size 3]

x_start = 1 / y_start = 61	
img_means:size() vs img:size():	
   3
 360
 480
[torch.LongStorage of size 3]

   3
 360
 480
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6666666666667	
(orep_img_for_blob) img size after scaling:	
   3
 600
 800
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x97
  2 : CudaTensor - size: 18x72x97
  3 : CudaTensor - size: 18x70x95
  4 : CudaTensor - size: 18x68x93
  5 : CudaTensor - size: 256x74x99
}
proposal_im_deteect: img_blob size:    3
 600
 800
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 360
 480
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6666666666667	
proposal_im_detect: scaled_img_size:	
   5
 600
 800
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1926.1697  -2169.1963  -2093.4539
  -2056.6257  -2292.0149  -2184.1902
  -2017.4381  -2209.7637  -2085.6433

(2,.,.) = 
   2883.9700   3050.1543   2939.9897
   3094.5181   3278.7288   3124.7307
   2989.2969   3141.3733   2972.9365

(3,.,.) = 
   3744.5474   4079.5439   4078.4067
   4590.8062   5013.2134   5004.6504
   5019.1753   5506.4858   5481.1523

(4,.,.) = 
   1076.6681   1200.0447   1177.2258
   1345.0432   1448.4705   1395.2512
   1460.6157   1516.7579   1421.8420

(5,.,.) = 
    763.9405    755.6483    675.2274
    750.7670    704.4947    596.3864
    766.9560    685.0545    575.7372

(6,.,.) = 
   1682.0021   1906.2737   1948.4231
   2062.4966   2376.7998   2420.0210
   2370.0413   2721.4602   2748.2866

(7,.,.) = 
  -2790.8462  -2965.4553  -2788.6199
  -3013.3450  -3167.9336  -2903.1191
  -2890.8816  -2970.2781  -2676.5659

(8,.,.) = 
   5851.5635   6269.1543   6023.7461
   6597.3721   7032.1001   6704.4077
   6864.8486   7245.5415   6868.2534

(9,.,.) = 
   2577.1982   3097.3936   3301.3506
   2970.8975   3505.5356   3636.2830
   3243.6753   3785.3926   3872.6099

(10,.,.) = 
  -3443.6602  -3402.9690  -3153.7073
  -3690.1658  -3656.8638  -3385.9399
  -3655.2239  -3613.0566  -3365.4529

(11,.,.) = 
    491.4895    653.3849    743.9720
    765.3615    957.2087   1044.5315
    855.8299   1094.9865   1185.6190

(12,.,.) = 
    449.2610    724.6430    960.8314
    518.8130    840.7217   1066.5693
    277.1090    598.2609    796.7389

(13,.,.) = 
  -2961.8113  -3131.8621  -3030.0884
  -2987.4324  -3145.2510  -3031.3521
  -2922.4038  -3070.6565  -2929.0437

(14,.,.) = 
   5111.4209   5416.9048   5219.8232
   5391.1265   5686.6255   5446.4531
   5337.6792   5656.4849   5384.8706

(15,.,.) = 
   3503.8472   3800.7781   3773.7417
   4081.6248   4476.3584   4425.1304
   4418.5591   4833.6807   4759.7578

(16,.,.) = 
  -2963.2395  -3046.1707  -3035.1628
  -3099.4683  -3216.3491  -3192.4958
  -3235.0732  -3380.8462  -3343.0842

(17,.,.) = 
  -7700.2520  -8105.4766  -8002.8506
  -8837.8096  -9354.9502  -9250.1699
  -9547.6738 -10127.7705 -10000.3340

(18,.,.) = 
   1658.5387   1606.9261   1510.7059
   1850.4469   1770.3342   1663.9211
   1848.1344   1754.3578   1651.4814
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 95
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 19950
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 95
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 95
[torch.LongStorage of size 2]

shift_y size:	
 70
 95
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6650
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 19950
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  19950
[torch.LongStorage of size 1]
	
  first line: 3744.5473632812	
(fast bbox transform) src_w size:  19950
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 19950
     4
[torch.LongStorage of size 2]

scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 19950
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 53200
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13300
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13300
[torch.LongStorage of size 1]

test img #162: time = 0.341978	
(proposal_test:boxes_filter) boxes & scores size:	
 13300
     4
[torch.LongStorage of size 2]

 13300
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 953
   3
[torch.LongTensor of size 2]

mask size:	
 13300
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   4.8000e+02   4.8000e+02
        -inf         -inf   3.6545e+04   2.1541e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #163	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0001/ILSVRC2015_train_00149000/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 288
 352
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 352
 352
[torch.LongStorage of size 3]

x_start = 1 / y_start = 33	
img_means:size() vs img:size():	
   3
 288
 352
[torch.LongStorage of size 3]

   3
 288
 352
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 2.0833333333333	
(orep_img_for_blob) img size after scaling:	
   3
 600
 733
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x89
  2 : CudaTensor - size: 18x72x89
  3 : CudaTensor - size: 18x70x87
  4 : CudaTensor - size: 18x68x85
  5 : CudaTensor - size: 256x74x91
}
proposal_im_deteect: img_blob size:    3
 600
 733
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 288
 352
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 2.0833333333333	
proposal_im_detect: scaled_img_size:	
   6
 600
 733
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1926.3022  -2170.5190  -2095.7632
  -2057.5042  -2294.2258  -2187.4812
  -2018.7422  -2212.3301  -2088.9001

(2,.,.) = 
   2885.1648   3053.0537   2944.4031
   3096.3281   3282.6829   3129.9067
   2990.8748   3145.0222   2977.8809

(3,.,.) = 
   3757.6863   4094.4592   4094.0010
   4605.9580   5030.7124   5023.1846
   5033.5229   5523.3481   5499.1187

(4,.,.) = 
   1083.0776   1207.5018   1184.8346
   1351.9851   1456.1899   1403.1732
   1467.1246   1524.0514   1429.1631

(5,.,.) = 
    767.1608    759.4230    679.3279
    753.9190    708.5716    600.9841
    769.4364    688.5421    580.3836

(6,.,.) = 
   1690.9440   1916.7510   1959.3444
   2072.4885   2388.5369   2432.7886
   2379.8369   2733.3174   2761.3406

(7,.,.) = 
  -2797.3391  -2974.4429  -2799.2883
  -3019.7136  -3177.1926  -2913.9814
  -2895.2717  -2977.2673  -2685.4229

(8,.,.) = 
   5867.3984   6287.8555   6043.9360
   6613.9512   7051.6499   6725.3779
   6878.6626   7262.5063   6887.0820

(9,.,.) = 
   2586.7629   3109.6589   3315.0027
   2981.5347   3518.9143   3651.3867
   3252.9688   3796.9749   3885.7344

(10,.,.) = 
  -3446.1685  -3407.2449  -3159.3081
  -3692.3779  -3661.1377  -3391.1633
  -3656.3816  -3616.5981  -3370.5520

(11,.,.) = 
    495.2572    657.5980    747.4089
    768.1474    960.5667   1047.5884
    857.7022   1097.6567   1188.5616

(12,.,.) = 
    451.5284    728.5574    964.5522
    521.3638    844.8225   1070.8680
    280.1588    602.6949    801.3582

(13,.,.) = 
  -2964.0791  -3135.9219  -3035.2778
  -2989.7820  -3149.6226  -3037.2498
  -2923.6904  -3073.9773  -2933.5884

(14,.,.) = 
   5118.7827   5426.9072   5230.8296
   5398.2681   5696.1099   5457.3008
   5342.8442   5664.4722   5394.3911

(15,.,.) = 
   3517.3286   3816.5991   3790.0183
   4096.1040   4493.3794   4443.0752
   4432.1733   4849.8550   4776.8730

(16,.,.) = 
  -2970.2407  -3054.2534  -3043.3318
  -3107.9373  -3225.7905  -3201.8091
  -3242.8872  -3390.1746  -3352.7722

(17,.,.) = 
  -7725.9673  -8133.9653  -8031.8936
  -8866.4277  -9386.7432  -9283.2695
  -9574.7373 -10158.8516 -10033.1689

(18,.,.) = 
   1660.9014   1609.9646   1514.3746
   1853.2327   1773.7028   1667.9402
   1850.6915   1757.6830   1655.7898
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 87
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 18270
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 87
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 87
[torch.LongStorage of size 2]

shift_y size:	
 70
 87
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6090
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 18270
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 18270
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 18270
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  18270
[torch.LongStorage of size 1]
	
  first line: 3757.6862792969	
(fast bbox transform) src_w size:  18270
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 18270
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 18270
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 18270
     4
[torch.LongStorage of size 2]

scores size:	
 18270
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 18270
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 18270
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 18270
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 48720
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 12180
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 12180
[torch.LongStorage of size 1]

test img #163: time = 0.33426800000001	
(proposal_test:boxes_filter) boxes & scores size:	
 12180
     4
[torch.LongStorage of size 2]

 12180
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 699
   3
[torch.LongTensor of size 2]

mask size:	
 12180
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   3.5200e+02   3.5200e+02
        -inf         -inf   2.9294e+04   1.7349e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #164	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00058002/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 264
 480
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 480
 480
[torch.LongStorage of size 3]

x_start = 1 / y_start = 109	
img_means:size() vs img:size():	
   3
 264
 480
[torch.LongStorage of size 3]

   3
 264
 480
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 2.2727272727273	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1090
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x133
  2 : CudaTensor - size: 18x72x133
  3 : CudaTensor - size: 18x70x131
  4 : CudaTensor - size: 18x68x129
  5 : CudaTensor - size: 256x74x135
}
proposal_im_deteect: img_blob size:     3
  600
 1090
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 264
 480
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 2.2727272727273	
proposal_im_detect: scaled_img_size:	
    7
  600
 1091
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1905.6425 -2145.3733 -2070.5894
 -2031.3004 -2263.5706 -2156.8108
 -1990.5222 -2179.8792 -2057.2407

(2,.,.) = 
  2853.5522  3017.6157  2907.5249
  3058.8201  3239.7134  3086.9521
  2952.6841  3101.4133  2934.1226

(3,.,.) = 
  3671.5803  4000.3386  4000.6936
  4503.6299  4918.1182  4911.2144
  4926.9634  5405.8135  5383.0640

(4,.,.) = 
  1049.7965  1169.7880  1147.6277
  1313.3264  1414.0819  1361.8481
  1427.8577  1482.0485  1389.1542

(5,.,.) = 
   746.0161   737.8531   659.6378
   732.3381   685.6803   579.6263
   749.1125   667.1168   558.5097

(6,.,.) = 
  1642.0609  1860.8656  1903.1083
  2016.7190  2324.6235  2368.0154
  2321.5427  2665.8679  2693.2537

(7,.,.) = 
 -2745.7595 -2917.8806 -2742.4189
 -2963.3433 -3114.9216 -2853.0513
 -2841.7786 -2918.7783 -2628.1274

(8,.,.) = 
  5747.9775  6159.4775  5918.7578
  6480.9976  6908.8374  6587.4233
  6746.6069  7120.5786  6750.1040

(9,.,.) = 
  2524.9243  3037.0820  3237.9661
  2908.9443  3435.3772  3564.4387
  3180.6372  3714.6616  3801.0393

(10,.,.) = 
 -3400.6021 -3360.1069 -3112.2939
 -3642.1343 -3608.3440 -3340.1443
 -3604.9661 -3561.7678 -3316.2141

(11,.,.) = 
   478.8226   637.9099   728.8115
   751.2322   940.3971  1027.4071
   841.8941  1077.3156  1167.1499

(12,.,.) = 
   448.2577   719.7410   953.1985
   516.1469   833.3115  1056.2809
   273.6891   589.8112   785.2527

(13,.,.) = 
 -2926.5408 -3095.5774 -2994.4114
 -2948.7229 -3104.5068 -2990.8738
 -2882.5300 -3028.9417 -2888.7192

(14,.,.) = 
  5042.4941  5344.7544  5150.4619
  5315.5015  5607.9233  5370.3877
  5259.6616  5574.5586  5306.1685

(15,.,.) = 
  3431.2676  3721.5691  3696.3997
  3999.2739  4386.1499  4337.3325
  4333.0815  4740.2505  4669.4551

(16,.,.) = 
 -2916.5056 -2997.3210 -2986.3296
 -3044.8782 -3159.8142 -3136.8030
 -3177.4260 -3320.3076 -3283.7610

(17,.,.) = 
 -7558.2319 -7956.4614 -7857.6650
 -8675.3350 -9183.3340 -9082.0498
 -9376.3604 -9946.3896 -9823.5391

(18,.,.) = 
  1637.7928  1587.0886  1491.2334
  1825.6162  1746.8267  1640.4316
  1820.7692  1728.0865  1625.0903
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 131
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 27510
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 131
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 131
[torch.LongStorage of size 2]

shift_y size:	
  70
 131
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 9170
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 27510
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 27510
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 27510
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  27510
[torch.LongStorage of size 1]
	
  first line: 3671.5803222656	
(fast bbox transform) src_w size:  27510
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 27510
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 27510
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 27510
     4
[torch.LongStorage of size 2]

scores size:	
 27510
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 27510
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 27510
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 27510
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 73360
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 18340
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 18340
[torch.LongStorage of size 1]

test img #164: time = 0.431102	
(proposal_test:boxes_filter) boxes & scores size:	
 18340
     4
[torch.LongStorage of size 2]

 18340
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 2099
    3
[torch.LongTensor of size 2]

mask size:	
 18340
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   4.8000e+02   4.8000e+02
        -inf         -inf   2.6300e+04   1.5513e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #165	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00118003/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1906.0448 -2144.6589 -2068.2263
 -2031.2394 -2262.2625 -2153.7017
 -1989.8142 -2177.8789 -2053.6001

(2,.,.) = 
  2853.6323  3015.7407  2903.6025
  3058.3999  3237.2639  3082.3530
  2951.8289  3098.6067  2929.3091

(3,.,.) = 
  3666.7585  3992.8418  3990.8362
  4497.2837  4908.7266  4899.4644
  4919.0161  5395.1147  5370.6460

(4,.,.) = 
  1047.6396  1166.7799  1144.0326
  1310.3059  1410.1295  1357.5602
  1424.4781  1477.6063  1384.5817

(5,.,.) = 
   745.6874   736.6926   657.6750
   731.6279   684.2733   577.6895
   747.9035   665.3015   556.2983

(6,.,.) = 
  1638.6562  1856.4210  1897.9655
  2012.3838  2319.1907  2361.7947
  2316.3167  2659.5825  2686.3113

(7,.,.) = 
 -2744.6040 -2914.6926 -2737.1821
 -2961.6870 -3111.3425 -2847.5657
 -2840.1057 -2915.2292 -2622.8962

(8,.,.) = 
  5743.3379  6151.0610  5906.3662
  6474.4507  6898.5781  6573.7305
  6738.6528  7109.3374  6736.4346

(9,.,.) = 
  2522.0046  3031.9993  3230.7622
  2905.0203  3429.0974  3556.0803
  3175.8301  3707.7190  3792.2388

(10,.,.) = 
 -3399.1768 -3356.3164 -3106.2495
 -3639.8101 -3603.9553 -3333.6255
 -3602.3293 -3557.4785 -3310.1882

(11,.,.) = 
   476.4210   635.5076   726.8373
   748.8104   937.9299  1025.3093
   839.7974  1075.0872  1165.1768

(12,.,.) = 
   446.6033   717.6129   951.4718
   514.5900   831.1001  1054.1091
   272.0756   587.3690   782.4902

(13,.,.) = 
 -2927.1641 -3094.1082 -2990.6934
 -2949.0220 -3102.6577 -2986.4392
 -2882.2314 -3026.6155 -2884.1353

(14,.,.) = 
  5040.8145  5339.6816  5141.9287
  5312.5625  5601.9067  5360.9868
  5255.8120  5567.9565  5296.6191

(15,.,.) = 
  3426.6726  3714.5642  3687.2466
  3993.2173  4377.7700  4326.9287
  4325.7041  4730.8164  4658.6338

(16,.,.) = 
 -2914.1521 -2992.9626 -2980.1704
 -3041.2944 -3154.2629 -3129.7390
 -3172.7156 -3313.6050 -3275.8635

(17,.,.) = 
 -7549.3442 -7942.4116 -7838.6470
 -8663.1719 -9165.9697 -9059.9248
 -9361.3838 -9926.7266 -9800.3350

(18,.,.) = 
  1636.4911  1584.5825  1487.7883
  1823.9304  1744.1060  1636.9059
  1818.8412  1725.3246  1621.7384
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3666.7585449219	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #165: time = 0.51207199999999	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1744e+04   4.2414e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #166	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00058003/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 264
 480
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 480
 480
[torch.LongStorage of size 3]

x_start = 1 / y_start = 109	
img_means:size() vs img:size():	
   3
 264
 480
[torch.LongStorage of size 3]

   3
 264
 480
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 2.2727272727273	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1090
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x133
  2 : CudaTensor - size: 18x72x133
  3 : CudaTensor - size: 18x70x131
  4 : CudaTensor - size: 18x68x129
  5 : CudaTensor - size: 256x74x135
}
proposal_im_deteect: img_blob size:     3
  600
 1090
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 264
 480
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 2.2727272727273	
proposal_im_detect: scaled_img_size:	
    7
  600
 1091
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1904.3494 -2143.4656 -2068.0271
 -2030.8289 -2262.3325 -2154.8884
 -1990.7881 -2179.5366 -2056.4165

(2,.,.) = 
  2851.5337  3014.3977  2903.6562
  3057.4326  3237.2034  3083.7961
  2952.2344  3100.1804  2932.4011

(3,.,.) = 
  3670.3499  3999.1560  3999.6880
  4502.3623  4916.8916  4910.2124
  4925.9854  5404.8604  5382.5317

(4,.,.) = 
  1049.4252  1169.8047  1147.9778
  1313.1584  1414.4550  1362.7731
  1428.3940  1483.0212  1390.5938

(5,.,.) = 
   745.7283   737.2666   658.7507
   732.3382   685.5507   579.3973
   749.2914   667.3442   558.8789

(6,.,.) = 
  1641.4882  1860.2130  1902.5748
  2015.5260  2323.2410  2366.7556
  2319.6948  2664.0591  2691.5376

(7,.,.) = 
 -2745.2002 -2916.3201 -2740.1621
 -2962.8354 -3113.5276 -2850.9470
 -2841.7612 -2917.9692 -2626.6375

(8,.,.) = 
  5747.6465  6158.5757  5917.3247
  6481.1450  6908.6597  6586.9819
  6747.2734  7121.1465  6750.7681

(9,.,.) = 
  2525.2173  3036.8740  3237.5540
  2909.5366  3435.5515  3564.3965
  3181.1167  3714.8000  3800.9871

(10,.,.) = 
 -3399.9702 -3358.7109 -3110.4478
 -3642.0923 -3607.7600 -3338.9717
 -3605.6636 -3562.1404 -3316.2378

(11,.,.) = 
   478.5502   638.0594   729.4396
   750.4828   940.1200  1027.6716
   841.0536  1076.7792  1167.0801

(12,.,.) = 
   445.7911   716.7990   950.3313
   513.5482   830.1332  1053.0038
   271.6987   587.1453   782.3186

(13,.,.) = 
 -2925.7756 -3093.3330 -2991.1296
 -2948.8579 -3103.2563 -2988.4626
 -2883.1018 -3028.3403 -2887.1167

(14,.,.) = 
  5041.2749  5342.0781  5146.7554
  5315.3545  5606.5503  5368.1182
  5260.3550  5574.4790  5305.4053

(15,.,.) = 
  3431.3081  3721.7725  3696.6787
  3999.4495  4386.5576  4337.9473
  4333.2061  4740.7349  4670.3130

(16,.,.) = 
 -2915.3884 -2996.2200 -2985.5247
 -3044.9119 -3159.9270 -3137.3091
 -3178.1836 -3321.1147 -3285.0688

(17,.,.) = 
 -7556.1885 -7954.0752 -7854.9731
 -8674.1699 -9182.1162 -9080.8711
 -9376.2100 -9946.4922 -9824.1201

(18,.,.) = 
  1636.7682  1585.6833  1489.7316
  1824.9301  1745.9109  1639.5035
  1820.6644  1727.8596  1625.0529
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 131
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 27510
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 131
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 131
[torch.LongStorage of size 2]

shift_y size:	
  70
 131
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 9170
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 27510
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 27510
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 27510
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  27510
[torch.LongStorage of size 1]
	
  first line: 3670.3498535156	
(fast bbox transform) src_w size:  27510
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 27510
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 27510
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 27510
     4
[torch.LongStorage of size 2]

scores size:	
 27510
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 27510
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 27510
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 27510
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 73360
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 18340
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 18340
[torch.LongStorage of size 1]

test img #166: time = 0.485145	
(proposal_test:boxes_filter) boxes & scores size:	
 18340
     4
[torch.LongStorage of size 2]

 18340
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 2099
    3
[torch.LongTensor of size 2]

mask size:	
 18340
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   4.8000e+02   4.8000e+02
        -inf         -inf   2.6316e+04   1.5517e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #167	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00040010/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1920
 1920
[torch.LongStorage of size 3]

x_start = 1 / y_start = 421	
img_means:size() vs img:size():	
    3
 1080
 1920
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.55555555555556	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
 1080
 1920
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.55555555555556	
proposal_im_detect: scaled_img_size:	
    2
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1906.6638 -2145.9341 -2070.1086
 -2032.9825 -2264.6760 -2156.8020
 -1992.3812 -2181.1948 -2057.4961

(2,.,.) = 
  2854.7993  3017.6733  2906.5078
  3060.5264  3240.3779  3086.3997
  2954.6316  3102.5261  2934.1067

(3,.,.) = 
  3675.2158  4003.4502  4002.8481
  4507.6729  4921.4570  4913.4272
  4930.8633  5408.9009  5385.0225

(4,.,.) = 
  1050.9849  1171.1622  1148.9106
  1314.7949  1415.6304  1363.4296
  1429.6345  1483.6349  1390.7078

(5,.,.) = 
   747.6364   739.0734   660.2560
   734.0865   687.2501   580.7931
   750.6113   668.4614   559.6964

(6,.,.) = 
  1644.1532  1863.0566  1905.1045
  2018.5166  2326.5183  2369.6558
  2322.7908  2667.3245  2694.4441

(7,.,.) = 
 -2749.1016 -2920.1809 -2743.5129
 -2967.0081 -3117.7507 -2854.6265
 -2845.5496 -2921.7974 -2630.0618

(8,.,.) = 
  5754.5952  6164.7075  5921.7168
  6488.1416  6914.7622  6591.0962
  6753.3755  7126.2549  6753.9092

(9,.,.) = 
  2528.4255  3040.1335  3240.4788
  2913.0593  3438.9656  3567.3413
  3184.2754  3717.6836  3803.2974

(10,.,.) = 
 -3402.9004 -3360.9597 -3111.8882
 -3644.7754 -3609.8171 -3340.1577
 -3607.8994 -3563.9033 -3317.1570

(11,.,.) = 
   478.5590   637.9201   729.0821
   750.8075   940.2195  1027.5469
   841.5070  1077.1699  1167.2920

(12,.,.) = 
   446.2596   717.4810   951.3035
   514.4175   831.3764  1054.5494
   272.5218   588.4109   783.9264

(13,.,.) = 
 -2929.0698 -3096.5286 -2993.9172
 -2951.7913 -3106.1353 -2990.8740
 -2885.5552 -3030.7676 -2889.0300

(14,.,.) = 
  5046.3262  5346.5674  5150.1245
  5319.8467  5610.4746  5370.8242
  5264.1777  5577.7368  5307.3892

(15,.,.) = 
  3435.5981  3725.5715  3699.4348
  4003.8225  4390.4922  4340.6328
  4337.2651  4744.2837  4672.5791

(16,.,.) = 
 -2918.7463 -2998.9270 -2987.4329
 -3047.9248 -3162.1936 -3138.6384
 -3180.4946 -3322.6567 -3285.5354

(17,.,.) = 
 -7564.9277 -7961.3716 -7860.1089
 -8682.9463 -9189.1191 -9085.3193
 -9383.9834 -9952.2627 -9827.0811

(18,.,.) = 
  1638.3214  1586.8633  1490.6368
  1826.5278  1747.0604  1640.4207
  1822.0491  1728.7737  1625.6832
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3675.2158203125	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #167: time = 0.79128299999999	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.9200e+03   1.9200e+03
        -inf         -inf   1.0794e+05   6.3852e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #168	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00008002/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1915.1713 -2155.4568 -2079.4053
 -2041.8916 -2274.6040 -2166.3547
 -2001.0868 -2190.7266 -2066.5762

(2,.,.) = 
  2867.3604  3031.0059  2919.4270
  3073.8892  3254.5659  3099.9827
  2967.4338  3115.9944  2946.8696

(3,.,.) = 
  3691.9531  4021.7085  4021.1560
  4527.4829  4943.1343  4935.1689
  4951.8452  5431.9580  5408.1113

(4,.,.) = 
  1055.5099  1176.1471  1153.8051
  1320.4565  1421.5946  1369.1763
  1435.5964  1489.7866  1396.5844

(5,.,.) = 
   750.8444   742.3903   663.3813
   737.1074   690.2275   583.4503
   753.7012   671.2703   562.0880

(6,.,.) = 
  1651.1010  1870.9764  1913.1792
  2026.8020  2336.1736  2379.4912
  2332.1885  2678.1360  2705.3799

(7,.,.) = 
 -2760.1587 -2932.0693 -2754.7798
 -2978.8647 -3130.3245 -2866.1892
 -2856.8743 -2933.5137 -2640.6394

(8,.,.) = 
  5778.9946  6191.0054  5947.2930
  6515.1616  6943.7661  6618.9751
  6781.1680  7155.7378  6782.1167

(9,.,.) = 
  2539.3132  3053.0984  3254.1648
  2925.1160  3453.1370  3582.0237
  3197.1826  3732.7891  3818.7993

(10,.,.) = 
 -3418.6750 -3376.7053 -3126.6423
 -3661.3994 -3626.3955 -3355.6921
 -3623.9890 -3579.8994 -3332.1775

(11,.,.) = 
   480.2795   640.2535   731.8548
   753.8248   943.9321  1031.6323
   844.7354  1081.2944  1171.7537

(12,.,.) = 
   447.9173   720.1114   954.9585
   516.4798   834.5604  1058.6798
   273.5858   590.6195   786.9322

(13,.,.) = 
 -2941.4097 -3109.6897 -3006.6299
 -2963.7654 -3118.9014 -3003.1294
 -2897.2261 -3043.1289 -2900.7930

(14,.,.) = 
  5067.8882  5369.5371  5172.3823
  5342.1904  5634.1748  5393.6255
  5286.0884  5601.0620  5329.6958

(15,.,.) = 
  3450.5076  3741.7368  3715.5647
  4020.7517  4409.0796  4359.0962
  4355.3262  4764.0317  4692.1460

(16,.,.) = 
 -2932.4871 -3013.1023 -3001.4587
 -3061.7830 -3176.5945 -3152.8184
 -3194.4084 -3337.1902 -3299.8240

(17,.,.) = 
 -7598.7891 -7997.2139 -7895.7007
 -8720.8242 -9229.2842 -9125.2344
 -9423.9854 -9994.7490 -9869.2246

(18,.,.) = 
  1645.7728  1594.2413  1497.6599
  1834.6793  1754.9744  1647.8810
  1829.9442  1736.3494  1632.8088
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3691.953125	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #168: time = 0.74329	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2241e+04   4.2717e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #169	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00001000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1915.8661 -2156.2373 -2080.1619
 -2042.6769 -2275.4768 -2167.2051
 -2001.8801 -2191.6245 -2067.4255

(2,.,.) = 
  2868.3955  3032.0667  2920.4648
  3075.0469  3255.7627  3101.1309
  2968.6057  3117.2065  2948.0273

(3,.,.) = 
  3693.9175  4023.8059  4023.2229
  4529.8799  4945.7104  4937.6870
  4954.4683  5434.7803  5410.8579

(4,.,.) = 
  1056.1383  1176.8400  1154.4900
  1321.2482  1422.4260  1369.9907
  1436.4259  1490.6455  1397.4293

(5,.,.) = 
   751.3282   742.8541   663.7949
   737.5875   690.7166   583.8669
   754.1851   671.7507   562.4745

(6,.,.) = 
  1652.0266  1871.9832  1914.1871
  2027.9282  2337.3777  2380.6646
  2333.4646  2679.4973  2706.6956

(7,.,.) = 
 -2761.3396 -2933.3062 -2755.9546
 -2980.1873 -3131.6819 -2867.4575
 -2858.2197 -2934.8872 -2641.8879

(8,.,.) = 
  5781.7578  6193.8896  5950.0889
  6518.3560  6947.0894  6622.1519
  6784.5957  7159.2998  6785.4912

(9,.,.) = 
  2540.6704  3054.6553  3255.7776
  2926.7354  3454.9521  3583.8599
  3198.9131  3734.7214  3820.7500

(10,.,.) = 
 -3420.1338 -3378.1306 -3127.9985
 -3663.0662 -3628.0059 -3357.2024
 -3625.8203 -3581.6729 -3333.8162

(11,.,.) = 
   480.5200   640.5530   732.1896
   754.2051   944.3633  1032.1006
   845.1526  1081.7855  1172.2980

(12,.,.) = 
   447.9792   720.2336   955.1432
   516.5466   834.7256  1058.9215
   273.5643   590.7293   787.1742

(13,.,.) = 
 -2942.4587 -3110.7615 -3007.6716
 -2964.8647 -3120.0481 -3004.2273
 -2898.4543 -3044.3972 -2901.9382

(14,.,.) = 
  5069.8975  5371.6230  5174.4019
  5344.4287  5636.4688  5395.8340
  5288.5337  5603.5815  5332.0635

(15,.,.) = 
  3452.3496  3743.7063  3717.5139
  4022.9114  4411.3984  4361.3706
  4357.6899  4766.5576  4694.6133

(16,.,.) = 
 -2933.9014 -3014.5491 -3002.9182
 -3063.4053 -3178.2498 -3154.4478
 -3196.1990 -3338.9976 -3301.5540

(17,.,.) = 
 -7602.6392 -8001.1880 -7899.5908
 -8725.3232 -9233.9502 -9129.8154
 -9428.9424 -9999.8838 -9874.2227

(18,.,.) = 
  1646.4717  1594.9087  1498.3262
  1835.5120  1755.7450  1648.6394
  1830.8276  1737.1726  1633.5939
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3693.9174804688	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #169: time = 0.606779	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2284e+04   4.2744e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #170	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00058001/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 264
 480
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 480
 480
[torch.LongStorage of size 3]

x_start = 1 / y_start = 109	
img_means:size() vs img:size():	
   3
 264
 480
[torch.LongStorage of size 3]

   3
 264
 480
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 2.2727272727273	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1090
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x133
  2 : CudaTensor - size: 18x72x133
  3 : CudaTensor - size: 18x70x131
  4 : CudaTensor - size: 18x68x129
  5 : CudaTensor - size: 256x74x135
}
proposal_im_deteect: img_blob size:     3
  600
 1090
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 264
 480
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 2.2727272727273	
proposal_im_detect: scaled_img_size:	
    7
  600
 1091
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1907.1129 -2146.3433 -2070.5818
 -2032.6445 -2264.2913 -2156.4436
 -1991.5074 -2180.1484 -2056.5125

(2,.,.) = 
  2855.5635  3018.5161  2907.3235
  3060.5950  3240.3455  3086.3857
  2954.1338  3101.7866  2933.2737

(3,.,.) = 
  3671.3813  3999.3625  3998.9392
  4502.7188  4915.9316  4907.9683
  4924.8452  5402.1152  5378.1592

(4,.,.) = 
  1049.1931  1169.1395  1146.8842
  1312.3730  1412.9268  1360.6577
  1426.7639  1480.3921  1387.5376

(5,.,.) = 
   746.8393   738.2012   659.5807
   733.0228   686.0219   579.6536
   749.4874   667.0911   558.2011

(6,.,.) = 
  1641.1689  1859.8245  1901.9178
  2015.3773  2323.0525  2366.1318
  2319.6416  2663.6541  2690.8123

(7,.,.) = 
 -2747.8423 -2918.9805 -2742.2925
 -2965.1555 -3115.7913 -2852.7461
 -2843.3359 -2919.5012 -2627.8413

(8,.,.) = 
  5749.7354  6159.7119  5916.9438
  6481.6938  6907.8833  6584.3232
  6745.9624  7118.1001  6745.7896

(9,.,.) = 
  2525.3823  3037.0051  3237.4036
  2908.8123  3434.4624  3562.8333
  3179.8159  3712.7712  3798.3196

(10,.,.) = 
 -3402.4688 -3360.5635 -3111.3018
 -3643.3003 -3608.2493 -3338.5007
 -3605.3716 -3561.1362 -3314.2092

(11,.,.) = 
   477.4480   636.8266   728.1519
   749.9174   939.2685  1026.5464
   840.6310  1076.0182  1165.8809

(12,.,.) = 
   447.6048   719.0185   953.0967
   515.7390   832.7731  1056.2031
   273.3265   589.2299   784.7986

(13,.,.) = 
 -2928.9509 -3096.6748 -2994.2090
 -2950.8628 -3105.3267 -2990.0085
 -2884.2080 -3029.4563 -2887.7400

(14,.,.) = 
  5044.9775  5345.4141  5149.2466
  5317.1235  5607.8208  5368.2241
  5260.3555  5573.7095  5303.3389

(15,.,.) = 
  3431.0112  3720.4644  3694.4387
  3998.1770  4384.0923  4334.2886
  4330.9912  4737.0474  4665.3848

(16,.,.) = 
 -2917.0793 -2997.1021 -2985.6182
 -3044.6257 -3158.7192 -3135.0513
 -3176.2551 -3317.8745 -3280.6401

(17,.,.) = 
 -7557.6265 -7953.7100 -7852.6816
 -8673.0791 -9178.4707 -9074.6318
 -9372.3027 -9939.3604 -9813.9551

(18,.,.) = 
  1638.4651  1587.1454  1490.9353
  1826.1168  1746.7673  1640.0250
  1820.7637  1727.5164  1624.2870
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 131
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 27510
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 131
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 131
[torch.LongStorage of size 2]

shift_y size:	
  70
 131
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 9170
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 27510
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 27510
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 27510
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  27510
[torch.LongStorage of size 1]
	
  first line: 3671.3813476562	
(fast bbox transform) src_w size:  27510
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 27510
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 27510
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 27510
     4
[torch.LongStorage of size 2]

scores size:	
 27510
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 27510
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 27510
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 27510
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 73360
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 18340
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 18340
[torch.LongStorage of size 1]

test img #170: time = 0.49779100000001	
(proposal_test:boxes_filter) boxes & scores size:	
 18340
     4
[torch.LongStorage of size 2]

 18340
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 2099
    3
[torch.LongTensor of size 2]

mask size:	
 18340
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   4.8000e+02   4.8000e+02
        -inf         -inf   2.6272e+04   1.5489e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #171	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00010002/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1920
 1920
[torch.LongStorage of size 3]

x_start = 1 / y_start = 421	
img_means:size() vs img:size():	
    3
 1080
 1920
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.55555555555556	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
 1080
 1920
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.55555555555556	
proposal_im_detect: scaled_img_size:	
    2
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1909.1804 -2148.2363 -2072.2346
 -2034.7441 -2266.2344 -2158.0312
 -1993.5283 -2181.9426 -2058.0105

(2,.,.) = 
  2858.0361  3020.7502  2909.0881
  3063.1204  3242.5779  3088.2244
  2956.5376  3103.8379  2934.9639

(3,.,.) = 
  3670.5850  3998.6062  3998.6506
  4501.9810  4915.2949  4907.9297
  4924.6445  5402.2114  5379.1855

(4,.,.) = 
  1048.0215  1167.7991  1145.6031
  1311.5619  1412.0500  1359.9215
  1426.4094  1480.0607  1387.4265

(5,.,.) = 
   745.8419   737.4266   659.0787
   732.0396   685.1393   579.0446
   748.7460   666.3798   557.5117

(6,.,.) = 
  1639.7264  1858.2728  1900.6129
  2013.6292  2321.3567  2364.7598
  2317.9180  2662.1553  2689.5979

(7,.,.) = 
 -2747.6150 -2918.3579 -2741.2402
 -2964.9583 -3115.1631 -2851.7397
 -2843.3091 -2918.9585 -2626.8567

(8,.,.) = 
  5749.2607  6159.1768  5916.5767
  6481.6777  6907.9600  6584.7886
  6746.8574  7119.2261  6747.3970

(9,.,.) = 
  2524.6208  3035.7739  3235.8472
  2907.7676  3433.0408  3561.3247
  3179.1013  3712.0325  3797.7478

(10,.,.) = 
 -3404.9536 -3362.8582 -3113.4561
 -3646.0916 -3610.9165 -3341.2051
 -3608.2056 -3563.8264 -3316.9563

(11,.,.) = 
   476.3906   635.6100   727.2659
   749.3522   938.6789  1026.2993
   840.2769  1075.7004  1165.9647

(12,.,.) = 
   447.0668   717.9866   951.9923
   515.0725   831.6657  1054.9758
   272.0949   587.5520   783.1390

(13,.,.) = 
 -2930.9148 -3098.2329 -2995.1719
 -2952.4885 -3106.3655 -2990.4578
 -2885.5928 -3030.3730 -2888.2256

(14,.,.) = 
  5047.1328  5347.1719  5150.6851
  5319.5034  5609.8750  5369.9941
  5262.7563  5575.8833  5305.4229

(15,.,.) = 
  3429.8054  3719.1790  3693.4915
  3997.1106  4383.2026  4333.8320
  4330.4678  4736.8799  4665.8325

(16,.,.) = 
 -2918.0488 -2998.0635 -2986.8049
 -3045.3279 -3159.4773 -3136.2944
 -3177.0337 -3318.7607 -3281.9739

(17,.,.) = 
 -7556.4106 -7952.7480 -7852.6602
 -8672.2949 -9178.0176 -9075.2998
 -9372.4941 -9940.1758 -9816.2666

(18,.,.) = 
  1639.0884  1587.7762  1491.5505
  1826.8518  1747.5485  1640.7771
  1821.5518  1728.3037  1625.0017
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3670.5849609375	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #171: time = 0.769378	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.9200e+03   1.9200e+03
        -inf         -inf   1.0784e+05   6.3742e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #172	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00026001/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1903.2639 -2141.8391 -2065.7095
 -2029.6859 -2260.7461 -2152.4353
 -1989.9824 -2178.2375 -2054.3220

(2,.,.) = 
  2850.0200  3012.0002  2900.2830
  3055.7722  3234.6846  3080.3508
  2951.3086  3098.5093  2929.7253

(3,.,.) = 
  3666.2065  3993.0518  3991.6538
  4499.0093  4911.2910  4902.3623
  4924.2998  5400.9531  5376.2490

(4,.,.) = 
  1048.3845  1168.3662  1145.7781
  1312.0571  1412.8053  1360.3973
  1427.5873  1481.4646  1388.2625

(5,.,.) = 
   745.8348   736.9982   658.1643
   732.9446   685.8588   579.2047
   749.9647   667.7628   558.8631

(6,.,.) = 
  1639.9824  1857.9652  1899.3281
  2014.2911  2321.1406  2363.4355
  2319.1936  2662.9624  2689.4753

(7,.,.) = 
 -2744.9175 -2914.8596 -2737.5432
 -2962.9678 -3112.6545 -2848.9675
 -2843.0093 -2918.4241 -2626.0405

(8,.,.) = 
  5744.3979  6152.7603  5908.7520
  6478.8379  6903.6362  6578.9238
  6746.7954  7118.2036  6744.6523

(9,.,.) = 
  2522.9626  3033.5637  3232.9397
  2908.0942  3432.9727  3560.5549
  3180.6890  3713.1338  3798.1038

(10,.,.) = 
 -3397.1111 -3354.3704 -3104.8704
 -3639.4856 -3603.6140 -3333.4199
 -3604.0361 -3559.1768 -3311.6809

(11,.,.) = 
   478.2938   637.5676   728.5305
   749.7546   938.9986  1026.1244
   840.7433  1076.1121  1165.9453

(12,.,.) = 
   445.3725   716.4033   949.7773
   512.7940   829.4065  1052.2864
   271.4238   586.8955   782.0898

(13,.,.) = 
 -2924.9478 -3091.6030 -2988.6177
 -2948.5354 -3102.0190 -2986.2471
 -2883.2122 -3027.6729 -2885.4668

(14,.,.) = 
  5038.8872  5337.8428  5140.8667
  5313.3721  5602.8159  5362.4971
  5259.5698  5571.8457  5300.7324

(15,.,.) = 
  3428.6179  3717.3193  3690.2913
  3997.2815  4382.6089  4331.7417
  4332.1826  4738.1167  4665.4106

(16,.,.) = 
 -2912.6230 -2992.1116 -2980.1030
 -3042.7488 -3156.3538 -3132.3469
 -3176.7573 -3318.2727 -3280.7012

(17,.,.) = 
 -7548.3955 -7942.5625 -7840.0361
 -8668.1611 -9171.9541 -9066.5596
 -9372.4609 -9938.4785 -9811.6738

(18,.,.) = 
  1635.4501  1583.6240  1487.2078
  1823.6505  1743.8944  1636.9996
  1819.8344  1726.3597  1623.0061
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3666.2065429688	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #172: time = 0.60618599999999	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1914e+04   4.2531e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #173	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00008001/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1899.0782 -2138.0916 -2064.2639
 -2024.2681 -2255.6641 -2149.9238
 -1983.5773 -2172.0862 -2050.7832

(2,.,.) = 
  2843.6738  3007.2246  2898.9114
  3047.9299  3228.2458  3077.4834
  2942.1250  3090.2969  2925.1023

(3,.,.) = 
  3656.2629  3986.6284  3990.4873
  4485.6616  4902.0215  4899.4219
  4908.1182  5388.9253  5371.2378

(4,.,.) = 
  1045.5226  1166.0739  1144.9165
  1308.5745  1410.3105  1359.6227
  1423.4075  1478.7760  1387.6903

(5,.,.) = 
   741.5585   733.4792   656.1261
   728.1868   681.7817   576.6837
   744.7546   663.1817   555.6519

(6,.,.) = 
  1634.8792  1854.2000  1897.6863
  2007.9128  2316.2395  2361.2078
  2311.6606  2656.7661  2686.1489

(7,.,.) = 
 -2734.0137 -2904.7566 -2730.1304
 -2950.5571 -3100.9170 -2840.3826
 -2829.1992 -2905.2537 -2616.0125

(8,.,.) = 
  5725.2207  6137.2280  5900.6602
  6456.3379  6885.3174  6569.2163
  6721.4424  7097.2329  6732.9546

(9,.,.) = 
  2513.9878  3025.1250  3226.4529
  2896.6184  3422.1582  3552.3584
  3167.0769  3700.4697  3788.6123

(10,.,.) = 
 -3388.7866 -3349.3718 -3104.3953
 -3629.5088 -3597.1875 -3331.9231
 -3592.7119 -3551.1667 -3308.7048

(11,.,.) = 
   476.9869   636.6252   728.3353
   748.5354   938.3849  1026.3707
   839.2424  1075.0011  1165.8118

(12,.,.) = 
   445.8905   716.2448   949.3913
   512.8983   828.6445  1051.2681
   270.9578   585.3633   780.3578

(13,.,.) = 
 -2915.5601 -3083.2627 -2983.2412
 -2937.2964 -3091.4131 -2978.8123
 -2870.5591 -3015.5627 -2876.8530

(14,.,.) = 
  5023.8687  5325.7261  5134.7954
  5295.7158  5587.9487  5353.9897
  5239.7603  5554.6562  5290.4712

(15,.,.) = 
  3417.5557  3708.8127  3686.5903
  3983.9678  4371.8950  4326.5991
  4316.9683  4725.6152  4658.9688

(16,.,.) = 
 -2905.4924 -2988.0786 -2980.2463
 -3033.2852 -3150.0149 -3130.3083
 -3164.9192 -3309.4961 -3276.7856

(17,.,.) = 
 -7528.3979 -7929.9175 -7838.0708
 -8642.3486 -9154.3545 -9061.2891
 -9342.3506 -9917.2744 -9804.1084

(18,.,.) = 
  1631.4674  1581.7654  1487.6136
  1818.7640  1741.5402  1637.1322
  1814.1235  1723.1243  1622.0920
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3656.2629394531	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #173: time = 0.573082	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1795e+04   4.2493e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #174	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0001/ILSVRC2015_train_00289000/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1905.5325 -2144.7190 -2069.1941
 -2030.7002 -2262.4143 -2154.8958
 -1989.6462 -2178.6128 -2055.4648

(2,.,.) = 
  2853.8147  3016.9136  2905.8760
  3058.4148  3238.2190  3084.4292
  2951.9722  3099.7756  2931.8235

(3,.,.) = 
  3669.4512  3998.1917  3999.0469
  4501.8364  4916.2388  4909.5337
  4924.8926  5403.4961  5380.6382

(4,.,.) = 
  1049.0985  1169.1222  1147.1525
  1312.3713  1413.3134  1361.4166
  1426.9927  1481.2513  1388.6167

(5,.,.) = 
   745.5201   737.1193   658.9312
   731.5554   684.6376   578.5121
   747.7393   665.3000   556.5499

(6,.,.) = 
  1641.0155  1860.0559  1902.6143
  2015.3405  2323.1914  2366.6726
  2319.8101  2663.9443  2691.2617

(7,.,.) = 
 -2746.2522 -2917.4053 -2740.8975
 -2963.4006 -3114.0183 -2851.2839
 -2841.8054 -2917.8625 -2626.3796

(8,.,.) = 
  5746.8130  6157.5728  5916.0083
  6479.9775  6907.0762  6584.9497
  6745.2612  7118.3076  6746.9517

(9,.,.) = 
  2524.2817  3036.0247  3236.6201
  2907.8816  3434.0735  3562.8457
  3179.3599  3713.5588  3799.8130

(10,.,.) = 
 -3399.7532 -3358.6860 -3110.4822
 -3641.7327 -3607.3364 -3338.4795
 -3605.3123 -3561.4932 -3315.1450

(11,.,.) = 
   478.5882   638.0688   729.4430
   751.4825   941.0818  1028.4227
   842.4597  1078.1202  1168.0361

(12,.,.) = 
   448.7418   719.8472   953.3132
   516.5015   833.4365  1056.4740
   273.7524   589.8759   785.5706

(13,.,.) = 
 -2926.7588 -3094.6362 -2992.4490
 -2948.9089 -3103.7095 -2989.1714
 -2883.3884 -3029.0713 -2888.2019

(14,.,.) = 
  5041.8149  5342.7744  5147.4761
  5315.0747  5606.5063  5368.0884
  5260.1587  5574.5078  5305.2256

(15,.,.) = 
  3429.7317  3719.9302  3694.7566
  3997.9758  4384.8276  4335.8867
  4331.7173  4738.6118  4667.4326

(16,.,.) = 
 -2914.9617 -2995.6443 -2984.8635
 -3043.2507 -3157.9285 -3135.0344
 -3175.8137 -3318.2498 -3281.7874

(17,.,.) = 
 -7554.3389 -7952.3730 -7853.6743
 -8671.9365 -9179.9189 -9078.6133
 -9373.7988 -9943.4277 -9820.0732

(18,.,.) = 
  1637.3840  1586.5360  1490.6858
  1825.4464  1746.5095  1639.9482
  1820.5286  1727.5121  1624.1792
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3669.451171875	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #174: time = 0.538156	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1764e+04   4.2403e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #175	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00040007/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1920
 1920
[torch.LongStorage of size 3]

x_start = 1 / y_start = 421	
img_means:size() vs img:size():	
    3
 1080
 1920
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.55555555555556	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
 1080
 1920
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.55555555555556	
proposal_im_detect: scaled_img_size:	
    2
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1907.6779 -2146.7642 -2070.9902
 -2033.0895 -2264.6287 -2156.7263
 -1991.8247 -2180.3635 -2056.7141

(2,.,.) = 
  2856.0491  3018.8308  2907.4678
  3061.0098  3240.5200  3086.4595
  2954.4004  3101.8167  2933.2476

(3,.,.) = 
  3668.5820  3996.3086  3996.1963
  4499.4087  4912.4253  4904.9297
  4921.7305  5398.9609  5375.8105

(4,.,.) = 
  1047.5312  1167.1741  1145.0513
  1310.8434  1411.1892  1359.1389
  1425.5067  1479.0519  1386.5165

(5,.,.) = 
   745.6224   737.1248   658.6832
   731.7781   684.8104   578.6475
   748.3774   666.0011   557.1203

(6,.,.) = 
  1638.8097  1857.0790  1899.3766
  2012.4937  2319.8645  2363.2534
  2316.6980  2660.4980  2687.9521

(7,.,.) = 
 -2745.5962 -2916.3843 -2739.5801
 -2962.7969 -3113.1018 -2850.0010
 -2841.1016 -2916.8853 -2625.1025

(8,.,.) = 
  5745.7905  6155.4717  5913.1499
  6477.6440  6903.7002  6580.8350
  6742.3706  7114.5269  6743.0703

(9,.,.) = 
  2522.8652  3033.8391  3233.8667
  2905.7913  3430.8809  3559.1636
  3176.9016  3709.6677  3795.3555

(10,.,.) = 
 -3402.9736 -3360.9485 -3111.6277
 -3644.0342 -3608.8691 -3339.1924
 -3606.1057 -3561.7510 -3314.9055

(11,.,.) = 
   476.3254   635.4875   727.0976
   749.0319   938.2908  1025.8748
   839.8907  1075.2432  1165.4646

(12,.,.) = 
   446.9601   717.8376   951.8107
   515.0222   831.5320  1054.7833
   272.2834   587.6725   783.1342

(13,.,.) = 
 -2928.8477 -3096.3943 -2993.6033
 -2950.4370 -3104.5950 -2988.9714
 -2883.5513 -3028.5837 -2886.7114

(14,.,.) = 
  5044.0249  5344.2446  5147.9995
  5316.2173  5606.8237  5367.1699
  5259.3691  5572.7148  5302.4595

(15,.,.) = 
  3427.8291  3716.9692  3691.3113
  3994.7458  4380.5161  4331.2119
  4327.7773  4733.8594  4662.9131

(16,.,.) = 
 -2916.6204 -2996.6465 -2985.2439
 -3043.8098 -3157.9753 -3134.6113
 -3175.3547 -3317.1108 -3280.2031

(17,.,.) = 
 -7552.8403 -7948.8003 -7848.4873
 -8667.9912 -9173.3330 -9070.3750
 -9367.5635 -9934.8564 -9810.7314

(18,.,.) = 
  1638.2491  1586.9327  1490.6733
  1825.9144  1746.6145  1639.7865
  1820.5981  1727.3528  1624.0009
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3668.58203125	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #175: time = 0.84151199999999	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.9200e+03   1.9200e+03
        -inf         -inf   1.0775e+05   6.3692e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #176	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00033002/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 358
 640
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 640
 640
[torch.LongStorage of size 3]

x_start = 1 / y_start = 142	
img_means:size() vs img:size():	
   3
 358
 640
[torch.LongStorage of size 3]

   3
 358
 640
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6759776536313	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1072
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x131
  2 : CudaTensor - size: 18x72x131
  3 : CudaTensor - size: 18x70x129
  4 : CudaTensor - size: 18x68x127
  5 : CudaTensor - size: 256x74x133
}
proposal_im_deteect: img_blob size:     3
  600
 1072
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 358
 640
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6759776536313	
proposal_im_detect: scaled_img_size:	
    5
  600
 1073
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1897.6106 -2135.4219 -2059.8625
 -2022.2776 -2252.4939 -2144.9006
 -1981.1510 -2168.3479 -2045.1589

(2,.,.) = 
  2841.1924  3002.9917  2891.9395
  3044.9551  3223.3196  3069.9238
  2939.0215  3085.3169  2917.4561

(3,.,.) = 
  3645.2510  3971.2629  3971.6514
  4472.0884  4882.9585  4876.2012
  4892.8159  5368.0161  5346.0342

(4,.,.) = 
  1040.8445  1159.8759  1138.0005
  1302.3700  1402.4580  1350.8848
  1416.6765  1470.0703  1378.1349

(5,.,.) = 
   740.5135   731.8707   653.8090
   726.7576   679.7435   574.1217
   743.1903   661.0518   552.7980

(6,.,.) = 
  1628.3505  1845.2964  1887.6750
  2000.2156  2305.8186  2349.3706
  2303.0229  2645.1387  2672.9973

(7,.,.) = 
 -2731.2314 -2900.8906 -2724.6272
 -2947.1941 -3096.4355 -2834.4307
 -2825.9963 -2901.1067 -2610.4370

(8,.,.) = 
  5713.5024  6121.1133  5879.9761
  6441.7837  6865.6748  6544.8340
  6705.5430  7076.0142  6707.0059

(9,.,.) = 
  2507.6233  3016.2290  3215.6135
  2888.7441  3411.4324  3539.4360
  3159.0020  3689.3213  3774.9678

(10,.,.) = 
 -3383.4229 -3341.3579 -3093.1887
 -3623.2178 -3588.0750 -3319.7410
 -3585.8481 -3541.5981 -3296.1707

(11,.,.) = 
   473.9984   632.4960   723.7549
   745.0632   933.6230  1021.0085
   835.7918  1070.3165  1160.3959

(12,.,.) = 
   445.2738   714.9767   947.7332
   512.6511   827.6980  1049.7759
   270.8708   584.5403   778.8149

(13,.,.) = 
 -2914.1721 -3080.7415 -2978.4319
 -2936.2051 -3089.2327 -2974.1045
 -2869.4270 -3013.3823 -2872.1582

(14,.,.) = 
  5017.6084  5316.2979  5121.0581
  5288.6289  5577.7588  5339.3052
  5232.0654  5543.7051  5274.8813

(15,.,.) = 
  3406.9858  3694.5193  3669.2964
  3971.0532  4354.8389  4306.2827
  4302.6479  4706.8071  4636.9927

(16,.,.) = 
 -2898.2776 -2977.8755 -2966.9836
 -3024.6677 -3138.3750 -3115.8477
 -3156.0569 -3297.2468 -3261.3972

(17,.,.) = 
 -7506.9097 -7900.7588 -7801.7705
 -8616.3037 -9119.3467 -9018.0322
 -9313.0703 -9878.1816 -9756.5381

(18,.,.) = 
  1628.9169  1577.7511  1481.8270
  1815.5831  1736.7568  1630.3969
  1810.4938  1717.8275  1615.0034
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 129
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 27090
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 129
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 129
[torch.LongStorage of size 2]

shift_y size:	
  70
 129
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 9030
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 27090
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 27090
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 27090
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  27090
[torch.LongStorage of size 1]
	
  first line: 3645.2509765625	
(fast bbox transform) src_w size:  27090
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 27090
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 27090
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 27090
     4
[torch.LongStorage of size 2]

scores size:	
 27090
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 27090
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 27090
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 27090
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 72240
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 18060
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 18060
[torch.LongStorage of size 1]

test img #176: time = 0.47495300000001	
(proposal_test:boxes_filter) boxes & scores size:	
 18060
     4
[torch.LongStorage of size 2]

 18060
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1809
    3
[torch.LongTensor of size 2]

mask size:	
 18060
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   6.4000e+02   6.4000e+02
        -inf         -inf   3.5492e+04   2.0910e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #177	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00102007/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 360
 640
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 640
 640
[torch.LongStorage of size 3]

x_start = 1 / y_start = 141	
img_means:size() vs img:size():	
   3
 360
 640
[torch.LongStorage of size 3]

   3
 360
 640
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6666666666667	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 360
 640
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6666666666667	
proposal_im_detect: scaled_img_size:	
    5
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1914.7690 -2154.9839 -2078.8660
 -2041.5422 -2274.1755 -2165.8677
 -2000.8097 -2190.3845 -2066.1777

(2,.,.) = 
  2866.7727  3030.2769  2918.6367
  3073.3599  3253.8975  3099.2637
  2967.0862  3115.5295  2946.3557

(3,.,.) = 
  3691.3545  4021.0298  4020.4634
  4527.0737  4942.6465  4934.6548
  4951.7563  5431.8501  5407.9771

(4,.,.) = 
  1055.4462  1176.0967  1153.7727
  1320.3636  1421.5374  1369.1510
  1435.5616  1489.7838  1396.5940

(5,.,.) = 
   750.7928   742.2665   663.2096
   737.0957   690.1838   583.3548
   753.7175   671.2844   562.0643

(6,.,.) = 
  1650.9705  1870.7716  1912.9717
  2026.7676  2336.0115  2379.2913
  2332.2539  2678.1055  2705.3169

(7,.,.) = 
 -2759.9602 -2931.7368 -2754.3735
 -2978.7622 -3130.0771 -2865.8789
 -2856.9641 -2933.4985 -2640.5203

(8,.,.) = 
  5778.5337  6190.3677  5946.5615
  6514.9624  6943.3926  6618.5420
  6781.3789  7155.8511  6782.1562

(9,.,.) = 
  2539.0774  3052.8203  3253.8789
  2925.0964  3453.0754  3581.9387
  3197.3291  3732.8914  3818.8711

(10,.,.) = 
 -3417.9014 -3375.8181 -3125.7417
 -3660.8115 -3625.6934 -3354.9353
 -3623.8506 -3579.6487 -3331.8625

(11,.,.) = 
   480.3605   640.3515   731.9467
   753.8505   943.9587  1031.6802
   844.8638  1081.4261  1171.9243

(12,.,.) = 
   447.7352   719.8910   954.6704
   516.1951   834.2474  1058.3108
   273.3158   590.3277   786.6383

(13,.,.) = 
 -2940.9475 -3109.0815 -3005.9922
 -2963.5569 -3118.5454 -3002.7207
 -2897.2407 -3043.0154 -2900.5562

(14,.,.) = 
  5067.1660  5368.6465  5171.4434
  5341.7515  5633.5649  5392.9443
  5286.0942  5600.8979  5329.4248

(15,.,.) = 
  3450.2251  3741.3784  3715.1733
  4020.6353  4408.8828  4358.8691
  4355.4448  4764.1050  4692.1836

(16,.,.) = 
 -2931.7539 -3012.3208 -3000.7388
 -3061.3203 -3176.0874 -3152.3696
 -3194.2905 -3337.0200 -3299.6987

(17,.,.) = 
 -7597.7056 -7995.9194 -7894.3853
 -8720.0381 -9228.3457 -9124.2852
 -9423.7920 -9994.4492 -9868.9229

(18,.,.) = 
  1645.3881  1593.7936  1497.2167
  1834.3810  1754.6249  1647.5375
  1829.8499  1736.2229  1632.6754
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3691.3544921875	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #177: time = 0.442251	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   6.4000e+02   6.4000e+02
        -inf         -inf   3.6108e+04   2.1339e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #178	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00037000/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 360
 636
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 636
 636
[torch.LongStorage of size 3]

x_start = 1 / y_start = 139	
img_means:size() vs img:size():	
   3
 360
 636
[torch.LongStorage of size 3]

   3
 360
 636
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6666666666667	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1060
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1060
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 360
 636
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6666666666667	
proposal_im_detect: scaled_img_size:	
    5
  600
 1060
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1905.6917 -2146.4639 -2073.8176
 -2031.5533 -2264.9614 -2160.6694
 -1990.9668 -2181.7432 -2061.8567

(2,.,.) = 
  2853.9644  3019.5530  2912.7969
  3058.9319  3241.6462  3092.3850
  2952.6782  3103.4312  2939.8787

(3,.,.) = 
  3676.3264  4011.1404  4018.4600
  4508.7949  4930.5054  4931.6851
  4931.7266  5417.6821  5403.4194

(4,.,.) = 
  1051.5787  1173.8909  1154.2083
  1316.4135  1419.6384  1370.3469
  1431.4104  1488.2188  1398.2379

(5,.,.) = 
   745.8276   738.8851   662.3859
   732.3781   687.1956   582.7921
   748.9697   668.2852   561.5721

(6,.,.) = 
  1644.2372  1866.3438  1912.0311
  2018.4155  2329.8408  2377.2668
  2323.1536  2671.2126  2702.7927

(7,.,.) = 
 -2745.4998 -2919.4219 -2747.0754
 -2963.0120 -3116.5310 -2857.8625
 -2841.1138 -2920.1042 -2632.6387

(8,.,.) = 
  5751.2217  6169.3145  5937.3579
  6484.8589  6920.2188  6608.3535
  6750.2104  7131.9688  6771.4976

(9,.,.) = 
  2527.2458  3042.4316  3247.2786
  2911.3184  3441.1499  3574.9565
  3182.1785  3719.7483  3811.1995

(10,.,.) = 
 -3404.2979 -3367.1777 -3123.6628
 -3645.8357 -3615.7078 -3351.8125
 -3608.3696 -3568.8569 -3327.7065

(11,.,.) = 
   479.3470   639.9098   732.2104
   751.8818   942.5330  1031.0435
   842.2081  1078.8984  1170.2064

(12,.,.) = 
   448.0569   719.2339   953.1685
   515.9983   832.8159  1056.4242
   274.1706   589.9561   786.0803

(13,.,.) = 
 -2924.9688 -3094.9644 -2996.4946
 -2945.9558 -3102.6506 -2991.8604
 -2879.3132 -3026.7837 -2889.6750

(14,.,.) = 
  5042.9849  5349.0737  5160.9141
  5315.5791  5612.0234  5380.7974
  5259.7271  5579.0342  5317.4482

(15,.,.) = 
  3435.3506  3731.1040  3712.5042
  4003.8157  4396.7324  4355.1538
  4337.8613  4751.2812  4687.9722

(16,.,.) = 
 -2920.2300 -3005.5032 -2999.7913
 -3048.7939 -3168.2476 -3150.4609
 -3180.4463 -3327.7974 -3296.7480

(17,.,.) = 
 -7566.6812 -7976.1553 -7890.6025
 -8685.2842 -9205.8984 -9119.7695
 -9386.6768 -9970.1182 -9863.1787

(18,.,.) = 
  1639.8691  1591.3003  1497.8829
  1828.1547  1751.8074  1647.9993
  1823.3010  1733.0156  1632.5640
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3676.3264160156	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #178: time = 0.431631	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1150
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   6.3600e+02   6.3600e+02
        -inf         -inf   3.5611e+04   2.1425e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #179	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00017002/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1917.7496  -2158.5461  -2082.8005
  -2044.6968  -2278.0706  -2170.2034
  -2003.9963  -2194.4734  -2070.5308

(2,.,.) = 
   2871.2036   3035.4043   2924.2986
   3078.0374   3259.3984   3105.0771
   2971.2219   3120.5388   2951.7229

(3,.,.) = 
   3703.2688   4033.8298   4032.9248
   4539.6470   4956.4141   4948.0728
   4963.4365   5444.5059   5420.1675

(4,.,.) = 
   1058.9208   1179.9445   1157.4786
   1324.9127   1426.1500   1373.5475
   1439.9436   1494.3563   1401.1213

(5,.,.) = 
    753.6973    745.5093    666.4111
    739.8666    693.3802    586.4581
    756.4426    674.2294    564.8737

(6,.,.) = 
   1656.5743   1877.1525   1919.2133
   2032.6382   2342.8062   2385.9841
   2337.9097   2684.4961   2711.5427

(7,.,.) = 
  -2764.8621  -2937.5737  -2760.8118
  -2983.9304  -3136.1951  -2872.3525
  -2861.5981  -2939.0159  -2646.5769

(8,.,.) = 
   5791.3667   6204.4028   5960.9429
   6528.3081   6958.1523   6633.2139
   6793.8696   7169.5879   6795.8345

(9,.,.) = 
   2546.4707   3060.8921   3262.0286
   2932.7644   3461.4580   3590.3787
   3204.4375   3740.7593   3826.8955

(10,.,.) = 
  -3425.9504  -3384.4089  -3134.5044
  -3669.0540  -3634.3555  -3363.7598
  -3631.1284  -3587.3228  -3339.5034

(11,.,.) = 
    480.9809    641.0548    732.6763
    755.1965    945.3743   1033.0303
    845.5635   1082.2394   1172.7158

(12,.,.) = 
    447.8412    720.2107    955.3740
    516.8439    835.2595   1059.7711
    274.0354    591.5502    788.5303

(13,.,.) = 
  -2944.8953  -3113.6204  -3010.6846
  -2966.5164  -3122.3174  -3006.6907
  -2900.2100  -3046.7156  -2904.3145

(14,.,.) = 
   5075.5674   5377.8379   5180.8242
   5349.9702   5642.5278   5402.1436
   5293.9238   5609.5493   5338.2466

(15,.,.) = 
   3460.0598   3752.3157   3726.1404
   4031.0610   4420.5195   4370.4985
   4365.6069   4775.3779   4703.3315

(16,.,.) = 
  -2940.8813  -3021.7832  -3009.8584
  -3070.6631  -3185.6445  -3161.3003
  -3202.8994  -3345.7993  -3307.7178

(17,.,.) = 
  -7619.0591  -8018.7466  -7916.6279
  -8742.9072  -9252.6211  -9148.0195
  -9445.6035 -10017.4590  -9891.0225

(18,.,.) = 
   1649.3375   1597.9153   1501.5601
   1838.5826   1758.7673   1651.7970
   1833.6140   1739.8263   1636.3790
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3703.2687988281	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #179: time = 0.54316399999999	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2318e+04   4.2789e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #180	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00108000/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 240
 320
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 320
 320
[torch.LongStorage of size 3]

x_start = 1 / y_start = 41	
img_means:size() vs img:size():	
   3
 240
 320
[torch.LongStorage of size 3]

   3
 240
 320
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 2.5	
(orep_img_for_blob) img size after scaling:	
   3
 600
 800
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x97
  2 : CudaTensor - size: 18x72x97
  3 : CudaTensor - size: 18x70x95
  4 : CudaTensor - size: 18x68x93
  5 : CudaTensor - size: 256x74x99
}
proposal_im_deteect: img_blob size:    3
 600
 800
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 240
 320
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 2.5	
proposal_im_detect: scaled_img_size:	
   8
 600
 800
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
  -1915.0044  -2156.0437  -2079.4373
  -2044.3188  -2277.6665  -2169.0503
  -2004.6814  -2195.1331  -2070.4993

(2,.,.) = 
   2867.5432   3031.5339   2920.2803
   3076.4768   3258.1973   3103.4214
   2971.4312   3121.2593   2952.1418

(3,.,.) = 
   3715.0447   4046.2373   4044.6248
   4555.7041   4973.5186   4964.5571
   4981.5532   5464.2920   5439.0493

(4,.,.) = 
   1067.3126   1189.5924   1167.2050
   1333.3057   1436.0531   1383.7717
   1448.2556   1503.8381   1410.1638

(5,.,.) = 
    758.3499    749.1976    668.5650
    745.0370    698.1296    590.1394
    760.9127    678.8192    569.7764

(6,.,.) = 
   1668.1442   1890.0581   1931.9070
   2046.0708   2357.3486   2400.2246
   2351.6282   2699.8367   2726.5088

(7,.,.) = 
  -2774.6013  -2947.3357  -2770.1406
  -2995.2461  -3147.9663  -2883.4543
  -2872.8826  -2950.8064  -2657.6311

(8,.,.) = 
   5811.8765   6225.0732   5979.2729
   6552.4751   6982.5898   6655.5796
   6817.9941   7194.7256   6818.9458

(9,.,.) = 
   2558.3628   3074.9329   3277.5457
   2949.1843   3480.0940   3609.8132
   3220.3259   3758.3713   3844.6353

(10,.,.) = 
  -3420.8289  -3379.0605  -3129.8188
  -3665.5146  -3631.3418  -3360.6248
  -3630.9939  -3588.1538  -3341.0281

(11,.,.) = 
    486.8486    647.7360    738.4054
    759.0909    949.8270   1037.2975
    849.7924   1087.4705   1178.1462

(12,.,.) = 
    446.7742    720.6138    955.5792
    515.7256    835.7934   1060.2510
    274.7607    593.8821    790.7833

(13,.,.) = 
  -2945.7024  -3113.7078  -3010.9358
  -2971.5300  -3127.1433  -3011.9048
  -2906.2297  -3052.4082  -2909.7173

(14,.,.) = 
   5080.1846   5382.2593   5184.1870
   5357.9790   5650.2993   5409.3569
   5304.1904   5619.9517   5347.9927

(15,.,.) = 
   3477.0068   3770.7156   3743.3652
   4050.7666   4441.7993   4390.5830
   4385.3921   4796.9980   4723.6812

(16,.,.) = 
  -2941.0059  -3022.1204  -3010.5225
  -3075.7771  -3190.9309  -3166.9739
  -3210.9670  -3354.8213  -3317.3120

(17,.,.) = 
  -7641.9551  -8041.4600  -7937.6514
  -8771.4775  -9282.6143  -9177.0479
  -9477.0146 -10051.3350  -9924.3721

(18,.,.) = 
   1647.5892   1595.5532   1499.1752
   1838.1006   1757.8616   1651.4924
   1835.7378   1742.0258   1639.3734
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
 18
 70
 95
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 19950
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 95
 70
[torch.DoubleTensor of size 2]

shift_x size:	
 70
 95
[torch.LongStorage of size 2]

shift_y size:	
 70
 95
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 6650
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 19950
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 19950
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  19950
[torch.LongStorage of size 1]
	
  first line: 3715.0446777344	
(fast bbox transform) src_w size:  19950
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 19950
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 19950
     4
[torch.LongStorage of size 2]

scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 19950
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 19950
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 53200
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 13300
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 13300
[torch.LongStorage of size 1]

test img #180: time = 0.31990800000001	
(proposal_test:boxes_filter) boxes & scores size:	
 13300
     4
[torch.LongStorage of size 2]

 13300
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 953
   3
[torch.LongTensor of size 2]

mask size:	
 13300
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   3.2000e+02   3.2000e+02
        -inf         -inf   2.4173e+04   1.4249e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #181	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00069003/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1910.1405 -2149.6970 -2073.7180
 -2037.0083 -2268.9841 -2160.7319
 -1996.7861 -2185.8274 -2061.7051

(2,.,.) = 
  2859.8762  3022.8284  2911.2617
  3066.2502  3246.2114  3091.7605
  2960.8333  3108.8047  2939.7588

(3,.,.) = 
  3681.4268  4010.4866  4010.0547
  4515.5537  4930.1899  4922.0254
  4939.7319  5418.4600  5394.1982

(4,.,.) = 
  1052.8215  1173.4664  1151.1903
  1317.2854  1418.4760  1366.1542
  1432.2990  1486.4955  1393.3326

(5,.,.) = 
   748.8975   740.4843   661.5511
   735.5839   688.7489   582.0368
   752.2708   670.0051   560.9981

(6,.,.) = 
  1646.2239  1865.5497  1907.7117
  2020.9365  2329.4661  2372.6587
  2325.7202  2670.8647  2697.9622

(7,.,.) = 
 -2753.6802 -2924.9319 -2747.7917
 -2971.9939 -3122.8162 -2859.0862
 -2850.8467 -2927.1111 -2634.6416

(8,.,.) = 
  5764.8984  6176.0337  5932.6553
  6499.8481  6927.2549  6602.7949
  6765.9800  7139.2690  6765.6738

(9,.,.) = 
  2532.6030  3045.2839  3245.8904
  2918.1082  3445.0720  3573.6599
  3189.9819  3724.4099  3810.1833

(10,.,.) = 
 -3410.3086 -3368.1570 -3118.3831
 -3652.3125 -3616.9829 -3346.5239
 -3615.0625 -3570.5881 -3322.8389

(11,.,.) = 
   479.3868   639.1318   730.5566
   751.7013   941.5185  1029.1505
   842.3629  1078.4845  1168.8390

(12,.,.) = 
   446.3968   717.9987   952.3708
   514.6560   832.2469  1056.1219
   272.8413   589.5177   785.7264

(13,.,.) = 
 -2934.6353 -3102.2156 -2999.1128
 -2957.4919 -3111.9177 -2996.0747
 -2891.4058 -3036.5852 -2894.1626

(14,.,.) = 
  5056.1816  5356.8696  5159.8340
  5330.2334  5621.2192  5380.7114
  5274.6230  5588.3652  5316.9541

(15,.,.) = 
  3441.6292  3732.2969  3706.1924
  4010.6611  4398.1245  4348.0654
  4344.5938  4752.2354  4680.1436

(16,.,.) = 
 -2924.5068 -3004.9202 -2993.4060
 -3054.0796 -3168.5300 -3144.8132
 -3186.7444 -3328.9436 -3291.4189

(17,.,.) = 
 -7578.5718 -7976.1782 -7874.8589
 -8698.8975 -9205.9609 -9101.6064
 -9400.9883 -9969.8027 -9843.4941

(18,.,.) = 
  1641.7146  1590.0704  1493.5353
  1830.1311  1750.3445  1643.2878
  1825.6039  1731.9824  1628.5328
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3681.4267578125	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #181: time = 0.53791899999999	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.2029e+04   4.2587e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #182	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00050000/000003.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1902.2192 -2141.0090 -2065.6050
 -2028.0981 -2259.2800 -2151.7778
 -1987.9065 -2176.1875 -2052.9324

(2,.,.) = 
  2848.5474  3011.2136  2900.6667
  3053.8699  3233.2322  3079.9956
  2948.9631  3096.2100  2928.3616

(3,.,.) = 
  3662.2429  3990.1255  3990.8447
  4493.9155  4907.2593  4900.6377
  4918.3716  5396.1533  5373.5576

(4,.,.) = 
  1047.1753  1167.1473  1145.1886
  1310.1566  1411.1798  1359.4962
  1425.3179  1479.6050  1387.1055

(5,.,.) = 
   743.7330   734.9554   656.4460
   730.5294   683.3521   577.1937
   747.6196   665.3007   556.6732

(6,.,.) = 
  1638.1926  1856.6571  1899.1885
  2012.2706  2319.6929  2363.2070
  2317.1077  2661.0325  2688.3052

(7,.,.) = 
 -2742.0188 -2912.5359 -2736.3389
 -2959.6091 -3109.5212 -2846.9785
 -2839.4282 -2914.6660 -2623.0342

(8,.,.) = 
  5737.7285  6147.1963  5905.6152
  6470.8442  6896.6489  6574.7505
  6738.3594  7110.2876  6739.2305

(9,.,.) = 
  2520.0923  3031.0005  3231.4495
  2904.3328  3429.5759  3558.0386
  3176.6055  3709.4014  3794.9521

(10,.,.) = 
 -3394.0527 -3352.4761 -3104.5850
 -3635.9453 -3600.9766 -3332.3564
 -3600.4070 -3556.0247 -3309.8701

(11,.,.) = 
   477.9302   637.2387   728.3889
   749.5992   939.1249  1026.4802
   840.7564  1076.2817  1166.2297

(12,.,.) = 
   446.6307   717.9437   951.6693
   514.0010   830.8864  1053.9167
   272.0084   587.6171   782.8899

(13,.,.) = 
 -2922.8726 -3090.0652 -2987.9360
 -2946.0759 -3099.7849 -2984.8271
 -2880.5413 -3024.9478 -2883.4568

(14,.,.) = 
  5034.5854  5334.5557  5139.3999
  5308.3403  5598.4341  5359.7695
  5254.2612  5566.8188  5297.1304

(15,.,.) = 
  3424.3125  3713.7104  3688.4497
  3992.2461  4378.0059  4328.9717
  4326.7778  4732.8921  4661.8018

(16,.,.) = 
 -2909.5994 -2989.6848 -2978.9102
 -3038.6521 -3152.7368 -3130.0356
 -3172.2590 -3314.1072 -3277.7302

(17,.,.) = 
 -7540.5806 -7936.8574 -7838.1440
 -8657.6416 -9163.5635 -9062.1025
 -9360.9756 -9928.8760 -9805.9189

(18,.,.) = 
  1634.0637  1582.8711  1487.1819
  1821.9833  1742.8541  1636.7367
  1818.0438  1725.0540  1622.1990
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3662.2429199219	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #182: time = 0.551272	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1910e+04   4.2531e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #183	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00013010/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1920
 1920
[torch.LongStorage of size 3]

x_start = 1 / y_start = 421	
img_means:size() vs img:size():	
    3
 1080
 1920
[torch.LongStorage of size 3]

    3
 1080
 1920
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.55555555555556	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
 1080
 1920
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.55555555555556	
proposal_im_detect: scaled_img_size:	
    2
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1916.0160 -2156.4282 -2080.3523
 -2042.6787 -2275.5193 -2167.2646
 -2001.7260 -2191.4851 -2067.2971

(2,.,.) = 
  2868.6675  3032.3591  2920.7483
  3075.1328  3255.8806  3101.2441
  2968.4124  3117.0386  2947.9131

(3,.,.) = 
  3694.2024  4024.1384  4023.5811
  4529.6304  4945.4536  4937.4604
  4953.2231  5433.3682  5409.4844

(4,.,.) = 
  1056.1984  1176.9221  1154.5970
  1321.0771  1422.2441  1369.8400
  1435.9926  1490.0790  1396.8657

(5,.,.) = 
   751.3054   742.8529   663.7823
   737.4149   690.5443   583.7046
   753.8967   671.4587   562.2441

(6,.,.) = 
  1652.0594  1872.0139  1914.2214
  2027.5094  2336.8889  2380.1797
  2332.3335  2678.3445  2705.5476

(7,.,.) = 
 -2761.4312 -2933.3848 -2756.0217
 -2979.6008 -3131.0283 -2866.6978
 -2856.6260 -2933.1218 -2639.9878

(8,.,.) = 
  5782.0884  6194.2896  5950.4902
  6517.6226  6946.3643  6621.3677
  6782.0488  7156.5317  6782.6436

(9,.,.) = 
  2540.7781  3054.7891  3255.9614
  2926.3279  3454.4248  3583.3274
  3197.6030  3733.0847  3818.9495

(10,.,.) = 
 -3420.5154 -3378.5159 -3128.3464
 -3663.0728 -3627.9792 -3357.1104
 -3624.7815 -3580.5283 -3332.5552

(11,.,.) = 
   480.4982   640.5651   732.2250
   753.9806   944.1638  1031.9290
   844.5750  1081.1790  1171.6678

(12,.,.) = 
   447.9717   720.2455   955.1962
   516.4915   834.6969  1058.9325
   273.5890   590.6879   787.1550

(13,.,.) = 
 -2942.7275 -3111.0415 -3007.9324
 -2964.9026 -3120.0293 -3004.1680
 -2897.9243 -3043.8391 -2901.3396

(14,.,.) = 
  5070.3560  5372.1113  5174.8691
  5344.2954  5636.3320  5395.6572
  5287.2061  5602.2056  5330.6533

(15,.,.) = 
  3452.5574  3743.9465  3717.7732
  4022.3997  4410.8120  4360.8101
  4356.0605  4764.6880  4692.7119

(16,.,.) = 
 -2934.1799 -3014.8408 -3003.2185
 -3063.4612 -3178.2698 -3154.4631
 -3195.8062 -3338.5544 -3301.0398

(17,.,.) = 
 -7603.2959 -8001.9385 -7900.3887
 -8724.9922 -9233.6650 -9129.6162
 -9426.8867 -9997.6133 -9872.0146

(18,.,.) = 
  1646.6445  1595.0825  1498.4969
  1835.5477  1755.7968  1648.6688
  1830.5552  1736.8673  1633.2727
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3694.2023925781	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #183: time = 0.739881	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.9200e+03   1.9200e+03
        -inf         -inf   1.0825e+05   6.4017e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #184	
/disk2/bingbin/ILSVRC2015_test/Data/VID/train/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00094002/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
    3
 1280
 1280
[torch.LongStorage of size 3]

x_start = 1 / y_start = 281	
img_means:size() vs img:size():	
    3
  720
 1280
[torch.LongStorage of size 3]

    3
  720
 1280
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 0.83333333333333	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:     3
  720
 1280
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 0.83333333333333	
proposal_im_detect: scaled_img_size:	
    3
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1903.0609 -2141.4231 -2065.4111
 -2028.1249 -2258.8188 -2150.6863
 -1986.9136 -2174.4377 -2050.6621

(2,.,.) = 
  2849.2495  3011.3010  2899.6404
  3053.6626  3232.3027  3078.1487
  2947.4871  3093.9822  2925.2615

(3,.,.) = 
  3656.1743  3982.7493  3982.5796
  4485.3999  4896.9072  4889.3125
  4907.3765  5383.2539  5360.0825

(4,.,.) = 
  1044.1251  1163.3644  1141.2527
  1306.3125  1406.4966  1354.5457
  1420.8837  1474.1504  1381.6215

(5,.,.) = 
   742.7751   734.0226   655.6633
   728.9435   681.7169   575.7092
   745.4208   662.9470   554.2931

(6,.,.) = 
  1633.3119  1850.7611  1892.9600
  2006.2793  2312.5649  2355.7847
  2310.0813  2652.8479  2680.1348

(7,.,.) = 
 -2739.0991 -2909.0107 -2731.9553
 -2955.7268 -3105.1423 -2842.0227
 -2834.3208 -2909.3464 -2617.4521

(8,.,.) = 
  5730.2852  6138.5068  5895.9336
  6460.5840  6884.9521  6562.1997
  6725.1646  7095.7690  6724.4014

(9,.,.) = 
  2515.1074  3024.9795  3224.6335
  2897.3577  3421.2693  3549.2151
  3168.4094  3699.8828  3785.1492

(10,.,.) = 
 -3392.9053 -3350.4973 -3101.3127
 -3633.3894 -3597.8867 -3328.3337
 -3596.0513 -3551.3328 -3304.6340

(11,.,.) = 
   475.4639   634.3375   725.7223
   747.2610   936.2124  1023.6694
   838.3201  1073.3503  1163.4453

(12,.,.) = 
   446.3766   716.8306   950.2076
   513.9847   829.9087  1052.5502
   271.5549   586.1281   780.8994

(13,.,.) = 
 -2922.5305 -3089.4077 -2986.6204
 -2944.7410 -3098.0681 -2982.4436
 -2877.8523 -3022.0952 -2880.3066

(14,.,.) = 
  5032.0059  5331.2017  5134.9277
  5303.7798  5593.3364  5353.6924
  5247.1611  5559.2271  5289.0083

(15,.,.) = 
  3417.2371  3705.2109  3679.3223
  3982.8611  4367.2114  4317.6943
  4315.4277  4720.0215  4648.8945

(16,.,.) = 
 -2906.6592 -2986.2542 -2974.9905
 -3033.4453 -3147.1670 -3124.1555
 -3165.2598 -3306.4763 -3269.9741

(17,.,.) = 
 -7529.2451 -7923.4819 -7823.1875
 -8641.6211 -9145.1055 -9042.0938
 -9340.3682 -9905.7461 -9781.7969

(18,.,.) = 
  1633.3895  1581.9556  1485.6179
  1820.5684  1741.3372  1634.5194
  1815.4840  1722.3712  1619.0354
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3656.1743164062	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of tmp_mult:	
 4
[torch.LongStorage of size 1]

proposal_im_detect: size of pred_boxes:	
 26880
     4
[torch.LongStorage of size 2]

proposal_im_detect: size of pred_boxes (before clip):	
 26880
     4
[torch.LongStorage of size 2]

scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size:	
 26880
     4
[torch.LongStorage of size 2]

filter_boxes: scores size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: valid_idx size:	
 26880
[torch.LongStorage of size 1]

filter_boxes: boxes size after filtering:	
 71680
[torch.LongStorage of size 1]

filter_boxes: boxes size returned:	
 17920
     4
[torch.LongStorage of size 2]

filter_boxes: scores size returned:	
 17920
[torch.LongStorage of size 1]

test img #184: time = 0.590018	
(proposal_test:boxes_filter) boxes & scores size:	
 17920
     4
[torch.LongStorage of size 2]

 17920
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) nms_idx size:	
 2
[torch.LongStorage of size 1]

 1539
    3
[torch.LongTensor of size 2]

mask size:	
 17920
     4
[torch.LongStorage of size 2]

(proposal_test:boxes_filter) boxes size after nms:	
 8
[torch.LongStorage of size 1]

(proposal_test:boxes_filter) boxes after reshape	
  1.0000e+00   1.0000e+00   1.2800e+03   1.2800e+03
        -inf         -inf   7.1722e+04   4.2364e+04
[torch.CudaTensor of size 2x4]

(proposal_test:boxes_filter) boxes size returned:	
 2
 4
[torch.LongStorage of size 2]

img #185	
/disk2/bingbin/ILSVRC2015_test/Data/VID/val/ILSVRC2015_VID_train_0000/ILSVRC2015_train_00102006/000000.JPEG	
img loaded	
in prep_img_for_blob	
in prep_img_fore_blob: img_means prepared; img_means size & img_size:	
   3
 224
 224
[torch.LongStorage of size 3]

   3
 360
 640
[torch.LongStorage of size 3]

img_means before resize:	
   3
 224
 224
[torch.LongStorage of size 3]

img_means after resize:	
   3
 640
 640
[torch.LongStorage of size 3]

x_start = 1 / y_start = 141	
img_means:size() vs img:size():	
   3
 360
 640
[torch.LongStorage of size 3]

   3
 360
 640
[torch.LongStorage of size 3]

(prep_img_for_blob) img_scale: 1.6666666666667	
(orep_img_for_blob) img size after scaling:	
    3
  600
 1066
[torch.LongStorage of size 3]

orig outputs:	
{
  1 : CudaTensor - size: 18x72x130
  2 : CudaTensor - size: 18x72x130
  3 : CudaTensor - size: 18x70x128
  4 : CudaTensor - size: 18x68x126
  5 : CudaTensor - size: 256x74x132
}
proposal_im_deteect: img_blob size:     3
  600
 1066
[torch.LongStorage of size 3]
	
proposal_im_detect: img_size:    3
 360
 640
[torch.LongStorage of size 3]
	
proposal_im_detect: img_scales: 1.6666666666667	
proposal_im_detect: scaled_img_size:	
    5
  600
 1067
[torch.DoubleTensor of size 3]

outputs:	
(1,.,.) = 
 -1909.5151 -2149.0879 -2073.2849
 -2034.5712 -2266.6904 -2159.1189
 -1992.0389 -2181.2095 -2058.0493

(2,.,.) = 
  2858.3975  3021.8608  2910.6570
  3062.8274  3243.4534  3089.5808
  2954.6819  3103.2100  2935.2029

(3,.,.) = 
  3678.0732  4006.2522  4006.2754
  4508.9224  4922.8574  4915.8291
  4928.5356  5407.1411  5385.0039

(4,.,.) = 
  1052.0768  1171.9755  1149.9156
  1315.5713  1415.9001  1364.0120
  1429.1049  1482.7471  1390.4615

(5,.,.) = 
   748.8881   740.3963   661.9748
   734.0255   687.3763   581.5436
   749.1877   667.0660   559.0971

(6,.,.) = 
  1644.0543  1863.4741  1906.0303
  2017.4071  2326.0425  2369.9832
  2320.8079  2665.6743  2693.8135

(7,.,.) = 
 -2749.3855 -2921.7063 -2745.9011
 -2965.8030 -3117.7659 -2855.8540
 -2841.5955 -2919.0652 -2628.7285

(8,.,.) = 
  5756.7134  6168.2031  5926.5752
  6486.4795  6914.6519  6593.2275
  6745.9834  7120.5591  6751.5786

(9,.,.) = 
  2528.2935  3040.5752  3241.7356
  2911.4478  3437.8486  3567.2725
  3180.3831  3714.4250  3801.2837

(10,.,.) = 
 -3405.2544 -3364.2576 -3115.4180
 -3644.6416 -3611.1890 -3342.2810
 -3604.6997 -3562.3569 -3317.3013

(11,.,.) = 
   477.2466   636.6989   728.1887
   749.7240   939.0873  1026.7549
   840.3524  1076.0841  1166.5602

(12,.,.) = 
   447.2918   718.2928   952.3389
   516.3102   832.9583  1056.0588
   274.3780   589.8976   785.0471

(13,.,.) = 
 -2930.4407 -3099.2310 -2996.9995
 -2951.0251 -3106.9600 -2992.4102
 -2882.5076 -3029.1323 -2888.4631

(14,.,.) = 
  5049.0435  5351.0200  5155.0991
  5318.9390  5611.6133  5373.1782
  5258.9146  5574.5542  5306.2271

(15,.,.) = 
  3436.7859  3727.1262  3701.6750
  4002.6982  4389.9907  4341.3203
  4332.9297  4740.5527  4670.8828

(16,.,.) = 
 -2921.4387 -3001.7976 -2990.3418
 -3048.0964 -3162.9138 -3139.8452
 -3177.6082 -3320.6443 -3284.6643

(17,.,.) = 
 -7571.9839 -7969.0337 -7868.4243
 -8685.4697 -9192.7314 -9090.6602
 -9379.4521 -9949.6826 -9827.9746

(18,.,.) = 
  1640.2531  1589.0254  1492.9681
  1827.7006  1748.6555  1642.3793
  1821.6373  1729.0515  1626.5470
[torch.CudaTensor of size 18x3x3]

proposal_im_detect: outputs size:	
  18
  70
 128
[torch.LongStorage of size 3]

proposal_im_detect: outputs size after reshaping:	
     6
 26880
[torch.LongStorage of size 2]

locate_anchors_single_scale: output_size:	
 128
  70
[torch.DoubleTensor of size 2]

shift_x size:	
  70
 128
[torch.LongStorage of size 2]

shift_y size:	
  70
 128
[torch.LongStorage of size 2]

conf_anchors size:	
 3
 4
[torch.LongStorage of size 2]

out_anchors size:	
    3
 8960
    4
[torch.LongStorage of size 3]

out_anchors size (after reshape):	
     4
 26880
[torch.LongStorage of size 2]

(fast bbox transform) boxes size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) box_deltas size:      4
 26880
[torch.LongStorage of size 2]
	
(fast bbox transform) dst_ctr_x size:  26880
[torch.LongStorage of size 1]
	
  first line: 3678.0732421875	
(fast bbox transform) src_w size:  26880
[torch.LongStorage of size 1]
	
fast bbox transform: output size:	
 26880
     4
[torch.LongStorage of size 2]

